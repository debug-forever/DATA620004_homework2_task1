
(base) C:\Users\26336>cd C:\Users\26336\Desktop\FDU\神经网络\home_work_2\caltech-101

(base) C:\Users\26336\Desktop\FDU\神经网络\home_work_2\caltech-101>cd ..

(base) C:\Users\26336\Desktop\FDU\神经网络\home_work_2>di
'di' is not recognized as an internal or external command,
operable program or batch file.

(base) C:\Users\26336\Desktop\FDU\神经网络\home_work_2>dir
 Volume in drive C is Windows-SSD
 Volume Serial Number is 7E06-5E02

 Directory of C:\Users\26336\Desktop\FDU\神经网络\home_work_2

2025/05/21  19:40    <DIR>          .
2025/05/21  19:40    <DIR>          ..
2025/05/21  16:43    <DIR>          caltech-101
2025/05/19  15:56       137,414,764 caltech-101.zip
2025/05/21  16:53    <DIR>          checkpoints
2025/05/21  16:20    <DIR>          data
2025/05/21  16:51             1,930 dataset.py
2025/05/21  20:11               823 main.py
2025/05/21  16:50             1,576 model.py
2025/05/21  16:43             1,846 prepare_data.py
2025/05/19  17:03               586 readme.md
2025/05/21  17:18    <DIR>          runs
2025/05/19  15:33             2,978 task.txt
2025/05/19  15:40             1,148 task1.txt
2025/05/21  20:09             4,839 train.py
2025/05/19  15:58    <DIR>          __MACOSX
2025/05/21  16:51    <DIR>          __pycache__
               9 File(s)    137,430,490 bytes
               8 Dir(s)   9,729,990,656 bytes free

(base) C:\Users\26336\Desktop\FDU\神经网络\home_work_2>python main.py
Training with pretrained weights...
Number of classes: 102
Class names: ['BACKGROUND_Google', 'Faces', 'Faces_easy', 'Leopards', 'Motorbikes', 'accordion', 'airplanes', 'anchor', 'ant', 'barrel', 'bass', 'beaver', 'binocular', 'bonsai', 'brain', 'brontosaurus', 'buddha', 'butterfly', 'camera', 'cannon', 'car_side', 'ceiling_fan', 'cellphone', 'chair', 'chandelier', 'cougar_body', 'cougar_face', 'crab', 'crayfish', 'crocodile', 'crocodile_head', 'cup', 'dalmatian', 'dollar_bill', 'dolphin', 'dragonfly', 'electric_guitar', 'elephant', 'emu', 'euphonium', 'ewer', 'ferry', 'flamingo', 'flamingo_head', 'garfield', 'gerenuk', 'gramophone', 'grand_piano', 'hawksbill', 'headphone', 'hedgehog', 'helicopter', 'ibis', 'inline_skate', 'joshua_tree', 'kangaroo', 'ketch', 'lamp', 'laptop', 'llama', 'lobster', 'lotus', 'mandolin', 'mayfly', 'menorah', 'metronome', 'minaret', 'nautilus', 'octopus', 'okapi', 'pagoda', 'panda', 'pigeon', 'pizza', 'platypus', 'pyramid', 'revolver', 'rhino', 'rooster', 'saxophone', 'schooner', 'scissors', 'scorpion', 'sea_horse', 'snoopy', 'soccer_ball', 'stapler', 'starfish', 'stegosaurus', 'stop_sign', 'strawberry', 'sunflower', 'tick', 'trilobite', 'umbrella', 'watch', 'water_lilly', 'wheelchair', 'wild_cat', 'windsor_chair', 'wrench', 'yin_yang']
Training samples: 7280
Validation samples: 1864
Epoch: 1/3 | Batch: 1/228 | Loss: 4.8406
Epoch: 1/3 | Batch: 11/228 | Loss: 4.0538
Epoch: 1/3 | Batch: 21/228 | Loss: 3.4114
Epoch: 1/3 | Batch: 31/228 | Loss: 3.3127
Epoch: 1/3 | Batch: 41/228 | Loss: 2.7285
Epoch: 1/3 | Batch: 51/228 | Loss: 2.3049
Epoch: 1/3 | Batch: 61/228 | Loss: 1.8042
Epoch: 1/3 | Batch: 71/228 | Loss: 2.3415
Epoch: 1/3 | Batch: 81/228 | Loss: 1.9638
Epoch: 1/3 | Batch: 91/228 | Loss: 1.6111
Epoch: 1/3 | Batch: 101/228 | Loss: 1.7271
Epoch: 1/3 | Batch: 111/228 | Loss: 1.9677
Epoch: 1/3 | Batch: 121/228 | Loss: 1.1169
Epoch: 1/3 | Batch: 131/228 | Loss: 0.9712
Epoch: 1/3 | Batch: 141/228 | Loss: 1.0282
Epoch: 1/3 | Batch: 151/228 | Loss: 1.2493
Epoch: 1/3 | Batch: 161/228 | Loss: 1.1835
Epoch: 1/3 | Batch: 171/228 | Loss: 1.2919
Epoch: 1/3 | Batch: 181/228 | Loss: 1.0663
Epoch: 1/3 | Batch: 191/228 | Loss: 1.1240
Epoch: 1/3 | Batch: 201/228 | Loss: 0.9263
Epoch: 1/3 | Batch: 211/228 | Loss: 0.5214
Epoch: 1/3 | Batch: 221/228 | Loss: 0.6804
Epoch: 1/3 | Train Loss: 1.7887 | Train Acc: 59.64% | Val Loss: 0.5273 | Val Acc: 84.66%
Current learning rate: 0.0001
Current learning rate: 0.0001
Current learning rate: 0.0001
Current learning rate: 0.0001
Current learning rate: 0.0001
Current learning rate: 0.0001
Current learning rate: 0.001
Best accuracy: 84.66%
Model saved to checkpoints\resnet18_pretrained_best.pth
Epoch: 2/3 | Batch: 1/228 | Loss: 0.9692
Epoch: 2/3 | Batch: 11/228 | Loss: 0.7177
Epoch: 2/3 | Batch: 21/228 | Loss: 0.8339
Epoch: 2/3 | Batch: 31/228 | Loss: 0.8459
Epoch: 2/3 | Batch: 41/228 | Loss: 0.3156
Epoch: 2/3 | Batch: 51/228 | Loss: 0.7257
Epoch: 2/3 | Batch: 61/228 | Loss: 0.5802
Epoch: 2/3 | Batch: 71/228 | Loss: 0.9380
Epoch: 2/3 | Batch: 81/228 | Loss: 0.9817
Epoch: 2/3 | Batch: 91/228 | Loss: 0.4095
Epoch: 2/3 | Batch: 101/228 | Loss: 0.7113
Epoch: 2/3 | Batch: 111/228 | Loss: 0.5397
Epoch: 2/3 | Batch: 121/228 | Loss: 0.8229
Epoch: 2/3 | Batch: 131/228 | Loss: 0.5430
Epoch: 2/3 | Batch: 141/228 | Loss: 0.3978
Epoch: 2/3 | Batch: 151/228 | Loss: 0.4015
Epoch: 2/3 | Batch: 161/228 | Loss: 0.7082
Epoch: 2/3 | Batch: 171/228 | Loss: 0.9032
Epoch: 2/3 | Batch: 181/228 | Loss: 0.6698
Epoch: 2/3 | Batch: 191/228 | Loss: 0.6912
Epoch: 2/3 | Batch: 201/228 | Loss: 0.5666
Epoch: 2/3 | Batch: 211/228 | Loss: 1.0224
Epoch: 2/3 | Batch: 221/228 | Loss: 0.4675
Epoch: 2/3 | Train Loss: 0.7837 | Train Acc: 79.34% | Val Loss: 0.3579 | Val Acc: 89.86%
Current learning rate: 0.0001
Current learning rate: 0.0001
Current learning rate: 0.0001
Current learning rate: 0.0001
Current learning rate: 0.0001
Current learning rate: 0.0001
Current learning rate: 0.001
Best accuracy: 89.86%
Model saved to checkpoints\resnet18_pretrained_best.pth
Epoch: 3/3 | Batch: 1/228 | Loss: 0.7860
Epoch: 3/3 | Batch: 11/228 | Loss: 0.2091
Epoch: 3/3 | Batch: 21/228 | Loss: 0.3126
Epoch: 3/3 | Batch: 31/228 | Loss: 0.8400
Epoch: 3/3 | Batch: 41/228 | Loss: 0.5242
Epoch: 3/3 | Batch: 51/228 | Loss: 0.6875
Epoch: 3/3 | Batch: 61/228 | Loss: 0.9423
Epoch: 3/3 | Batch: 71/228 | Loss: 0.6970
Epoch: 3/3 | Batch: 81/228 | Loss: 0.8309
Epoch: 3/3 | Batch: 91/228 | Loss: 0.6319
Epoch: 3/3 | Batch: 101/228 | Loss: 0.4846
Epoch: 3/3 | Batch: 111/228 | Loss: 0.9262
Epoch: 3/3 | Batch: 121/228 | Loss: 0.3043
Epoch: 3/3 | Batch: 131/228 | Loss: 0.2796
Epoch: 3/3 | Batch: 141/228 | Loss: 1.0864
Epoch: 3/3 | Batch: 151/228 | Loss: 0.4878
Epoch: 3/3 | Batch: 161/228 | Loss: 0.7759
Epoch: 3/3 | Batch: 171/228 | Loss: 0.6855
Epoch: 3/3 | Batch: 181/228 | Loss: 0.4843
Epoch: 3/3 | Batch: 191/228 | Loss: 0.3371
Epoch: 3/3 | Batch: 201/228 | Loss: 0.6910
Epoch: 3/3 | Batch: 211/228 | Loss: 0.4620
Epoch: 3/3 | Batch: 221/228 | Loss: 0.6792
Epoch: 3/3 | Train Loss: 0.6043 | Train Acc: 83.04% | Val Loss: 0.3139 | Val Acc: 90.40%
Current learning rate: 0.0001
Current learning rate: 0.0001
Current learning rate: 0.0001
Current learning rate: 0.0001
Current learning rate: 0.0001
Current learning rate: 0.0001
Current learning rate: 0.001
Best accuracy: 90.40%
Model saved to checkpoints\resnet18_pretrained_best.pth

(base) C:\Users\26336\Desktop\FDU\神经网络\home_work_2>tensorboard --logdir=runs
'tensorboard' is not recognized as an internal or external command,
operable program or batch file.

(base) C:\Users\26336\Desktop\FDU\神经网络\home_work_2>pip install tensorboard
Defaulting to user installation because normal site-packages is not writeable
Requirement already satisfied: tensorboard in c:\users\26336\appdata\roaming\python\python312\site-packages (2.19.0)
Requirement already satisfied: absl-py>=0.4 in c:\users\26336\appdata\roaming\python\python312\site-packages (from tensorboard) (2.2.2)
Requirement already satisfied: grpcio>=1.48.2 in c:\users\26336\appdata\roaming\python\python312\site-packages (from tensorboard) (1.71.0)
Requirement already satisfied: markdown>=2.6.8 in e:\anaconda\lib\site-packages (from tensorboard) (3.4.1)
Requirement already satisfied: numpy>=1.12.0 in c:\users\26336\appdata\roaming\python\python312\site-packages (from tensorboard) (1.26.2)
Requirement already satisfied: packaging in e:\anaconda\lib\site-packages (from tensorboard) (23.2)
Requirement already satisfied: protobuf!=4.24.0,>=3.19.6 in e:\anaconda\lib\site-packages (from tensorboard) (3.20.3)
Requirement already satisfied: setuptools>=41.0.0 in e:\anaconda\lib\site-packages (from tensorboard) (69.5.1)
Requirement already satisfied: six>1.9 in e:\anaconda\lib\site-packages (from tensorboard) (1.16.0)
Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in c:\users\26336\appdata\roaming\python\python312\site-packages (from tensorboard) (0.7.2)
Requirement already satisfied: werkzeug>=1.0.1 in e:\anaconda\lib\site-packages (from tensorboard) (3.0.3)
Requirement already satisfied: MarkupSafe>=2.1.1 in e:\anaconda\lib\site-packages (from werkzeug>=1.0.1->tensorboard) (2.1.3)

(base) C:\Users\26336\Desktop\FDU\神经网络\home_work_2>
(base) C:\Users\26336\Desktop\FDU\神经网络\home_work_2>
(base) C:\Users\26336\Desktop\FDU\神经网络\home_work_2>
(base) C:\Users\26336\Desktop\FDU\神经网络\home_work_2>
(base) C:\Users\26336\Desktop\FDU\神经网络\home_work_2>python -m tensorboard.main --logdir=runs
TensorFlow installation not found - running with reduced feature set.
Serving TensorBoard on localhost; to expose to the network, use a proxy or pass --bind_all
TensorBoard 2.19.0 at http://localhost:6006/ (Press CTRL+C to quit)
W0521 20:49:19.631838  2896 plugin_event_multiplexer.py:267] Deleting accumulator 'caltech101_resnet18_scratch'
W0521 20:50:15.716310  2896 plugin_event_multiplexer.py:267] Deleting accumulator 'caltech101_resnet18_pretrained'
^C
(base) C:\Users\26336\Desktop\FDU\神经网络\home_work_2>

(base) C:\Users\26336\Desktop\FDU\神经网络\home_work_2>
(base) C:\Users\26336\Desktop\FDU\神经网络\home_work_2>
(base) C:\Users\26336\Desktop\FDU\神经网络\home_work_2>
(base) C:\Users\26336\Desktop\FDU\神经网络\home_work_2>
(base) C:\Users\26336\Desktop\FDU\神经网络\home_work_2>python main.py
Training with pretrained weights...
Number of classes: 102
Class names: ['BACKGROUND_Google', 'Faces', 'Faces_easy', 'Leopards', 'Motorbikes', 'accordion', 'airplanes', 'anchor', 'ant', 'barrel', 'bass', 'beaver', 'binocular', 'bonsai', 'brain', 'brontosaurus', 'buddha', 'butterfly', 'camera', 'cannon', 'car_side', 'ceiling_fan', 'cellphone', 'chair', 'chandelier', 'cougar_body', 'cougar_face', 'crab', 'crayfish', 'crocodile', 'crocodile_head', 'cup', 'dalmatian', 'dollar_bill', 'dolphin', 'dragonfly', 'electric_guitar', 'elephant', 'emu', 'euphonium', 'ewer', 'ferry', 'flamingo', 'flamingo_head', 'garfield', 'gerenuk', 'gramophone', 'grand_piano', 'hawksbill', 'headphone', 'hedgehog', 'helicopter', 'ibis', 'inline_skate', 'joshua_tree', 'kangaroo', 'ketch', 'lamp', 'laptop', 'llama', 'lobster', 'lotus', 'mandolin', 'mayfly', 'menorah', 'metronome', 'minaret', 'nautilus', 'octopus', 'okapi', 'pagoda', 'panda', 'pigeon', 'pizza', 'platypus', 'pyramid', 'revolver', 'rhino', 'rooster', 'saxophone', 'schooner', 'scissors', 'scorpion', 'sea_horse', 'snoopy', 'soccer_ball', 'stapler', 'starfish', 'stegosaurus', 'stop_sign', 'strawberry', 'sunflower', 'tick', 'trilobite', 'umbrella', 'watch', 'water_lilly', 'wheelchair', 'wild_cat', 'windsor_chair', 'wrench', 'yin_yang']
Training samples: 7280
Validation samples: 1864
Epoch: 1/20 | Batch: 1/228 | Loss: 4.8541
Epoch: 1/20 | Batch: 11/228 | Loss: 3.9895
Epoch: 1/20 | Batch: 21/228 | Loss: 3.1345
Epoch: 1/20 | Batch: 31/228 | Loss: 2.5251
Epoch: 1/20 | Batch: 41/228 | Loss: 2.7014
Epoch: 1/20 | Batch: 51/228 | Loss: 2.4159
Epoch: 1/20 | Batch: 61/228 | Loss: 2.1033
Epoch: 1/20 | Batch: 71/228 | Loss: 2.0569
Epoch: 1/20 | Batch: 81/228 | Loss: 1.7604
Epoch: 1/20 | Batch: 91/228 | Loss: 1.6038
Epoch: 1/20 | Batch: 101/228 | Loss: 1.5000
Epoch: 1/20 | Batch: 111/228 | Loss: 1.6089
Epoch: 1/20 | Batch: 121/228 | Loss: 1.7311
Epoch: 1/20 | Batch: 131/228 | Loss: 1.6770
Epoch: 1/20 | Batch: 141/228 | Loss: 1.4257
Epoch: 1/20 | Batch: 151/228 | Loss: 1.3923
Epoch: 1/20 | Batch: 161/228 | Loss: 1.3056
Epoch: 1/20 | Batch: 171/228 | Loss: 1.1038
Epoch: 1/20 | Batch: 181/228 | Loss: 1.2691
Epoch: 1/20 | Batch: 191/228 | Loss: 1.0499
Epoch: 1/20 | Batch: 201/228 | Loss: 0.7442
Epoch: 1/20 | Batch: 211/228 | Loss: 1.1220
Epoch: 1/20 | Batch: 221/228 | Loss: 1.1434
Epoch: 1/20 | Train Loss: 1.7741 | Train Acc: 58.98% | Val Loss: 0.4927 | Val Acc: 86.53%
Current learning rate: 0.0001
Current learning rate: 0.0001
Current learning rate: 0.0001
Current learning rate: 0.0001
Current learning rate: 0.0001
Current learning rate: 0.0001
Current learning rate: 0.001
Best accuracy: 86.53%
Model saved to checkpoints\resnet18_pretrained_best.pth
Epoch: 2/20 | Batch: 1/228 | Loss: 1.3465
Epoch: 2/20 | Batch: 11/228 | Loss: 0.5196
Epoch: 2/20 | Batch: 21/228 | Loss: 0.5333
Epoch: 2/20 | Batch: 31/228 | Loss: 0.8827
Epoch: 2/20 | Batch: 41/228 | Loss: 0.6209
Epoch: 2/20 | Batch: 51/228 | Loss: 0.4369
Epoch: 2/20 | Batch: 61/228 | Loss: 1.1981
Epoch: 2/20 | Batch: 71/228 | Loss: 0.6018
Epoch: 2/20 | Batch: 81/228 | Loss: 0.5260
Epoch: 2/20 | Batch: 91/228 | Loss: 0.8467
Epoch: 2/20 | Batch: 101/228 | Loss: 1.1813
Epoch: 2/20 | Batch: 111/228 | Loss: 0.6492
Epoch: 2/20 | Batch: 121/228 | Loss: 0.9057
Epoch: 2/20 | Batch: 131/228 | Loss: 0.7409
Epoch: 2/20 | Batch: 141/228 | Loss: 0.8594
Epoch: 2/20 | Batch: 151/228 | Loss: 0.5296
Epoch: 2/20 | Batch: 161/228 | Loss: 0.7208
Epoch: 2/20 | Batch: 171/228 | Loss: 0.9160
Epoch: 2/20 | Batch: 181/228 | Loss: 0.7614
Epoch: 2/20 | Batch: 191/228 | Loss: 0.6671
Epoch: 2/20 | Batch: 201/228 | Loss: 1.1975
Epoch: 2/20 | Batch: 211/228 | Loss: 0.6378
Epoch: 2/20 | Batch: 221/228 | Loss: 0.6559
Epoch: 2/20 | Train Loss: 0.7589 | Train Acc: 80.00% | Val Loss: 0.3734 | Val Acc: 88.84%
Current learning rate: 0.0001
Current learning rate: 0.0001
Current learning rate: 0.0001
Current learning rate: 0.0001
Current learning rate: 0.0001
Current learning rate: 0.0001
Current learning rate: 0.001
Best accuracy: 88.84%
Model saved to checkpoints\resnet18_pretrained_best.pth
Epoch: 3/20 | Batch: 1/228 | Loss: 0.5788
Epoch: 3/20 | Batch: 11/228 | Loss: 0.6251
Epoch: 3/20 | Batch: 21/228 | Loss: 0.2312
Epoch: 3/20 | Batch: 31/228 | Loss: 0.2113
Epoch: 3/20 | Batch: 41/228 | Loss: 0.4892
Epoch: 3/20 | Batch: 51/228 | Loss: 0.6201
Epoch: 3/20 | Batch: 61/228 | Loss: 0.2914
Epoch: 3/20 | Batch: 71/228 | Loss: 0.3296
Epoch: 3/20 | Batch: 81/228 | Loss: 0.6704
Epoch: 3/20 | Batch: 91/228 | Loss: 0.4583
Epoch: 3/20 | Batch: 101/228 | Loss: 0.4062
Epoch: 3/20 | Batch: 111/228 | Loss: 0.5008
Epoch: 3/20 | Batch: 121/228 | Loss: 0.4457
Epoch: 3/20 | Batch: 131/228 | Loss: 0.9224
Epoch: 3/20 | Batch: 141/228 | Loss: 0.4886
Epoch: 3/20 | Batch: 151/228 | Loss: 0.4805
Epoch: 3/20 | Batch: 161/228 | Loss: 0.5009
Epoch: 3/20 | Batch: 171/228 | Loss: 1.0572
Epoch: 3/20 | Batch: 181/228 | Loss: 0.8944
Epoch: 3/20 | Batch: 191/228 | Loss: 0.5351
Epoch: 3/20 | Batch: 201/228 | Loss: 0.3635
Epoch: 3/20 | Batch: 211/228 | Loss: 0.5977
Epoch: 3/20 | Batch: 221/228 | Loss: 0.6396
Epoch: 3/20 | Train Loss: 0.5971 | Train Acc: 83.60% | Val Loss: 0.3434 | Val Acc: 89.54%
Current learning rate: 0.0001
Current learning rate: 0.0001
Current learning rate: 0.0001
Current learning rate: 0.0001
Current learning rate: 0.0001
Current learning rate: 0.0001
Current learning rate: 0.001
Best accuracy: 89.54%
Model saved to checkpoints\resnet18_pretrained_best.pth
Epoch: 4/20 | Batch: 1/228 | Loss: 0.6767
Epoch: 4/20 | Batch: 11/228 | Loss: 0.7391
Epoch: 4/20 | Batch: 21/228 | Loss: 0.4980
Epoch: 4/20 | Batch: 31/228 | Loss: 0.2834
Epoch: 4/20 | Batch: 41/228 | Loss: 0.3219
Epoch: 4/20 | Batch: 51/228 | Loss: 0.4993
Epoch: 4/20 | Batch: 61/228 | Loss: 0.3346
Epoch: 4/20 | Batch: 71/228 | Loss: 0.7195
Epoch: 4/20 | Batch: 81/228 | Loss: 0.2618
Epoch: 4/20 | Batch: 91/228 | Loss: 0.7614
Epoch: 4/20 | Batch: 101/228 | Loss: 0.5948
Epoch: 4/20 | Batch: 111/228 | Loss: 0.4946
Epoch: 4/20 | Batch: 121/228 | Loss: 0.3583
Epoch: 4/20 | Batch: 131/228 | Loss: 0.2433
Epoch: 4/20 | Batch: 141/228 | Loss: 0.8095
Epoch: 4/20 | Batch: 151/228 | Loss: 0.4809
Epoch: 4/20 | Batch: 161/228 | Loss: 0.2930
Epoch: 4/20 | Batch: 171/228 | Loss: 0.3721
Epoch: 4/20 | Batch: 181/228 | Loss: 0.3268
Epoch: 4/20 | Batch: 191/228 | Loss: 0.4786
Epoch: 4/20 | Batch: 201/228 | Loss: 0.7594
Epoch: 4/20 | Batch: 211/228 | Loss: 0.7468
Epoch: 4/20 | Batch: 221/228 | Loss: 0.8182
Epoch: 4/20 | Train Loss: 0.5590 | Train Acc: 84.31% | Val Loss: 0.3206 | Val Acc: 90.24%
Current learning rate: 0.0001
Current learning rate: 0.0001
Current learning rate: 0.0001
Current learning rate: 0.0001
Current learning rate: 0.0001
Current learning rate: 0.0001
Current learning rate: 0.001
Best accuracy: 90.24%
Model saved to checkpoints\resnet18_pretrained_best.pth
Epoch: 5/20 | Batch: 1/228 | Loss: 0.7684
Epoch: 5/20 | Batch: 11/228 | Loss: 0.9382
Epoch: 5/20 | Batch: 21/228 | Loss: 0.5794
Epoch: 5/20 | Batch: 31/228 | Loss: 0.4263
Epoch: 5/20 | Batch: 41/228 | Loss: 0.3210
Epoch: 5/20 | Batch: 51/228 | Loss: 0.3993
Epoch: 5/20 | Batch: 61/228 | Loss: 0.2647
Epoch: 5/20 | Batch: 71/228 | Loss: 0.4021
Epoch: 5/20 | Batch: 81/228 | Loss: 0.4775
Epoch: 5/20 | Batch: 91/228 | Loss: 0.4724
Epoch: 5/20 | Batch: 101/228 | Loss: 0.5215
Epoch: 5/20 | Batch: 111/228 | Loss: 0.4607
Epoch: 5/20 | Batch: 121/228 | Loss: 0.1206
Epoch: 5/20 | Batch: 131/228 | Loss: 0.5323
Epoch: 5/20 | Batch: 141/228 | Loss: 0.4084
Epoch: 5/20 | Batch: 151/228 | Loss: 0.8567
Epoch: 5/20 | Batch: 161/228 | Loss: 0.6063
Epoch: 5/20 | Batch: 171/228 | Loss: 0.5282
Epoch: 5/20 | Batch: 181/228 | Loss: 0.3522
Epoch: 5/20 | Batch: 191/228 | Loss: 0.3259
Epoch: 5/20 | Batch: 201/228 | Loss: 0.6333
Epoch: 5/20 | Batch: 211/228 | Loss: 0.5646
Epoch: 5/20 | Batch: 221/228 | Loss: 0.4121
Epoch: 5/20 | Train Loss: 0.4875 | Train Acc: 86.54% | Val Loss: 0.3385 | Val Acc: 90.45%
Current learning rate: 0.0001
Current learning rate: 0.0001
Current learning rate: 0.0001
Current learning rate: 0.0001
Current learning rate: 0.0001
Current learning rate: 0.0001
Current learning rate: 0.001
Best accuracy: 90.45%
Model saved to checkpoints\resnet18_pretrained_best.pth
Epoch: 6/20 | Batch: 1/228 | Loss: 0.2835
Epoch: 6/20 | Batch: 11/228 | Loss: 0.5709
Epoch: 6/20 | Batch: 21/228 | Loss: 0.4445
Epoch: 6/20 | Batch: 31/228 | Loss: 0.2500
Epoch: 6/20 | Batch: 41/228 | Loss: 0.3139
Epoch: 6/20 | Batch: 51/228 | Loss: 0.1748
Epoch: 6/20 | Batch: 61/228 | Loss: 0.2345
Epoch: 6/20 | Batch: 71/228 | Loss: 0.4914
Epoch: 6/20 | Batch: 81/228 | Loss: 0.5457
Epoch: 6/20 | Batch: 91/228 | Loss: 0.4878
Epoch: 6/20 | Batch: 101/228 | Loss: 0.2873
Epoch: 6/20 | Batch: 111/228 | Loss: 0.3407
Epoch: 6/20 | Batch: 121/228 | Loss: 0.3996
Epoch: 6/20 | Batch: 131/228 | Loss: 0.4019
Epoch: 6/20 | Batch: 141/228 | Loss: 1.1723
Epoch: 6/20 | Batch: 151/228 | Loss: 0.2764
Epoch: 6/20 | Batch: 161/228 | Loss: 0.6482
Epoch: 6/20 | Batch: 171/228 | Loss: 0.3491
Epoch: 6/20 | Batch: 181/228 | Loss: 0.5424
Epoch: 6/20 | Batch: 191/228 | Loss: 0.3102
Epoch: 6/20 | Batch: 201/228 | Loss: 0.7232
Epoch: 6/20 | Batch: 211/228 | Loss: 0.3116
Epoch: 6/20 | Batch: 221/228 | Loss: 0.7444
Epoch: 6/20 | Train Loss: 0.4633 | Train Acc: 86.65% | Val Loss: 0.3148 | Val Acc: 90.72%
Current learning rate: 0.0001
Current learning rate: 0.0001
Current learning rate: 0.0001
Current learning rate: 0.0001
Current learning rate: 0.0001
Current learning rate: 0.0001
Current learning rate: 0.001
Best accuracy: 90.72%
Model saved to checkpoints\resnet18_pretrained_best.pth
Epoch: 7/20 | Batch: 1/228 | Loss: 0.2376
Epoch: 7/20 | Batch: 11/228 | Loss: 0.3166
Epoch: 7/20 | Batch: 21/228 | Loss: 0.4269
Epoch: 7/20 | Batch: 31/228 | Loss: 0.4561
Epoch: 7/20 | Batch: 41/228 | Loss: 0.4882
Epoch: 7/20 | Batch: 51/228 | Loss: 0.4557
Epoch: 7/20 | Batch: 61/228 | Loss: 0.3665
Epoch: 7/20 | Batch: 71/228 | Loss: 0.3193
Epoch: 7/20 | Batch: 81/228 | Loss: 0.2251
Epoch: 7/20 | Batch: 91/228 | Loss: 0.3741
Epoch: 7/20 | Batch: 101/228 | Loss: 0.4603
Epoch: 7/20 | Batch: 111/228 | Loss: 0.3361
Epoch: 7/20 | Batch: 121/228 | Loss: 0.3242
Epoch: 7/20 | Batch: 131/228 | Loss: 0.5533
Epoch: 7/20 | Batch: 141/228 | Loss: 0.6145
Epoch: 7/20 | Batch: 151/228 | Loss: 0.4651
Epoch: 7/20 | Batch: 161/228 | Loss: 0.1664
Epoch: 7/20 | Batch: 171/228 | Loss: 0.5323
Epoch: 7/20 | Batch: 181/228 | Loss: 0.4671
Epoch: 7/20 | Batch: 191/228 | Loss: 0.4135
Epoch: 7/20 | Batch: 201/228 | Loss: 0.3677
Epoch: 7/20 | Batch: 211/228 | Loss: 0.3583
Epoch: 7/20 | Batch: 221/228 | Loss: 0.1524
Epoch: 7/20 | Train Loss: 0.4330 | Train Acc: 87.25% | Val Loss: 0.3380 | Val Acc: 89.75%
Current learning rate: 0.0001
Current learning rate: 0.0001
Current learning rate: 0.0001
Current learning rate: 0.0001
Current learning rate: 0.0001
Current learning rate: 0.0001
Current learning rate: 0.001
Epoch: 8/20 | Batch: 1/228 | Loss: 0.3093
Epoch: 8/20 | Batch: 11/228 | Loss: 0.1818
Epoch: 8/20 | Batch: 21/228 | Loss: 0.1988
Epoch: 8/20 | Batch: 31/228 | Loss: 0.3958
Epoch: 8/20 | Batch: 41/228 | Loss: 0.5106
Epoch: 8/20 | Batch: 51/228 | Loss: 0.2830
Epoch: 8/20 | Batch: 61/228 | Loss: 0.1768
Epoch: 8/20 | Batch: 71/228 | Loss: 0.1692
Epoch: 8/20 | Batch: 81/228 | Loss: 0.4146
Epoch: 8/20 | Batch: 91/228 | Loss: 0.4251
Epoch: 8/20 | Batch: 101/228 | Loss: 0.5851
Epoch: 8/20 | Batch: 111/228 | Loss: 0.2198
Epoch: 8/20 | Batch: 121/228 | Loss: 0.2788
Epoch: 8/20 | Batch: 131/228 | Loss: 0.5870
Epoch: 8/20 | Batch: 141/228 | Loss: 0.6584
Epoch: 8/20 | Batch: 151/228 | Loss: 0.8862
Epoch: 8/20 | Batch: 161/228 | Loss: 0.2133
Epoch: 8/20 | Batch: 171/228 | Loss: 0.3139
Epoch: 8/20 | Batch: 181/228 | Loss: 0.7100
Epoch: 8/20 | Batch: 191/228 | Loss: 0.3588
Epoch: 8/20 | Batch: 201/228 | Loss: 0.5465
Epoch: 8/20 | Batch: 211/228 | Loss: 0.6897
Epoch: 8/20 | Batch: 221/228 | Loss: 0.4290
Epoch: 8/20 | Train Loss: 0.4127 | Train Acc: 88.46% | Val Loss: 0.3282 | Val Acc: 90.83%
Current learning rate: 0.0001
Current learning rate: 0.0001
Current learning rate: 0.0001
Current learning rate: 0.0001
Current learning rate: 0.0001
Current learning rate: 0.0001
Current learning rate: 0.001
Best accuracy: 90.83%
Model saved to checkpoints\resnet18_pretrained_best.pth
Epoch: 9/20 | Batch: 1/228 | Loss: 0.4733
Epoch: 9/20 | Batch: 11/228 | Loss: 0.8626
Epoch: 9/20 | Batch: 21/228 | Loss: 0.2613
Epoch: 9/20 | Batch: 31/228 | Loss: 0.1695
Epoch: 9/20 | Batch: 41/228 | Loss: 0.3225
Epoch: 9/20 | Batch: 51/228 | Loss: 0.7657
Epoch: 9/20 | Batch: 61/228 | Loss: 0.4671
Epoch: 9/20 | Batch: 71/228 | Loss: 0.2311
Epoch: 9/20 | Batch: 81/228 | Loss: 0.4334
Epoch: 9/20 | Batch: 91/228 | Loss: 0.2554
Epoch: 9/20 | Batch: 101/228 | Loss: 0.4164
Epoch: 9/20 | Batch: 111/228 | Loss: 0.2908
Epoch: 9/20 | Batch: 121/228 | Loss: 0.6377
Epoch: 9/20 | Batch: 131/228 | Loss: 0.1281
Epoch: 9/20 | Batch: 141/228 | Loss: 0.1140
Epoch: 9/20 | Batch: 151/228 | Loss: 0.5638
Epoch: 9/20 | Batch: 161/228 | Loss: 0.5638
Epoch: 9/20 | Batch: 171/228 | Loss: 0.9687
Epoch: 9/20 | Batch: 181/228 | Loss: 0.2092
Epoch: 9/20 | Batch: 191/228 | Loss: 0.2311
Epoch: 9/20 | Batch: 201/228 | Loss: 0.4419
Epoch: 9/20 | Batch: 211/228 | Loss: 0.5963
Epoch: 9/20 | Batch: 221/228 | Loss: 0.3393
Epoch: 9/20 | Train Loss: 0.4004 | Train Acc: 88.68% | Val Loss: 0.3259 | Val Acc: 90.29%
Current learning rate: 0.0001
Current learning rate: 0.0001
Current learning rate: 0.0001
Current learning rate: 0.0001
Current learning rate: 0.0001
Current learning rate: 0.0001
Current learning rate: 0.001
Epoch: 10/20 | Batch: 1/228 | Loss: 0.4176
Epoch: 10/20 | Batch: 11/228 | Loss: 0.1243
Epoch: 10/20 | Batch: 21/228 | Loss: 0.5311
Epoch: 10/20 | Batch: 31/228 | Loss: 0.0995
Epoch: 10/20 | Batch: 41/228 | Loss: 0.2319
Epoch: 10/20 | Batch: 51/228 | Loss: 0.1813
Epoch: 10/20 | Batch: 61/228 | Loss: 0.5779
Epoch: 10/20 | Batch: 71/228 | Loss: 0.2764
Epoch: 10/20 | Batch: 81/228 | Loss: 0.0880
Epoch: 10/20 | Batch: 91/228 | Loss: 0.3828
Epoch: 10/20 | Batch: 101/228 | Loss: 0.5370
Epoch: 10/20 | Batch: 111/228 | Loss: 0.1584
Epoch: 10/20 | Batch: 121/228 | Loss: 0.6089
Epoch: 10/20 | Batch: 131/228 | Loss: 0.4225
Epoch: 10/20 | Batch: 141/228 | Loss: 0.6509
Epoch: 10/20 | Batch: 151/228 | Loss: 0.2966
Epoch: 10/20 | Batch: 161/228 | Loss: 0.3500
Epoch: 10/20 | Batch: 171/228 | Loss: 0.4986
Epoch: 10/20 | Batch: 181/228 | Loss: 0.5152
Epoch: 10/20 | Batch: 191/228 | Loss: 0.3692
Epoch: 10/20 | Batch: 201/228 | Loss: 0.2685
Epoch: 10/20 | Batch: 211/228 | Loss: 0.3679
Epoch: 10/20 | Batch: 221/228 | Loss: 0.6197
Epoch: 10/20 | Train Loss: 0.3557 | Train Acc: 89.38% | Val Loss: 0.3406 | Val Acc: 89.75%
Current learning rate: 0.0001
Current learning rate: 0.0001
Current learning rate: 0.0001
Current learning rate: 0.0001
Current learning rate: 0.0001
Current learning rate: 0.0001
Current learning rate: 0.001
Epoch: 11/20 | Batch: 1/228 | Loss: 0.7013
Epoch: 11/20 | Batch: 11/228 | Loss: 0.1561
Epoch: 11/20 | Batch: 21/228 | Loss: 0.1756
Epoch: 11/20 | Batch: 31/228 | Loss: 0.6642
Epoch: 11/20 | Batch: 41/228 | Loss: 0.6539
Epoch: 11/20 | Batch: 51/228 | Loss: 0.2690
Epoch: 11/20 | Batch: 61/228 | Loss: 0.2733
Epoch: 11/20 | Batch: 71/228 | Loss: 0.5976
Epoch: 11/20 | Batch: 81/228 | Loss: 0.4614
Epoch: 11/20 | Batch: 91/228 | Loss: 0.2121
Epoch: 11/20 | Batch: 101/228 | Loss: 0.4382
Epoch: 11/20 | Batch: 111/228 | Loss: 0.3604
Epoch: 11/20 | Batch: 121/228 | Loss: 0.1741
Epoch: 11/20 | Batch: 131/228 | Loss: 0.6900
Epoch: 11/20 | Batch: 141/228 | Loss: 0.2508
Epoch: 11/20 | Batch: 151/228 | Loss: 0.5650
Epoch: 11/20 | Batch: 161/228 | Loss: 0.3523
Epoch: 11/20 | Batch: 171/228 | Loss: 0.1763
Epoch: 11/20 | Batch: 181/228 | Loss: 0.3678
Epoch: 11/20 | Batch: 191/228 | Loss: 0.3184
Epoch: 11/20 | Batch: 201/228 | Loss: 0.3377
Epoch: 11/20 | Batch: 211/228 | Loss: 0.1075
Epoch: 11/20 | Batch: 221/228 | Loss: 0.1964
Epoch: 11/20 | Train Loss: 0.3978 | Train Acc: 88.83% | Val Loss: 0.3377 | Val Acc: 90.18%
Current learning rate: 0.0001
Current learning rate: 0.0001
Current learning rate: 0.0001
Current learning rate: 0.0001
Current learning rate: 0.0001
Current learning rate: 0.0001
Current learning rate: 0.001
Epoch: 12/20 | Batch: 1/228 | Loss: 0.4577
Epoch: 12/20 | Batch: 11/228 | Loss: 0.4350
Epoch: 12/20 | Batch: 21/228 | Loss: 0.1171
Epoch: 12/20 | Batch: 31/228 | Loss: 0.8554
Epoch: 12/20 | Batch: 41/228 | Loss: 0.1278
Epoch: 12/20 | Batch: 51/228 | Loss: 0.3790
Epoch: 12/20 | Batch: 61/228 | Loss: 0.3406
Epoch: 12/20 | Batch: 71/228 | Loss: 0.3257
Epoch: 12/20 | Batch: 81/228 | Loss: 0.2244
Epoch: 12/20 | Batch: 91/228 | Loss: 0.6310
Epoch: 12/20 | Batch: 101/228 | Loss: 0.2791
Epoch: 12/20 | Batch: 111/228 | Loss: 0.3467
Epoch: 12/20 | Batch: 121/228 | Loss: 0.5143
Epoch: 12/20 | Batch: 131/228 | Loss: 0.3599
Epoch: 12/20 | Batch: 141/228 | Loss: 0.3789
Epoch: 12/20 | Batch: 151/228 | Loss: 0.4590
Epoch: 12/20 | Batch: 161/228 | Loss: 0.2063
Epoch: 12/20 | Batch: 171/228 | Loss: 0.5473
Epoch: 12/20 | Batch: 181/228 | Loss: 0.1890
Epoch: 12/20 | Batch: 191/228 | Loss: 0.6411
Epoch: 12/20 | Batch: 201/228 | Loss: 0.2922
Epoch: 12/20 | Batch: 211/228 | Loss: 0.2225
Epoch: 12/20 | Batch: 221/228 | Loss: 0.4952
Epoch: 12/20 | Train Loss: 0.3364 | Train Acc: 90.26% | Val Loss: 0.3533 | Val Acc: 90.24%
Current learning rate: 0.0001
Current learning rate: 0.0001
Current learning rate: 0.0001
Current learning rate: 0.0001
Current learning rate: 0.0001
Current learning rate: 0.0001
Current learning rate: 0.001
Epoch: 13/20 | Batch: 1/228 | Loss: 0.3184
Epoch: 13/20 | Batch: 11/228 | Loss: 0.2212
Epoch: 13/20 | Batch: 21/228 | Loss: 0.0988
Epoch: 13/20 | Batch: 31/228 | Loss: 0.1062
Epoch: 13/20 | Batch: 41/228 | Loss: 0.2375
Epoch: 13/20 | Batch: 51/228 | Loss: 0.4200
Epoch: 13/20 | Batch: 61/228 | Loss: 0.2888
Epoch: 13/20 | Batch: 71/228 | Loss: 0.2398
Epoch: 13/20 | Batch: 81/228 | Loss: 0.4458
Epoch: 13/20 | Batch: 91/228 | Loss: 0.7502
Epoch: 13/20 | Batch: 101/228 | Loss: 0.4803
Epoch: 13/20 | Batch: 111/228 | Loss: 0.2890
Epoch: 13/20 | Batch: 121/228 | Loss: 0.2711
Epoch: 13/20 | Batch: 131/228 | Loss: 0.2756
Epoch: 13/20 | Batch: 141/228 | Loss: 0.2914
Epoch: 13/20 | Batch: 151/228 | Loss: 0.4180
Epoch: 13/20 | Batch: 161/228 | Loss: 0.2466
Epoch: 13/20 | Batch: 171/228 | Loss: 0.1713
Epoch: 13/20 | Batch: 181/228 | Loss: 0.0942
Epoch: 13/20 | Batch: 191/228 | Loss: 0.4107
Epoch: 13/20 | Batch: 201/228 | Loss: 0.4582
Epoch: 13/20 | Batch: 211/228 | Loss: 0.2943
Epoch: 13/20 | Batch: 221/228 | Loss: 0.4342
Epoch: 13/20 | Train Loss: 0.3622 | Train Acc: 89.71% | Val Loss: 0.3830 | Val Acc: 89.86%
Current learning rate: 0.0001
Current learning rate: 0.0001
Current learning rate: 0.0001
Current learning rate: 0.0001
Current learning rate: 0.0001
Current learning rate: 0.0001
Current learning rate: 0.001
Epoch: 14/20 | Batch: 1/228 | Loss: 0.2353
Epoch: 14/20 | Batch: 11/228 | Loss: 0.0937
Epoch: 14/20 | Batch: 21/228 | Loss: 0.1077
Epoch: 14/20 | Batch: 31/228 | Loss: 0.6823
Epoch: 14/20 | Batch: 41/228 | Loss: 0.4061
Epoch: 14/20 | Batch: 51/228 | Loss: 0.2107
Epoch: 14/20 | Batch: 61/228 | Loss: 0.1820
Epoch: 14/20 | Batch: 71/228 | Loss: 0.6394
Epoch: 14/20 | Batch: 81/228 | Loss: 0.2558
Epoch: 14/20 | Batch: 91/228 | Loss: 0.2678
Epoch: 14/20 | Batch: 101/228 | Loss: 0.6826
Epoch: 14/20 | Batch: 111/228 | Loss: 0.3556
Epoch: 14/20 | Batch: 121/228 | Loss: 0.3943
Epoch: 14/20 | Batch: 131/228 | Loss: 0.4263
Epoch: 14/20 | Batch: 141/228 | Loss: 0.4070
Epoch: 14/20 | Batch: 151/228 | Loss: 0.1877
Epoch: 14/20 | Batch: 161/228 | Loss: 0.1661
Epoch: 14/20 | Batch: 171/228 | Loss: 0.0644
Epoch: 14/20 | Batch: 181/228 | Loss: 0.3430
Epoch: 14/20 | Batch: 191/228 | Loss: 0.1734
Epoch: 14/20 | Batch: 201/228 | Loss: 0.3628
Epoch: 14/20 | Batch: 211/228 | Loss: 0.6979
Epoch: 14/20 | Batch: 221/228 | Loss: 0.1767
Epoch: 14/20 | Train Loss: 0.3566 | Train Acc: 90.21% | Val Loss: 0.3572 | Val Acc: 90.67%
Current learning rate: 1e-05
Current learning rate: 1e-05
Current learning rate: 1e-05
Current learning rate: 1e-05
Current learning rate: 1e-05
Current learning rate: 1e-05
Current learning rate: 0.0001
Epoch: 15/20 | Batch: 1/228 | Loss: 0.1658
Epoch: 15/20 | Batch: 11/228 | Loss: 0.1665
Epoch: 15/20 | Batch: 21/228 | Loss: 0.4551
Epoch: 15/20 | Batch: 31/228 | Loss: 0.2010
Epoch: 15/20 | Batch: 41/228 | Loss: 0.2901
Epoch: 15/20 | Batch: 51/228 | Loss: 0.1828
Epoch: 15/20 | Batch: 61/228 | Loss: 0.2075
Epoch: 15/20 | Batch: 71/228 | Loss: 0.1353
Epoch: 15/20 | Batch: 81/228 | Loss: 0.2119
Epoch: 15/20 | Batch: 91/228 | Loss: 0.2398
Epoch: 15/20 | Batch: 101/228 | Loss: 0.0588
Epoch: 15/20 | Batch: 111/228 | Loss: 0.4086
Epoch: 15/20 | Batch: 121/228 | Loss: 0.4479
Epoch: 15/20 | Batch: 131/228 | Loss: 0.4351
Epoch: 15/20 | Batch: 141/228 | Loss: 0.0617
Epoch: 15/20 | Batch: 151/228 | Loss: 0.4106
Epoch: 15/20 | Batch: 161/228 | Loss: 0.2032
Epoch: 15/20 | Batch: 171/228 | Loss: 0.4023
Epoch: 15/20 | Batch: 181/228 | Loss: 0.1648
Epoch: 15/20 | Batch: 191/228 | Loss: 0.4808
Epoch: 15/20 | Batch: 201/228 | Loss: 0.0935
Epoch: 15/20 | Batch: 211/228 | Loss: 0.7962
Epoch: 15/20 | Batch: 221/228 | Loss: 0.5077
Epoch: 15/20 | Train Loss: 0.2713 | Train Acc: 92.51% | Val Loss: 0.2722 | Val Acc: 92.33%
Current learning rate: 1e-05
Current learning rate: 1e-05
Current learning rate: 1e-05
Current learning rate: 1e-05
Current learning rate: 1e-05
Current learning rate: 1e-05
Current learning rate: 0.0001
Best accuracy: 92.33%
Model saved to checkpoints\resnet18_pretrained_best.pth
Epoch: 16/20 | Batch: 1/228 | Loss: 0.0334
Epoch: 16/20 | Batch: 11/228 | Loss: 0.3413
Epoch: 16/20 | Batch: 21/228 | Loss: 0.6068
Epoch: 16/20 | Batch: 31/228 | Loss: 0.2609
Epoch: 16/20 | Batch: 41/228 | Loss: 0.1107
Epoch: 16/20 | Batch: 51/228 | Loss: 0.2770
Epoch: 16/20 | Batch: 61/228 | Loss: 0.1029
Epoch: 16/20 | Batch: 71/228 | Loss: 0.2310
Epoch: 16/20 | Batch: 81/228 | Loss: 0.2006
Epoch: 16/20 | Batch: 91/228 | Loss: 0.5990
Epoch: 16/20 | Batch: 101/228 | Loss: 0.2691
Epoch: 16/20 | Batch: 111/228 | Loss: 0.5077
Epoch: 16/20 | Batch: 121/228 | Loss: 0.4646
Epoch: 16/20 | Batch: 131/228 | Loss: 0.1874
Epoch: 16/20 | Batch: 141/228 | Loss: 0.4348
Epoch: 16/20 | Batch: 151/228 | Loss: 0.2496
Epoch: 16/20 | Batch: 161/228 | Loss: 0.1402
Epoch: 16/20 | Batch: 171/228 | Loss: 0.2776
Epoch: 16/20 | Batch: 181/228 | Loss: 0.4541
Epoch: 16/20 | Batch: 191/228 | Loss: 0.0537
Epoch: 16/20 | Batch: 201/228 | Loss: 0.3798
Epoch: 16/20 | Batch: 211/228 | Loss: 0.4117
Epoch: 16/20 | Batch: 221/228 | Loss: 0.1029
Epoch: 16/20 | Train Loss: 0.2682 | Train Acc: 92.34% | Val Loss: 0.2699 | Val Acc: 92.44%
Current learning rate: 1e-05
Current learning rate: 1e-05
Current learning rate: 1e-05
Current learning rate: 1e-05
Current learning rate: 1e-05
Current learning rate: 1e-05
Current learning rate: 0.0001
Best accuracy: 92.44%
Model saved to checkpoints\resnet18_pretrained_best.pth
Epoch: 17/20 | Batch: 1/228 | Loss: 0.1789
Epoch: 17/20 | Batch: 11/228 | Loss: 0.1854
Epoch: 17/20 | Batch: 21/228 | Loss: 0.0583
Epoch: 17/20 | Batch: 31/228 | Loss: 0.0413
Epoch: 17/20 | Batch: 41/228 | Loss: 0.4271
Epoch: 17/20 | Batch: 51/228 | Loss: 0.3838
Epoch: 17/20 | Batch: 61/228 | Loss: 0.2769
Epoch: 17/20 | Batch: 71/228 | Loss: 0.0386
Epoch: 17/20 | Batch: 81/228 | Loss: 0.1970
Epoch: 17/20 | Batch: 91/228 | Loss: 0.2876
Epoch: 17/20 | Batch: 101/228 | Loss: 0.3268
Epoch: 17/20 | Batch: 111/228 | Loss: 0.3123
Epoch: 17/20 | Batch: 121/228 | Loss: 0.1233
Epoch: 17/20 | Batch: 131/228 | Loss: 0.1462
Epoch: 17/20 | Batch: 141/228 | Loss: 0.2988
Epoch: 17/20 | Batch: 151/228 | Loss: 0.5748
Epoch: 17/20 | Batch: 161/228 | Loss: 0.0650
Epoch: 17/20 | Batch: 171/228 | Loss: 0.1856
Epoch: 17/20 | Batch: 181/228 | Loss: 0.2399
Epoch: 17/20 | Batch: 191/228 | Loss: 0.2101
Epoch: 17/20 | Batch: 201/228 | Loss: 0.4420
Epoch: 17/20 | Batch: 211/228 | Loss: 0.2359
Epoch: 17/20 | Batch: 221/228 | Loss: 0.4360
Epoch: 17/20 | Train Loss: 0.2340 | Train Acc: 93.21% | Val Loss: 0.2751 | Val Acc: 92.27%
Current learning rate: 1e-05
Current learning rate: 1e-05
Current learning rate: 1e-05
Current learning rate: 1e-05
Current learning rate: 1e-05
Current learning rate: 1e-05
Current learning rate: 0.0001
Epoch: 18/20 | Batch: 1/228 | Loss: 0.1230
Epoch: 18/20 | Batch: 11/228 | Loss: 0.4500
Epoch: 18/20 | Batch: 21/228 | Loss: 0.4640
Epoch: 18/20 | Batch: 31/228 | Loss: 0.2401
Epoch: 18/20 | Batch: 41/228 | Loss: 0.2568
Epoch: 18/20 | Batch: 51/228 | Loss: 0.3694
Epoch: 18/20 | Batch: 61/228 | Loss: 0.1753
Epoch: 18/20 | Batch: 71/228 | Loss: 0.2654
Epoch: 18/20 | Batch: 81/228 | Loss: 0.1423
Epoch: 18/20 | Batch: 91/228 | Loss: 0.1712
Epoch: 18/20 | Batch: 101/228 | Loss: 0.1424
Epoch: 18/20 | Batch: 111/228 | Loss: 0.1356
Epoch: 18/20 | Batch: 121/228 | Loss: 0.2510
Epoch: 18/20 | Batch: 131/228 | Loss: 0.1325
Epoch: 18/20 | Batch: 141/228 | Loss: 0.2743
Epoch: 18/20 | Batch: 151/228 | Loss: 0.2440
Epoch: 18/20 | Batch: 161/228 | Loss: 0.2150
Epoch: 18/20 | Batch: 171/228 | Loss: 0.1544
Epoch: 18/20 | Batch: 181/228 | Loss: 0.1716
Epoch: 18/20 | Batch: 191/228 | Loss: 0.1456
Epoch: 18/20 | Batch: 201/228 | Loss: 0.1177
Epoch: 18/20 | Batch: 211/228 | Loss: 0.1099
Epoch: 18/20 | Batch: 221/228 | Loss: 0.3058
Epoch: 18/20 | Train Loss: 0.2166 | Train Acc: 93.89% | Val Loss: 0.2599 | Val Acc: 92.76%
Current learning rate: 1e-05
Current learning rate: 1e-05
Current learning rate: 1e-05
Current learning rate: 1e-05
Current learning rate: 1e-05
Current learning rate: 1e-05
Current learning rate: 0.0001
Best accuracy: 92.76%
Model saved to checkpoints\resnet18_pretrained_best.pth
Epoch: 19/20 | Batch: 1/228 | Loss: 0.1802
Epoch: 19/20 | Batch: 11/228 | Loss: 0.0553
Epoch: 19/20 | Batch: 21/228 | Loss: 0.1407
Epoch: 19/20 | Batch: 31/228 | Loss: 0.2055
Epoch: 19/20 | Batch: 41/228 | Loss: 0.2622
Epoch: 19/20 | Batch: 51/228 | Loss: 0.0349
Epoch: 19/20 | Batch: 61/228 | Loss: 0.3545
Epoch: 19/20 | Batch: 71/228 | Loss: 0.3201
Epoch: 19/20 | Batch: 81/228 | Loss: 0.1572
Epoch: 19/20 | Batch: 91/228 | Loss: 0.2274
Epoch: 19/20 | Batch: 101/228 | Loss: 0.2551
Epoch: 19/20 | Batch: 111/228 | Loss: 0.1377
Epoch: 19/20 | Batch: 121/228 | Loss: 0.2940
Epoch: 19/20 | Batch: 131/228 | Loss: 0.0602
Epoch: 19/20 | Batch: 141/228 | Loss: 0.2026
Epoch: 19/20 | Batch: 151/228 | Loss: 0.2695
Epoch: 19/20 | Batch: 161/228 | Loss: 0.1784
Epoch: 19/20 | Batch: 171/228 | Loss: 0.2609
Epoch: 19/20 | Batch: 181/228 | Loss: 0.0910
Epoch: 19/20 | Batch: 191/228 | Loss: 0.2011
Epoch: 19/20 | Batch: 201/228 | Loss: 0.0587
Epoch: 19/20 | Batch: 211/228 | Loss: 0.3060
Epoch: 19/20 | Batch: 221/228 | Loss: 0.0256
Epoch: 19/20 | Train Loss: 0.2321 | Train Acc: 93.38% | Val Loss: 0.2549 | Val Acc: 92.76%
Current learning rate: 1e-05
Current learning rate: 1e-05
Current learning rate: 1e-05
Current learning rate: 1e-05
Current learning rate: 1e-05
Current learning rate: 1e-05
Current learning rate: 0.0001
Epoch: 20/20 | Batch: 1/228 | Loss: 0.1859
Epoch: 20/20 | Batch: 11/228 | Loss: 0.1269
Epoch: 20/20 | Batch: 21/228 | Loss: 0.2914
Epoch: 20/20 | Batch: 31/228 | Loss: 0.1813
Epoch: 20/20 | Batch: 41/228 | Loss: 0.1427
Epoch: 20/20 | Batch: 51/228 | Loss: 0.1894
Epoch: 20/20 | Batch: 61/228 | Loss: 0.0808
Epoch: 20/20 | Batch: 71/228 | Loss: 0.1338
Epoch: 20/20 | Batch: 81/228 | Loss: 0.2651
Epoch: 20/20 | Batch: 91/228 | Loss: 0.1841
Epoch: 20/20 | Batch: 101/228 | Loss: 0.3961
Epoch: 20/20 | Batch: 111/228 | Loss: 0.2138
Epoch: 20/20 | Batch: 121/228 | Loss: 0.2389
Epoch: 20/20 | Batch: 131/228 | Loss: 0.2729
Epoch: 20/20 | Batch: 141/228 | Loss: 0.2614
Epoch: 20/20 | Batch: 151/228 | Loss: 0.0734
Epoch: 20/20 | Batch: 161/228 | Loss: 0.1695
Epoch: 20/20 | Batch: 171/228 | Loss: 0.0392
Epoch: 20/20 | Batch: 181/228 | Loss: 0.3999
Epoch: 20/20 | Batch: 191/228 | Loss: 0.2223
Epoch: 20/20 | Batch: 201/228 | Loss: 0.1871
Epoch: 20/20 | Batch: 211/228 | Loss: 0.1080
Epoch: 20/20 | Batch: 221/228 | Loss: 0.1092
Epoch: 20/20 | Train Loss: 0.2103 | Train Acc: 93.89% | Val Loss: 0.2484 | Val Acc: 93.40%
Current learning rate: 1e-05
Current learning rate: 1e-05
Current learning rate: 1e-05
Current learning rate: 1e-05
Current learning rate: 1e-05
Current learning rate: 1e-05
Current learning rate: 0.0001
Best accuracy: 93.40%
Model saved to checkpoints\resnet18_pretrained_best.pth

(base) C:\Users\26336\Desktop\FDU\神经网络\home_work_2>
(base) C:\Users\26336\Desktop\FDU\神经网络\home_work_2>
(base) C:\Users\26336\Desktop\FDU\神经网络\home_work_2>
(base) C:\Users\26336\Desktop\FDU\神经网络\home_work_2>python -m tensorboard.main --logdir=runs
TensorFlow installation not found - running with reduced feature set.
Serving TensorBoard on localhost; to expose to the network, use a proxy or pass --bind_all
TensorBoard 2.19.0 at http://localhost:6006/ (Press CTRL+C to quit)
^C
(base) C:\Users\26336\Desktop\FDU\神经网络\home_work_2>

(base) C:\Users\26336\Desktop\FDU\神经网络\home_work_2>

(base) C:\Users\26336\Desktop\FDU\神经网络\home_work_2>

(base) C:\Users\26336\Desktop\FDU\神经网络\home_work_2>

(base) C:\Users\26336\Desktop\FDU\神经网络\home_work_2>

(base) C:\Users\26336\Desktop\FDU\神经网络\home_work_2>
(base) C:\Users\26336\Desktop\FDU\神经网络\home_work_2>
(base) C:\Users\26336\Desktop\FDU\神经网络\home_work_2>python main.py
Training with pretrained weights...
Number of classes: 102
Class names: ['BACKGROUND_Google', 'Faces', 'Faces_easy', 'Leopards', 'Motorbikes', 'accordion', 'airplanes', 'anchor', 'ant', 'barrel', 'bass', 'beaver', 'binocular', 'bonsai', 'brain', 'brontosaurus', 'buddha', 'butterfly', 'camera', 'cannon', 'car_side', 'ceiling_fan', 'cellphone', 'chair', 'chandelier', 'cougar_body', 'cougar_face', 'crab', 'crayfish', 'crocodile', 'crocodile_head', 'cup', 'dalmatian', 'dollar_bill', 'dolphin', 'dragonfly', 'electric_guitar', 'elephant', 'emu', 'euphonium', 'ewer', 'ferry', 'flamingo', 'flamingo_head', 'garfield', 'gerenuk', 'gramophone', 'grand_piano', 'hawksbill', 'headphone', 'hedgehog', 'helicopter', 'ibis', 'inline_skate', 'joshua_tree', 'kangaroo', 'ketch', 'lamp', 'laptop', 'llama', 'lobster', 'lotus', 'mandolin', 'mayfly', 'menorah', 'metronome', 'minaret', 'nautilus', 'octopus', 'okapi', 'pagoda', 'panda', 'pigeon', 'pizza', 'platypus', 'pyramid', 'revolver', 'rhino', 'rooster', 'saxophone', 'schooner', 'scissors', 'scorpion', 'sea_horse', 'snoopy', 'soccer_ball', 'stapler', 'starfish', 'stegosaurus', 'stop_sign', 'strawberry', 'sunflower', 'tick', 'trilobite', 'umbrella', 'watch', 'water_lilly', 'wheelchair', 'wild_cat', 'windsor_chair', 'wrench', 'yin_yang']
Training samples: 7280
Validation samples: 1864
Epoch: 1/20 | Batch: 1/455 | Loss: 5.1941
Epoch: 1/20 | Batch: 11/455 | Loss: 5.1061
Epoch: 1/20 | Batch: 21/455 | Loss: 3.5560
Epoch: 1/20 | Batch: 31/455 | Loss: 2.7635
Epoch: 1/20 | Batch: 41/455 | Loss: 2.8255
Epoch: 1/20 | Batch: 51/455 | Loss: 2.6932
Epoch: 1/20 | Batch: 61/455 | Loss: 2.6187
Epoch: 1/20 | Batch: 71/455 | Loss: 3.4120
Epoch: 1/20 | Batch: 81/455 | Loss: 2.5798
Epoch: 1/20 | Batch: 91/455 | Loss: 2.5353
Epoch: 1/20 | Batch: 101/455 | Loss: 2.8361
Epoch: 1/20 | Batch: 111/455 | Loss: 2.0710
Epoch: 1/20 | Batch: 121/455 | Loss: 2.3435
Epoch: 1/20 | Batch: 131/455 | Loss: 2.6493
Epoch: 1/20 | Batch: 141/455 | Loss: 1.8313
Epoch: 1/20 | Batch: 151/455 | Loss: 1.6830
Epoch: 1/20 | Batch: 161/455 | Loss: 1.3948
Epoch: 1/20 | Batch: 171/455 | Loss: 1.4334
Epoch: 1/20 | Batch: 181/455 | Loss: 1.3605
Epoch: 1/20 | Batch: 191/455 | Loss: 1.1651
Epoch: 1/20 | Batch: 201/455 | Loss: 1.1548
Epoch: 1/20 | Batch: 211/455 | Loss: 1.3184
Epoch: 1/20 | Batch: 221/455 | Loss: 0.9407
Epoch: 1/20 | Batch: 231/455 | Loss: 1.3619
Epoch: 1/20 | Batch: 241/455 | Loss: 1.2797
Epoch: 1/20 | Batch: 251/455 | Loss: 1.3142
Epoch: 1/20 | Batch: 261/455 | Loss: 1.0650
Epoch: 1/20 | Batch: 271/455 | Loss: 1.2649
Epoch: 1/20 | Batch: 281/455 | Loss: 1.2872
Epoch: 1/20 | Batch: 291/455 | Loss: 1.1311
Epoch: 1/20 | Batch: 301/455 | Loss: 0.3912
Epoch: 1/20 | Batch: 311/455 | Loss: 1.5278
Epoch: 1/20 | Batch: 321/455 | Loss: 0.6430
Epoch: 1/20 | Batch: 331/455 | Loss: 1.6184
Epoch: 1/20 | Batch: 341/455 | Loss: 0.9990
Epoch: 1/20 | Batch: 351/455 | Loss: 0.8832
Epoch: 1/20 | Batch: 361/455 | Loss: 1.5879
Epoch: 1/20 | Batch: 371/455 | Loss: 1.4842
Epoch: 1/20 | Batch: 381/455 | Loss: 1.4486
Epoch: 1/20 | Batch: 391/455 | Loss: 1.7461
Epoch: 1/20 | Batch: 401/455 | Loss: 0.9901
Epoch: 1/20 | Batch: 411/455 | Loss: 1.7159
Epoch: 1/20 | Batch: 421/455 | Loss: 1.2219
Epoch: 1/20 | Batch: 431/455 | Loss: 0.4864
Epoch: 1/20 | Batch: 441/455 | Loss: 0.8358
Epoch: 1/20 | Batch: 451/455 | Loss: 1.4955
Epoch: 1/20 | Train Loss: 1.7698 | Train Acc: 58.45% | Val Loss: 0.5317 | Val Acc: 85.09%
Current learning rate: 0.0001
Current learning rate: 0.0001
Current learning rate: 0.0001
Current learning rate: 0.0001
Current learning rate: 0.0001
Current learning rate: 0.0001
Current learning rate: 0.001
Best accuracy: 85.09%
Model saved to checkpoints\resnet18_pretrained_best.pth
Epoch: 2/20 | Batch: 1/455 | Loss: 0.6229
Epoch: 2/20 | Batch: 11/455 | Loss: 0.7706
Epoch: 2/20 | Batch: 21/455 | Loss: 0.8046
Epoch: 2/20 | Batch: 31/455 | Loss: 0.8326
Epoch: 2/20 | Batch: 41/455 | Loss: 1.2443
Epoch: 2/20 | Batch: 51/455 | Loss: 1.2271
Epoch: 2/20 | Batch: 61/455 | Loss: 0.8061
Epoch: 2/20 | Batch: 71/455 | Loss: 1.4314
Epoch: 2/20 | Batch: 81/455 | Loss: 0.9894
Epoch: 2/20 | Batch: 91/455 | Loss: 1.1035
Epoch: 2/20 | Batch: 101/455 | Loss: 1.3688
Epoch: 2/20 | Batch: 111/455 | Loss: 0.9705
Epoch: 2/20 | Batch: 121/455 | Loss: 1.0728
Epoch: 2/20 | Batch: 131/455 | Loss: 0.8641
Epoch: 2/20 | Batch: 141/455 | Loss: 0.9169
Epoch: 2/20 | Batch: 151/455 | Loss: 0.9680
Epoch: 2/20 | Batch: 161/455 | Loss: 0.8390
Epoch: 2/20 | Batch: 171/455 | Loss: 0.5386
Epoch: 2/20 | Batch: 181/455 | Loss: 0.4902
Epoch: 2/20 | Batch: 191/455 | Loss: 0.6555
Epoch: 2/20 | Batch: 201/455 | Loss: 1.0709
Epoch: 2/20 | Batch: 211/455 | Loss: 1.5445
Epoch: 2/20 | Batch: 221/455 | Loss: 1.1699
Epoch: 2/20 | Batch: 231/455 | Loss: 0.7470
Epoch: 2/20 | Batch: 241/455 | Loss: 1.4576
Epoch: 2/20 | Batch: 251/455 | Loss: 0.9430
Epoch: 2/20 | Batch: 261/455 | Loss: 1.0977
Epoch: 2/20 | Batch: 271/455 | Loss: 0.3564
Epoch: 2/20 | Batch: 281/455 | Loss: 1.1197
Epoch: 2/20 | Batch: 291/455 | Loss: 0.9924
Epoch: 2/20 | Batch: 301/455 | Loss: 1.1046
Epoch: 2/20 | Batch: 311/455 | Loss: 0.9890
Epoch: 2/20 | Batch: 321/455 | Loss: 0.7757
Epoch: 2/20 | Batch: 331/455 | Loss: 0.9902
Epoch: 2/20 | Batch: 341/455 | Loss: 0.5054
Epoch: 2/20 | Batch: 351/455 | Loss: 1.5849
Epoch: 2/20 | Batch: 361/455 | Loss: 1.5028
Epoch: 2/20 | Batch: 371/455 | Loss: 1.1880
Epoch: 2/20 | Batch: 381/455 | Loss: 0.3691
Epoch: 2/20 | Batch: 391/455 | Loss: 0.8548
Epoch: 2/20 | Batch: 401/455 | Loss: 0.7058
Epoch: 2/20 | Batch: 411/455 | Loss: 0.2464
Epoch: 2/20 | Batch: 421/455 | Loss: 0.6720
Epoch: 2/20 | Batch: 431/455 | Loss: 0.9714
Epoch: 2/20 | Batch: 441/455 | Loss: 1.0427
Epoch: 2/20 | Batch: 451/455 | Loss: 0.5177
Epoch: 2/20 | Train Loss: 0.8975 | Train Acc: 75.78% | Val Loss: 0.4333 | Val Acc: 87.61%
Current learning rate: 0.0001
Current learning rate: 0.0001
Current learning rate: 0.0001
Current learning rate: 0.0001
Current learning rate: 0.0001
Current learning rate: 0.0001
Current learning rate: 0.001
Best accuracy: 87.61%
Model saved to checkpoints\resnet18_pretrained_best.pth
Epoch: 3/20 | Batch: 1/455 | Loss: 0.7591
Epoch: 3/20 | Batch: 11/455 | Loss: 0.5188
Epoch: 3/20 | Batch: 21/455 | Loss: 0.8395
Epoch: 3/20 | Batch: 31/455 | Loss: 0.8910
Epoch: 3/20 | Batch: 41/455 | Loss: 1.0288
Epoch: 3/20 | Batch: 51/455 | Loss: 0.5414
Epoch: 3/20 | Batch: 61/455 | Loss: 0.9431
Epoch: 3/20 | Batch: 71/455 | Loss: 1.6819
Epoch: 3/20 | Batch: 81/455 | Loss: 0.7072
Epoch: 3/20 | Batch: 91/455 | Loss: 0.8952
Epoch: 3/20 | Batch: 101/455 | Loss: 0.5878
Epoch: 3/20 | Batch: 111/455 | Loss: 0.6513
Epoch: 3/20 | Batch: 121/455 | Loss: 0.6003
Epoch: 3/20 | Batch: 131/455 | Loss: 0.9083
Epoch: 3/20 | Batch: 141/455 | Loss: 1.0420
Epoch: 3/20 | Batch: 151/455 | Loss: 0.6941
Epoch: 3/20 | Batch: 161/455 | Loss: 0.5738
Epoch: 3/20 | Batch: 171/455 | Loss: 1.6676
Epoch: 3/20 | Batch: 181/455 | Loss: 1.3184
Epoch: 3/20 | Batch: 191/455 | Loss: 0.7550
Epoch: 3/20 | Batch: 201/455 | Loss: 0.6954
Epoch: 3/20 | Batch: 211/455 | Loss: 0.5248
Epoch: 3/20 | Batch: 221/455 | Loss: 0.8236
Epoch: 3/20 | Batch: 231/455 | Loss: 0.5926
Epoch: 3/20 | Batch: 241/455 | Loss: 0.2231
Epoch: 3/20 | Batch: 251/455 | Loss: 0.6727
Epoch: 3/20 | Batch: 261/455 | Loss: 0.3843
Epoch: 3/20 | Batch: 271/455 | Loss: 0.5550
Epoch: 3/20 | Batch: 281/455 | Loss: 0.9399
Epoch: 3/20 | Batch: 291/455 | Loss: 1.1908
Epoch: 3/20 | Batch: 301/455 | Loss: 0.8170
Epoch: 3/20 | Batch: 311/455 | Loss: 0.9063
Epoch: 3/20 | Batch: 321/455 | Loss: 1.5547
Epoch: 3/20 | Batch: 331/455 | Loss: 1.0512
Epoch: 3/20 | Batch: 341/455 | Loss: 1.1173
Epoch: 3/20 | Batch: 351/455 | Loss: 0.3235
Epoch: 3/20 | Batch: 361/455 | Loss: 0.9910
Epoch: 3/20 | Batch: 371/455 | Loss: 0.3584
Epoch: 3/20 | Batch: 381/455 | Loss: 0.6853
Epoch: 3/20 | Batch: 391/455 | Loss: 0.5141
Epoch: 3/20 | Batch: 401/455 | Loss: 1.2409
Epoch: 3/20 | Batch: 411/455 | Loss: 0.5639
Epoch: 3/20 | Batch: 421/455 | Loss: 0.6193
Epoch: 3/20 | Batch: 431/455 | Loss: 0.5442
Epoch: 3/20 | Batch: 441/455 | Loss: 0.3578
Epoch: 3/20 | Batch: 451/455 | Loss: 0.5424
Epoch: 3/20 | Train Loss: 0.7366 | Train Acc: 80.08% | Val Loss: 0.4060 | Val Acc: 88.04%
Current learning rate: 0.0001
Current learning rate: 0.0001
Current learning rate: 0.0001
Current learning rate: 0.0001
Current learning rate: 0.0001
Current learning rate: 0.0001
Current learning rate: 0.001
Best accuracy: 88.04%
Model saved to checkpoints\resnet18_pretrained_best.pth
Epoch: 4/20 | Batch: 1/455 | Loss: 0.8044
Epoch: 4/20 | Batch: 11/455 | Loss: 0.9294
Epoch: 4/20 | Batch: 21/455 | Loss: 0.6726
Epoch: 4/20 | Batch: 31/455 | Loss: 0.4916
Epoch: 4/20 | Batch: 41/455 | Loss: 0.9223
Epoch: 4/20 | Batch: 51/455 | Loss: 0.9860
Epoch: 4/20 | Batch: 61/455 | Loss: 0.4671
Epoch: 4/20 | Batch: 71/455 | Loss: 1.5467
Epoch: 4/20 | Batch: 81/455 | Loss: 0.6308
Epoch: 4/20 | Batch: 91/455 | Loss: 0.5611
Epoch: 4/20 | Batch: 101/455 | Loss: 0.2735
Epoch: 4/20 | Batch: 111/455 | Loss: 0.9919
Epoch: 4/20 | Batch: 121/455 | Loss: 0.3029
Epoch: 4/20 | Batch: 131/455 | Loss: 0.5862
Epoch: 4/20 | Batch: 141/455 | Loss: 0.1430
Epoch: 4/20 | Batch: 151/455 | Loss: 1.1445
Epoch: 4/20 | Batch: 161/455 | Loss: 0.7221
Epoch: 4/20 | Batch: 171/455 | Loss: 0.6398
Epoch: 4/20 | Batch: 181/455 | Loss: 0.7723
Epoch: 4/20 | Batch: 191/455 | Loss: 0.6140
Epoch: 4/20 | Batch: 201/455 | Loss: 0.1376
Epoch: 4/20 | Batch: 211/455 | Loss: 0.6029
Epoch: 4/20 | Batch: 221/455 | Loss: 1.1184
Epoch: 4/20 | Batch: 231/455 | Loss: 0.3040
Epoch: 4/20 | Batch: 241/455 | Loss: 1.2264
Epoch: 4/20 | Batch: 251/455 | Loss: 0.3155
Epoch: 4/20 | Batch: 261/455 | Loss: 0.3709
Epoch: 4/20 | Batch: 271/455 | Loss: 0.4225
Epoch: 4/20 | Batch: 281/455 | Loss: 0.3550
Epoch: 4/20 | Batch: 291/455 | Loss: 1.8068
Epoch: 4/20 | Batch: 301/455 | Loss: 0.5925
Epoch: 4/20 | Batch: 311/455 | Loss: 1.2026
Epoch: 4/20 | Batch: 321/455 | Loss: 0.9674
Epoch: 4/20 | Batch: 331/455 | Loss: 0.6442
Epoch: 4/20 | Batch: 341/455 | Loss: 1.0495
Epoch: 4/20 | Batch: 351/455 | Loss: 1.2692
Epoch: 4/20 | Batch: 361/455 | Loss: 0.7365
Epoch: 4/20 | Batch: 371/455 | Loss: 0.9481
Epoch: 4/20 | Batch: 381/455 | Loss: 1.4628
Epoch: 4/20 | Batch: 391/455 | Loss: 1.0161
Epoch: 4/20 | Batch: 401/455 | Loss: 0.9269
Epoch: 4/20 | Batch: 411/455 | Loss: 0.3338
Epoch: 4/20 | Batch: 421/455 | Loss: 0.1269
Epoch: 4/20 | Batch: 431/455 | Loss: 0.5451
Epoch: 4/20 | Batch: 441/455 | Loss: 0.6664
Epoch: 4/20 | Batch: 451/455 | Loss: 0.8779
Epoch: 4/20 | Train Loss: 0.7076 | Train Acc: 80.55% | Val Loss: 0.4178 | Val Acc: 87.66%
Current learning rate: 0.0001
Current learning rate: 0.0001
Current learning rate: 0.0001
Current learning rate: 0.0001
Current learning rate: 0.0001
Current learning rate: 0.0001
Current learning rate: 0.001
Epoch: 5/20 | Batch: 1/455 | Loss: 0.3230
Epoch: 5/20 | Batch: 11/455 | Loss: 0.4742
Epoch: 5/20 | Batch: 21/455 | Loss: 0.6497
Epoch: 5/20 | Batch: 31/455 | Loss: 0.7980
Epoch: 5/20 | Batch: 41/455 | Loss: 0.4321
Epoch: 5/20 | Batch: 51/455 | Loss: 0.5044
Epoch: 5/20 | Batch: 61/455 | Loss: 0.4447
Epoch: 5/20 | Batch: 71/455 | Loss: 0.6672
Epoch: 5/20 | Batch: 81/455 | Loss: 0.2822
Epoch: 5/20 | Batch: 91/455 | Loss: 0.5526
Epoch: 5/20 | Batch: 101/455 | Loss: 0.2427
Epoch: 5/20 | Batch: 111/455 | Loss: 0.8996
Epoch: 5/20 | Batch: 121/455 | Loss: 0.6189
Epoch: 5/20 | Batch: 131/455 | Loss: 0.3736
Epoch: 5/20 | Batch: 141/455 | Loss: 1.0602
Epoch: 5/20 | Batch: 151/455 | Loss: 1.1128
Epoch: 5/20 | Batch: 161/455 | Loss: 0.5810
Epoch: 5/20 | Batch: 171/455 | Loss: 0.8956
Epoch: 5/20 | Batch: 181/455 | Loss: 0.7348
Epoch: 5/20 | Batch: 191/455 | Loss: 0.3554
Epoch: 5/20 | Batch: 201/455 | Loss: 0.7941
Epoch: 5/20 | Batch: 211/455 | Loss: 0.2390
Epoch: 5/20 | Batch: 221/455 | Loss: 0.9595
Epoch: 5/20 | Batch: 231/455 | Loss: 0.7605
Epoch: 5/20 | Batch: 241/455 | Loss: 0.4278
Epoch: 5/20 | Batch: 251/455 | Loss: 0.2703
Epoch: 5/20 | Batch: 261/455 | Loss: 0.5240
Epoch: 5/20 | Batch: 271/455 | Loss: 0.8861
Epoch: 5/20 | Batch: 281/455 | Loss: 0.4188
Epoch: 5/20 | Batch: 291/455 | Loss: 0.4517
Epoch: 5/20 | Batch: 301/455 | Loss: 0.5801
Epoch: 5/20 | Batch: 311/455 | Loss: 0.8052
Epoch: 5/20 | Batch: 321/455 | Loss: 1.2078
Epoch: 5/20 | Batch: 331/455 | Loss: 0.0699
Epoch: 5/20 | Batch: 341/455 | Loss: 0.7578
Epoch: 5/20 | Batch: 351/455 | Loss: 0.3131
Epoch: 5/20 | Batch: 361/455 | Loss: 0.2656
Epoch: 5/20 | Batch: 371/455 | Loss: 0.3883
Epoch: 5/20 | Batch: 381/455 | Loss: 0.3019
Epoch: 5/20 | Batch: 391/455 | Loss: 0.6690
Epoch: 5/20 | Batch: 401/455 | Loss: 0.3331
Epoch: 5/20 | Batch: 411/455 | Loss: 1.2234
Epoch: 5/20 | Batch: 421/455 | Loss: 0.1710
Epoch: 5/20 | Batch: 431/455 | Loss: 1.3785
Epoch: 5/20 | Batch: 441/455 | Loss: 0.8074
Epoch: 5/20 | Batch: 451/455 | Loss: 0.1051
Epoch: 5/20 | Train Loss: 0.6196 | Train Acc: 82.83% | Val Loss: 0.3787 | Val Acc: 89.22%
Current learning rate: 0.0001
Current learning rate: 0.0001
Current learning rate: 0.0001
Current learning rate: 0.0001
Current learning rate: 0.0001
Current learning rate: 0.0001
Current learning rate: 0.001
Best accuracy: 89.22%
Model saved to checkpoints\resnet18_pretrained_best.pth
Epoch: 6/20 | Batch: 1/455 | Loss: 0.7744
Epoch: 6/20 | Batch: 11/455 | Loss: 0.8116
Epoch: 6/20 | Batch: 21/455 | Loss: 0.5016
Epoch: 6/20 | Batch: 31/455 | Loss: 0.3741
Epoch: 6/20 | Batch: 41/455 | Loss: 0.5326
Epoch: 6/20 | Batch: 51/455 | Loss: 0.7208
Epoch: 6/20 | Batch: 61/455 | Loss: 2.1727
Epoch: 6/20 | Batch: 71/455 | Loss: 0.3705
Epoch: 6/20 | Batch: 81/455 | Loss: 0.7740
Epoch: 6/20 | Batch: 91/455 | Loss: 0.0969
Epoch: 6/20 | Batch: 101/455 | Loss: 1.0959
Epoch: 6/20 | Batch: 111/455 | Loss: 0.4281
Epoch: 6/20 | Batch: 121/455 | Loss: 0.5937
Epoch: 6/20 | Batch: 131/455 | Loss: 0.6152
Epoch: 6/20 | Batch: 141/455 | Loss: 1.3412
Epoch: 6/20 | Batch: 151/455 | Loss: 0.0561
Epoch: 6/20 | Batch: 161/455 | Loss: 0.3036
Epoch: 6/20 | Batch: 171/455 | Loss: 0.7478
Epoch: 6/20 | Batch: 181/455 | Loss: 1.5127
Epoch: 6/20 | Batch: 191/455 | Loss: 0.8364
Epoch: 6/20 | Batch: 201/455 | Loss: 0.9875
Epoch: 6/20 | Batch: 211/455 | Loss: 0.6196
Epoch: 6/20 | Batch: 221/455 | Loss: 0.4578
Epoch: 6/20 | Batch: 231/455 | Loss: 0.5818
Epoch: 6/20 | Batch: 241/455 | Loss: 0.4752
Epoch: 6/20 | Batch: 251/455 | Loss: 0.5471
Epoch: 6/20 | Batch: 261/455 | Loss: 0.9662
Epoch: 6/20 | Batch: 271/455 | Loss: 0.2879
Epoch: 6/20 | Batch: 281/455 | Loss: 0.6754
Epoch: 6/20 | Batch: 291/455 | Loss: 0.6692
Epoch: 6/20 | Batch: 301/455 | Loss: 0.7646
Epoch: 6/20 | Batch: 311/455 | Loss: 0.9896
Epoch: 6/20 | Batch: 321/455 | Loss: 0.2589
Epoch: 6/20 | Batch: 331/455 | Loss: 0.7590
Epoch: 6/20 | Batch: 341/455 | Loss: 0.9286
Epoch: 6/20 | Batch: 351/455 | Loss: 0.5950
Epoch: 6/20 | Batch: 361/455 | Loss: 0.4396
Epoch: 6/20 | Batch: 371/455 | Loss: 1.1601
Epoch: 6/20 | Batch: 381/455 | Loss: 0.4898
Epoch: 6/20 | Batch: 391/455 | Loss: 0.3047
Epoch: 6/20 | Batch: 401/455 | Loss: 0.5209
Epoch: 6/20 | Batch: 411/455 | Loss: 0.8591
Epoch: 6/20 | Batch: 421/455 | Loss: 0.3578
Epoch: 6/20 | Batch: 431/455 | Loss: 0.3041
Epoch: 6/20 | Batch: 441/455 | Loss: 0.1208
Epoch: 6/20 | Batch: 451/455 | Loss: 0.7388
Epoch: 6/20 | Train Loss: 0.6042 | Train Acc: 82.73% | Val Loss: 0.3886 | Val Acc: 89.32%
Current learning rate: 0.0001
Current learning rate: 0.0001
Current learning rate: 0.0001
Current learning rate: 0.0001
Current learning rate: 0.0001
Current learning rate: 0.0001
Current learning rate: 0.001
Best accuracy: 89.32%
Model saved to checkpoints\resnet18_pretrained_best.pth
Epoch: 7/20 | Batch: 1/455 | Loss: 0.3542
Epoch: 7/20 | Batch: 11/455 | Loss: 0.3887
Epoch: 7/20 | Batch: 21/455 | Loss: 0.1136
Epoch: 7/20 | Batch: 31/455 | Loss: 0.2891
Epoch: 7/20 | Batch: 41/455 | Loss: 0.2899
Epoch: 7/20 | Batch: 51/455 | Loss: 0.2374
Epoch: 7/20 | Batch: 61/455 | Loss: 0.5946
Epoch: 7/20 | Batch: 71/455 | Loss: 0.4363
Epoch: 7/20 | Batch: 81/455 | Loss: 0.2905
Epoch: 7/20 | Batch: 91/455 | Loss: 0.4715
Epoch: 7/20 | Batch: 101/455 | Loss: 0.9776
Epoch: 7/20 | Batch: 111/455 | Loss: 0.3793
Epoch: 7/20 | Batch: 121/455 | Loss: 0.4744
Epoch: 7/20 | Batch: 131/455 | Loss: 0.3606
Epoch: 7/20 | Batch: 141/455 | Loss: 0.4867
Epoch: 7/20 | Batch: 151/455 | Loss: 0.8980
Epoch: 7/20 | Batch: 161/455 | Loss: 0.6278
Epoch: 7/20 | Batch: 171/455 | Loss: 0.5579
Epoch: 7/20 | Batch: 181/455 | Loss: 0.6107
Epoch: 7/20 | Batch: 191/455 | Loss: 0.5912
Epoch: 7/20 | Batch: 201/455 | Loss: 1.1715
Epoch: 7/20 | Batch: 211/455 | Loss: 0.4293
Epoch: 7/20 | Batch: 221/455 | Loss: 1.1102
Epoch: 7/20 | Batch: 231/455 | Loss: 0.3813
Epoch: 7/20 | Batch: 241/455 | Loss: 0.5883
Epoch: 7/20 | Batch: 251/455 | Loss: 0.3602
Epoch: 7/20 | Batch: 261/455 | Loss: 1.2049
Epoch: 7/20 | Batch: 271/455 | Loss: 0.2048
Epoch: 7/20 | Batch: 281/455 | Loss: 1.0243
Epoch: 7/20 | Batch: 291/455 | Loss: 0.6382
Epoch: 7/20 | Batch: 301/455 | Loss: 1.0817
Epoch: 7/20 | Batch: 311/455 | Loss: 0.3758
Epoch: 7/20 | Batch: 321/455 | Loss: 0.6794
Epoch: 7/20 | Batch: 331/455 | Loss: 0.4437
Epoch: 7/20 | Batch: 341/455 | Loss: 0.4882
Epoch: 7/20 | Batch: 351/455 | Loss: 0.7564
Epoch: 7/20 | Batch: 361/455 | Loss: 0.3500
Epoch: 7/20 | Batch: 371/455 | Loss: 1.1956
Epoch: 7/20 | Batch: 381/455 | Loss: 0.7399
Epoch: 7/20 | Batch: 391/455 | Loss: 0.3919
Epoch: 7/20 | Batch: 401/455 | Loss: 0.2511
Epoch: 7/20 | Batch: 411/455 | Loss: 0.5671
Epoch: 7/20 | Batch: 421/455 | Loss: 0.1933
Epoch: 7/20 | Batch: 431/455 | Loss: 0.7255
Epoch: 7/20 | Batch: 441/455 | Loss: 0.4879
Epoch: 7/20 | Batch: 451/455 | Loss: 0.3125
Epoch: 7/20 | Train Loss: 0.5547 | Train Acc: 84.86% | Val Loss: 0.4123 | Val Acc: 89.75%
Current learning rate: 0.0001
Current learning rate: 0.0001
Current learning rate: 0.0001
Current learning rate: 0.0001
Current learning rate: 0.0001
Current learning rate: 0.0001
Current learning rate: 0.001
Best accuracy: 89.75%
Model saved to checkpoints\resnet18_pretrained_best.pth
Epoch: 8/20 | Batch: 1/455 | Loss: 0.6345
Epoch: 8/20 | Batch: 11/455 | Loss: 0.0983
Epoch: 8/20 | Batch: 21/455 | Loss: 0.4585
Epoch: 8/20 | Batch: 31/455 | Loss: 0.2891
Epoch: 8/20 | Batch: 41/455 | Loss: 0.3893
Epoch: 8/20 | Batch: 51/455 | Loss: 0.7550
Epoch: 8/20 | Batch: 61/455 | Loss: 0.3525
Epoch: 8/20 | Batch: 71/455 | Loss: 0.6641
Epoch: 8/20 | Batch: 81/455 | Loss: 0.0072
Epoch: 8/20 | Batch: 91/455 | Loss: 0.6862
Epoch: 8/20 | Batch: 101/455 | Loss: 1.1054
Epoch: 8/20 | Batch: 111/455 | Loss: 0.2734
Epoch: 8/20 | Batch: 121/455 | Loss: 0.3249
Epoch: 8/20 | Batch: 131/455 | Loss: 0.6641
Epoch: 8/20 | Batch: 141/455 | Loss: 0.2560
Epoch: 8/20 | Batch: 151/455 | Loss: 0.1533
Epoch: 8/20 | Batch: 161/455 | Loss: 0.3816
Epoch: 8/20 | Batch: 171/455 | Loss: 0.3697
Epoch: 8/20 | Batch: 181/455 | Loss: 0.8635
Epoch: 8/20 | Batch: 191/455 | Loss: 0.7555
Epoch: 8/20 | Batch: 201/455 | Loss: 0.3691
Epoch: 8/20 | Batch: 211/455 | Loss: 0.7138
Epoch: 8/20 | Batch: 221/455 | Loss: 0.6126
Epoch: 8/20 | Batch: 231/455 | Loss: 0.7144
Epoch: 8/20 | Batch: 241/455 | Loss: 0.8267
Epoch: 8/20 | Batch: 251/455 | Loss: 0.5061
Epoch: 8/20 | Batch: 261/455 | Loss: 0.1112
Epoch: 8/20 | Batch: 271/455 | Loss: 0.9524
Epoch: 8/20 | Batch: 281/455 | Loss: 0.8031
Epoch: 8/20 | Batch: 291/455 | Loss: 0.1868
Epoch: 8/20 | Batch: 301/455 | Loss: 0.1424
Epoch: 8/20 | Batch: 311/455 | Loss: 0.6780
Epoch: 8/20 | Batch: 321/455 | Loss: 1.0346
Epoch: 8/20 | Batch: 331/455 | Loss: 0.1945
Epoch: 8/20 | Batch: 341/455 | Loss: 0.7134
Epoch: 8/20 | Batch: 351/455 | Loss: 0.3765
Epoch: 8/20 | Batch: 361/455 | Loss: 0.4676
Epoch: 8/20 | Batch: 371/455 | Loss: 0.1023
Epoch: 8/20 | Batch: 381/455 | Loss: 1.1615
Epoch: 8/20 | Batch: 391/455 | Loss: 0.5222
Epoch: 8/20 | Batch: 401/455 | Loss: 0.3293
Epoch: 8/20 | Batch: 411/455 | Loss: 0.1574
Epoch: 8/20 | Batch: 421/455 | Loss: 0.1765
Epoch: 8/20 | Batch: 431/455 | Loss: 1.0560
Epoch: 8/20 | Batch: 441/455 | Loss: 0.9956
Epoch: 8/20 | Batch: 451/455 | Loss: 1.0407
Epoch: 8/20 | Train Loss: 0.5347 | Train Acc: 84.92% | Val Loss: 0.3546 | Val Acc: 89.16%
Current learning rate: 0.0001
Current learning rate: 0.0001
Current learning rate: 0.0001
Current learning rate: 0.0001
Current learning rate: 0.0001
Current learning rate: 0.0001
Current learning rate: 0.001
Epoch: 9/20 | Batch: 1/455 | Loss: 0.2814
Epoch: 9/20 | Batch: 11/455 | Loss: 0.1676
Epoch: 9/20 | Batch: 21/455 | Loss: 1.6459
Epoch: 9/20 | Batch: 31/455 | Loss: 0.3483
Epoch: 9/20 | Batch: 41/455 | Loss: 1.0823
Epoch: 9/20 | Batch: 51/455 | Loss: 0.5562
Epoch: 9/20 | Batch: 61/455 | Loss: 0.3316
Epoch: 9/20 | Batch: 71/455 | Loss: 1.1112
Epoch: 9/20 | Batch: 81/455 | Loss: 0.9018
Epoch: 9/20 | Batch: 91/455 | Loss: 0.5709
Epoch: 9/20 | Batch: 101/455 | Loss: 0.9784
Epoch: 9/20 | Batch: 111/455 | Loss: 0.3021
Epoch: 9/20 | Batch: 121/455 | Loss: 0.5004
Epoch: 9/20 | Batch: 131/455 | Loss: 1.2331
Epoch: 9/20 | Batch: 141/455 | Loss: 0.4007
Epoch: 9/20 | Batch: 151/455 | Loss: 0.0547
Epoch: 9/20 | Batch: 161/455 | Loss: 0.9196
Epoch: 9/20 | Batch: 171/455 | Loss: 0.1090
Epoch: 9/20 | Batch: 181/455 | Loss: 0.4955
Epoch: 9/20 | Batch: 191/455 | Loss: 0.3752
Epoch: 9/20 | Batch: 201/455 | Loss: 0.4489
Epoch: 9/20 | Batch: 211/455 | Loss: 0.0555
Epoch: 9/20 | Batch: 221/455 | Loss: 0.3211
Epoch: 9/20 | Batch: 231/455 | Loss: 0.4935
Epoch: 9/20 | Batch: 241/455 | Loss: 0.5676
Epoch: 9/20 | Batch: 251/455 | Loss: 0.7625
Epoch: 9/20 | Batch: 261/455 | Loss: 0.5345
Epoch: 9/20 | Batch: 271/455 | Loss: 0.7498
Epoch: 9/20 | Batch: 281/455 | Loss: 0.2628
Epoch: 9/20 | Batch: 291/455 | Loss: 0.5465
Epoch: 9/20 | Batch: 301/455 | Loss: 0.3456
Epoch: 9/20 | Batch: 311/455 | Loss: 0.4261
Epoch: 9/20 | Batch: 321/455 | Loss: 0.2522
Epoch: 9/20 | Batch: 331/455 | Loss: 0.1972
Epoch: 9/20 | Batch: 341/455 | Loss: 0.3674
Epoch: 9/20 | Batch: 351/455 | Loss: 0.3297
Epoch: 9/20 | Batch: 361/455 | Loss: 0.1985
Epoch: 9/20 | Batch: 371/455 | Loss: 0.2739
Epoch: 9/20 | Batch: 381/455 | Loss: 0.6219
Epoch: 9/20 | Batch: 391/455 | Loss: 0.3176
Epoch: 9/20 | Batch: 401/455 | Loss: 0.2173
Epoch: 9/20 | Batch: 411/455 | Loss: 0.5293
Epoch: 9/20 | Batch: 421/455 | Loss: 0.6964
Epoch: 9/20 | Batch: 431/455 | Loss: 0.2695
Epoch: 9/20 | Batch: 441/455 | Loss: 0.4698
Epoch: 9/20 | Batch: 451/455 | Loss: 0.1116
Epoch: 9/20 | Train Loss: 0.5437 | Train Acc: 85.43% | Val Loss: 0.3517 | Val Acc: 90.40%
Current learning rate: 0.0001
Current learning rate: 0.0001
Current learning rate: 0.0001
Current learning rate: 0.0001
Current learning rate: 0.0001
Current learning rate: 0.0001
Current learning rate: 0.001
Best accuracy: 90.40%
Model saved to checkpoints\resnet18_pretrained_best.pth
Epoch: 10/20 | Batch: 1/455 | Loss: 0.6444
Epoch: 10/20 | Batch: 11/455 | Loss: 0.0636
Epoch: 10/20 | Batch: 21/455 | Loss: 0.8004
Epoch: 10/20 | Batch: 31/455 | Loss: 0.2318
Epoch: 10/20 | Batch: 41/455 | Loss: 1.1276
Epoch: 10/20 | Batch: 51/455 | Loss: 0.2198
Epoch: 10/20 | Batch: 61/455 | Loss: 0.2726
Epoch: 10/20 | Batch: 71/455 | Loss: 0.1546
Epoch: 10/20 | Batch: 81/455 | Loss: 0.1807
Epoch: 10/20 | Batch: 91/455 | Loss: 0.9783
Epoch: 10/20 | Batch: 101/455 | Loss: 0.5104
Epoch: 10/20 | Batch: 111/455 | Loss: 0.6018
Epoch: 10/20 | Batch: 121/455 | Loss: 0.1945
Epoch: 10/20 | Batch: 131/455 | Loss: 0.2188
Epoch: 10/20 | Batch: 141/455 | Loss: 0.1892
Epoch: 10/20 | Batch: 151/455 | Loss: 0.3424
Epoch: 10/20 | Batch: 161/455 | Loss: 0.5607
Epoch: 10/20 | Batch: 171/455 | Loss: 0.4897
Epoch: 10/20 | Batch: 181/455 | Loss: 1.1305
Epoch: 10/20 | Batch: 191/455 | Loss: 0.4568
Epoch: 10/20 | Batch: 201/455 | Loss: 0.1506
Epoch: 10/20 | Batch: 211/455 | Loss: 0.6845
Epoch: 10/20 | Batch: 221/455 | Loss: 0.5829
Epoch: 10/20 | Batch: 231/455 | Loss: 0.6330
Epoch: 10/20 | Batch: 241/455 | Loss: 0.4852
Epoch: 10/20 | Batch: 251/455 | Loss: 0.3576
Epoch: 10/20 | Batch: 261/455 | Loss: 0.5367
Epoch: 10/20 | Batch: 271/455 | Loss: 0.5276
Epoch: 10/20 | Batch: 281/455 | Loss: 0.3659
Epoch: 10/20 | Batch: 291/455 | Loss: 0.5567
Epoch: 10/20 | Batch: 301/455 | Loss: 0.6240
Epoch: 10/20 | Batch: 311/455 | Loss: 0.4917
Epoch: 10/20 | Batch: 321/455 | Loss: 0.3878
Epoch: 10/20 | Batch: 331/455 | Loss: 0.6472
Epoch: 10/20 | Batch: 341/455 | Loss: 0.8609
Epoch: 10/20 | Batch: 351/455 | Loss: 0.3617
Epoch: 10/20 | Batch: 361/455 | Loss: 0.2151
Epoch: 10/20 | Batch: 371/455 | Loss: 0.3720
Epoch: 10/20 | Batch: 381/455 | Loss: 0.3355
Epoch: 10/20 | Batch: 391/455 | Loss: 0.7213
Epoch: 10/20 | Batch: 401/455 | Loss: 0.1770
Epoch: 10/20 | Batch: 411/455 | Loss: 0.3538
Epoch: 10/20 | Batch: 421/455 | Loss: 0.7072
Epoch: 10/20 | Batch: 431/455 | Loss: 0.4218
Epoch: 10/20 | Batch: 441/455 | Loss: 0.4484
Epoch: 10/20 | Batch: 451/455 | Loss: 0.4322
Epoch: 10/20 | Train Loss: 0.4890 | Train Acc: 86.41% | Val Loss: 0.4016 | Val Acc: 89.70%
Current learning rate: 0.0001
Current learning rate: 0.0001
Current learning rate: 0.0001
Current learning rate: 0.0001
Current learning rate: 0.0001
Current learning rate: 0.0001
Current learning rate: 0.001
Epoch: 11/20 | Batch: 1/455 | Loss: 0.2355
Epoch: 11/20 | Batch: 11/455 | Loss: 0.5380
Epoch: 11/20 | Batch: 21/455 | Loss: 0.1293
Epoch: 11/20 | Batch: 31/455 | Loss: 0.3051
Epoch: 11/20 | Batch: 41/455 | Loss: 0.5873
Epoch: 11/20 | Batch: 51/455 | Loss: 0.1482
Epoch: 11/20 | Batch: 61/455 | Loss: 0.8779
Epoch: 11/20 | Batch: 71/455 | Loss: 0.4382
Epoch: 11/20 | Batch: 81/455 | Loss: 0.9431
Epoch: 11/20 | Batch: 91/455 | Loss: 0.3325
Epoch: 11/20 | Batch: 101/455 | Loss: 0.6374
Epoch: 11/20 | Batch: 111/455 | Loss: 0.0915
Epoch: 11/20 | Batch: 121/455 | Loss: 0.3514
Epoch: 11/20 | Batch: 131/455 | Loss: 0.7372
Epoch: 11/20 | Batch: 141/455 | Loss: 0.3948
Epoch: 11/20 | Batch: 151/455 | Loss: 0.2128
Epoch: 11/20 | Batch: 161/455 | Loss: 0.3208
Epoch: 11/20 | Batch: 171/455 | Loss: 0.1499
Epoch: 11/20 | Batch: 181/455 | Loss: 0.3143
Epoch: 11/20 | Batch: 191/455 | Loss: 0.0659
Epoch: 11/20 | Batch: 201/455 | Loss: 0.4063
Epoch: 11/20 | Batch: 211/455 | Loss: 0.2605
Epoch: 11/20 | Batch: 221/455 | Loss: 0.1289
Epoch: 11/20 | Batch: 231/455 | Loss: 0.8764
Epoch: 11/20 | Batch: 241/455 | Loss: 0.0664
Epoch: 11/20 | Batch: 251/455 | Loss: 0.3907
Epoch: 11/20 | Batch: 261/455 | Loss: 0.8251
Epoch: 11/20 | Batch: 271/455 | Loss: 0.1872
Epoch: 11/20 | Batch: 281/455 | Loss: 0.5399
Epoch: 11/20 | Batch: 291/455 | Loss: 0.1080
Epoch: 11/20 | Batch: 301/455 | Loss: 0.2270
Epoch: 11/20 | Batch: 311/455 | Loss: 0.5589
Epoch: 11/20 | Batch: 321/455 | Loss: 0.4311
Epoch: 11/20 | Batch: 331/455 | Loss: 0.3022
Epoch: 11/20 | Batch: 341/455 | Loss: 0.5193
Epoch: 11/20 | Batch: 351/455 | Loss: 0.1629
Epoch: 11/20 | Batch: 361/455 | Loss: 0.8361
Epoch: 11/20 | Batch: 371/455 | Loss: 0.1543
Epoch: 11/20 | Batch: 381/455 | Loss: 0.3505
Epoch: 11/20 | Batch: 391/455 | Loss: 0.8736
Epoch: 11/20 | Batch: 401/455 | Loss: 0.3341
Epoch: 11/20 | Batch: 411/455 | Loss: 0.0215
Epoch: 11/20 | Batch: 421/455 | Loss: 0.6227
Epoch: 11/20 | Batch: 431/455 | Loss: 0.2710
Epoch: 11/20 | Batch: 441/455 | Loss: 0.3819
Epoch: 11/20 | Batch: 451/455 | Loss: 0.8478
Epoch: 11/20 | Train Loss: 0.4758 | Train Acc: 86.72% | Val Loss: 0.4143 | Val Acc: 89.16%
Current learning rate: 0.0001
Current learning rate: 0.0001
Current learning rate: 0.0001
Current learning rate: 0.0001
Current learning rate: 0.0001
Current learning rate: 0.0001
Current learning rate: 0.001
Epoch: 12/20 | Batch: 1/455 | Loss: 0.5378
Epoch: 12/20 | Batch: 11/455 | Loss: 0.1840
Epoch: 12/20 | Batch: 21/455 | Loss: 0.4799
Epoch: 12/20 | Batch: 31/455 | Loss: 0.3592
Epoch: 12/20 | Batch: 41/455 | Loss: 0.5721
Epoch: 12/20 | Batch: 51/455 | Loss: 0.1735
Epoch: 12/20 | Batch: 61/455 | Loss: 0.2766
Epoch: 12/20 | Batch: 71/455 | Loss: 0.1820
Epoch: 12/20 | Batch: 81/455 | Loss: 0.1349
Epoch: 12/20 | Batch: 91/455 | Loss: 0.4450
Epoch: 12/20 | Batch: 101/455 | Loss: 0.1253
Epoch: 12/20 | Batch: 111/455 | Loss: 0.3584
Epoch: 12/20 | Batch: 121/455 | Loss: 0.6536
Epoch: 12/20 | Batch: 131/455 | Loss: 0.4592
Epoch: 12/20 | Batch: 141/455 | Loss: 0.3646
Epoch: 12/20 | Batch: 151/455 | Loss: 0.5714
Epoch: 12/20 | Batch: 161/455 | Loss: 0.1853
Epoch: 12/20 | Batch: 171/455 | Loss: 0.1701
Epoch: 12/20 | Batch: 181/455 | Loss: 0.1998
Epoch: 12/20 | Batch: 191/455 | Loss: 0.3767
Epoch: 12/20 | Batch: 201/455 | Loss: 0.6486
Epoch: 12/20 | Batch: 211/455 | Loss: 0.1824
Epoch: 12/20 | Batch: 221/455 | Loss: 0.3239
Epoch: 12/20 | Batch: 231/455 | Loss: 0.4338
Epoch: 12/20 | Batch: 241/455 | Loss: 1.0316
Epoch: 12/20 | Batch: 251/455 | Loss: 0.2343
Epoch: 12/20 | Batch: 261/455 | Loss: 0.3764
Epoch: 12/20 | Batch: 271/455 | Loss: 2.0680
Epoch: 12/20 | Batch: 281/455 | Loss: 0.5146
Epoch: 12/20 | Batch: 291/455 | Loss: 0.2511
Epoch: 12/20 | Batch: 301/455 | Loss: 0.1175
Epoch: 12/20 | Batch: 311/455 | Loss: 0.2730
Epoch: 12/20 | Batch: 321/455 | Loss: 0.2986
Epoch: 12/20 | Batch: 331/455 | Loss: 0.6475
Epoch: 12/20 | Batch: 341/455 | Loss: 0.6065
Epoch: 12/20 | Batch: 351/455 | Loss: 0.0333
Epoch: 12/20 | Batch: 361/455 | Loss: 0.8763
Epoch: 12/20 | Batch: 371/455 | Loss: 0.5878
Epoch: 12/20 | Batch: 381/455 | Loss: 0.9029
Epoch: 12/20 | Batch: 391/455 | Loss: 0.0573
Epoch: 12/20 | Batch: 401/455 | Loss: 0.2629
Epoch: 12/20 | Batch: 411/455 | Loss: 0.3627
Epoch: 12/20 | Batch: 421/455 | Loss: 0.1490
Epoch: 12/20 | Batch: 431/455 | Loss: 0.1207
Epoch: 12/20 | Batch: 441/455 | Loss: 0.8342
Epoch: 12/20 | Batch: 451/455 | Loss: 0.4813
Epoch: 12/20 | Train Loss: 0.4875 | Train Acc: 86.59% | Val Loss: 0.3820 | Val Acc: 89.43%
Current learning rate: 0.0001
Current learning rate: 0.0001
Current learning rate: 0.0001
Current learning rate: 0.0001
Current learning rate: 0.0001
Current learning rate: 0.0001
Current learning rate: 0.001
Epoch: 13/20 | Batch: 1/455 | Loss: 0.5169
Epoch: 13/20 | Batch: 11/455 | Loss: 0.2708
Epoch: 13/20 | Batch: 21/455 | Loss: 1.1682
Epoch: 13/20 | Batch: 31/455 | Loss: 0.4278
Epoch: 13/20 | Batch: 41/455 | Loss: 0.7022
Epoch: 13/20 | Batch: 51/455 | Loss: 0.5297
Epoch: 13/20 | Batch: 61/455 | Loss: 0.2509
Epoch: 13/20 | Batch: 71/455 | Loss: 0.1334
Epoch: 13/20 | Batch: 81/455 | Loss: 0.8404
Epoch: 13/20 | Batch: 91/455 | Loss: 0.6997
Epoch: 13/20 | Batch: 101/455 | Loss: 0.4710
Epoch: 13/20 | Batch: 111/455 | Loss: 0.5075
Epoch: 13/20 | Batch: 121/455 | Loss: 0.7147
Epoch: 13/20 | Batch: 131/455 | Loss: 0.4754
Epoch: 13/20 | Batch: 141/455 | Loss: 0.3540
Epoch: 13/20 | Batch: 151/455 | Loss: 0.8250
Epoch: 13/20 | Batch: 161/455 | Loss: 0.2277
Epoch: 13/20 | Batch: 171/455 | Loss: 0.0489
Epoch: 13/20 | Batch: 181/455 | Loss: 0.3976
Epoch: 13/20 | Batch: 191/455 | Loss: 0.5896
Epoch: 13/20 | Batch: 201/455 | Loss: 0.3166
Epoch: 13/20 | Batch: 211/455 | Loss: 0.6301
Epoch: 13/20 | Batch: 221/455 | Loss: 0.6425
Epoch: 13/20 | Batch: 231/455 | Loss: 0.2647
Epoch: 13/20 | Batch: 241/455 | Loss: 0.2104
Epoch: 13/20 | Batch: 251/455 | Loss: 0.2827
Epoch: 13/20 | Batch: 261/455 | Loss: 0.8742
Epoch: 13/20 | Batch: 271/455 | Loss: 0.5013
Epoch: 13/20 | Batch: 281/455 | Loss: 0.6606
Epoch: 13/20 | Batch: 291/455 | Loss: 0.6625
Epoch: 13/20 | Batch: 301/455 | Loss: 1.0881
Epoch: 13/20 | Batch: 311/455 | Loss: 0.7962
Epoch: 13/20 | Batch: 321/455 | Loss: 0.3773
Epoch: 13/20 | Batch: 331/455 | Loss: 0.5625
Epoch: 13/20 | Batch: 341/455 | Loss: 0.9550
Epoch: 13/20 | Batch: 351/455 | Loss: 0.5254
Epoch: 13/20 | Batch: 361/455 | Loss: 0.5404
Epoch: 13/20 | Batch: 371/455 | Loss: 0.0521
Epoch: 13/20 | Batch: 381/455 | Loss: 0.7337
Epoch: 13/20 | Batch: 391/455 | Loss: 0.0867
Epoch: 13/20 | Batch: 401/455 | Loss: 0.2932
Epoch: 13/20 | Batch: 411/455 | Loss: 0.8870
Epoch: 13/20 | Batch: 421/455 | Loss: 0.3909
Epoch: 13/20 | Batch: 431/455 | Loss: 0.1877
Epoch: 13/20 | Batch: 441/455 | Loss: 0.2751
Epoch: 13/20 | Batch: 451/455 | Loss: 0.5684
Epoch: 13/20 | Train Loss: 0.4783 | Train Acc: 86.51% | Val Loss: 0.4121 | Val Acc: 90.24%
Current learning rate: 0.0001
Current learning rate: 0.0001
Current learning rate: 0.0001
Current learning rate: 0.0001
Current learning rate: 0.0001
Current learning rate: 0.0001
Current learning rate: 0.001
Epoch: 14/20 | Batch: 1/455 | Loss: 0.4242
Epoch: 14/20 | Batch: 11/455 | Loss: 0.2266
Epoch: 14/20 | Batch: 21/455 | Loss: 0.2845
Epoch: 14/20 | Batch: 31/455 | Loss: 0.2257
Epoch: 14/20 | Batch: 41/455 | Loss: 0.6740
Epoch: 14/20 | Batch: 51/455 | Loss: 0.5434
Epoch: 14/20 | Batch: 61/455 | Loss: 0.7021
Epoch: 14/20 | Batch: 71/455 | Loss: 0.3521
Epoch: 14/20 | Batch: 81/455 | Loss: 0.2239
Epoch: 14/20 | Batch: 91/455 | Loss: 0.1332
Epoch: 14/20 | Batch: 101/455 | Loss: 0.3850
Epoch: 14/20 | Batch: 111/455 | Loss: 0.9012
Epoch: 14/20 | Batch: 121/455 | Loss: 0.4962
Epoch: 14/20 | Batch: 131/455 | Loss: 0.1210
Epoch: 14/20 | Batch: 141/455 | Loss: 0.7790
Epoch: 14/20 | Batch: 151/455 | Loss: 0.9775
Epoch: 14/20 | Batch: 161/455 | Loss: 0.6090
Epoch: 14/20 | Batch: 171/455 | Loss: 0.3134
Epoch: 14/20 | Batch: 181/455 | Loss: 0.0482
Epoch: 14/20 | Batch: 191/455 | Loss: 1.2956
Epoch: 14/20 | Batch: 201/455 | Loss: 0.6458
Epoch: 14/20 | Batch: 211/455 | Loss: 0.5553
Epoch: 14/20 | Batch: 221/455 | Loss: 0.3904
Epoch: 14/20 | Batch: 231/455 | Loss: 0.3762
Epoch: 14/20 | Batch: 241/455 | Loss: 0.7458
Epoch: 14/20 | Batch: 251/455 | Loss: 0.0409
Epoch: 14/20 | Batch: 261/455 | Loss: 0.3031
Epoch: 14/20 | Batch: 271/455 | Loss: 0.4253
Epoch: 14/20 | Batch: 281/455 | Loss: 0.3445
Epoch: 14/20 | Batch: 291/455 | Loss: 0.8476
Epoch: 14/20 | Batch: 301/455 | Loss: 0.4187
Epoch: 14/20 | Batch: 311/455 | Loss: 0.0735
Epoch: 14/20 | Batch: 321/455 | Loss: 0.5382
Epoch: 14/20 | Batch: 331/455 | Loss: 0.5734
Epoch: 14/20 | Batch: 341/455 | Loss: 0.3713
Epoch: 14/20 | Batch: 351/455 | Loss: 0.3825
Epoch: 14/20 | Batch: 361/455 | Loss: 0.6451
Epoch: 14/20 | Batch: 371/455 | Loss: 0.7593
Epoch: 14/20 | Batch: 381/455 | Loss: 0.0850
Epoch: 14/20 | Batch: 391/455 | Loss: 0.4168
Epoch: 14/20 | Batch: 401/455 | Loss: 0.0307
Epoch: 14/20 | Batch: 411/455 | Loss: 0.1847
Epoch: 14/20 | Batch: 421/455 | Loss: 0.4938
Epoch: 14/20 | Batch: 431/455 | Loss: 0.2551
Epoch: 14/20 | Batch: 441/455 | Loss: 0.7790
Epoch: 14/20 | Batch: 451/455 | Loss: 0.4662
Epoch: 14/20 | Train Loss: 0.4452 | Train Acc: 87.79% | Val Loss: 0.4653 | Val Acc: 89.00%
Current learning rate: 0.0001
Current learning rate: 0.0001
Current learning rate: 0.0001
Current learning rate: 0.0001
Current learning rate: 0.0001
Current learning rate: 0.0001
Current learning rate: 0.001
Epoch: 15/20 | Batch: 1/455 | Loss: 0.5281
Epoch: 15/20 | Batch: 11/455 | Loss: 0.1380
Epoch: 15/20 | Batch: 21/455 | Loss: 0.2334
Epoch: 15/20 | Batch: 31/455 | Loss: 0.4738
Epoch: 15/20 | Batch: 41/455 | Loss: 0.5502
Epoch: 15/20 | Batch: 51/455 | Loss: 0.1166
Epoch: 15/20 | Batch: 61/455 | Loss: 0.2655
Epoch: 15/20 | Batch: 71/455 | Loss: 0.3831
Epoch: 15/20 | Batch: 81/455 | Loss: 0.1153
Epoch: 15/20 | Batch: 91/455 | Loss: 0.7297
Epoch: 15/20 | Batch: 101/455 | Loss: 0.2811
Epoch: 15/20 | Batch: 111/455 | Loss: 0.0560
Epoch: 15/20 | Batch: 121/455 | Loss: 0.4891
Epoch: 15/20 | Batch: 131/455 | Loss: 0.2697
Epoch: 15/20 | Batch: 141/455 | Loss: 0.8692
Epoch: 15/20 | Batch: 151/455 | Loss: 0.4609
Epoch: 15/20 | Batch: 161/455 | Loss: 0.6438
Epoch: 15/20 | Batch: 171/455 | Loss: 0.3599
Epoch: 15/20 | Batch: 181/455 | Loss: 0.3984
Epoch: 15/20 | Batch: 191/455 | Loss: 0.7793
Epoch: 15/20 | Batch: 201/455 | Loss: 0.3427
Epoch: 15/20 | Batch: 211/455 | Loss: 0.8376
Epoch: 15/20 | Batch: 221/455 | Loss: 0.4901
Epoch: 15/20 | Batch: 231/455 | Loss: 0.7764
Epoch: 15/20 | Batch: 241/455 | Loss: 0.2837
Epoch: 15/20 | Batch: 251/455 | Loss: 0.1354
Epoch: 15/20 | Batch: 261/455 | Loss: 0.2266
Epoch: 15/20 | Batch: 271/455 | Loss: 0.6444
Epoch: 15/20 | Batch: 281/455 | Loss: 0.0957
Epoch: 15/20 | Batch: 291/455 | Loss: 0.4092
Epoch: 15/20 | Batch: 301/455 | Loss: 0.3929
Epoch: 15/20 | Batch: 311/455 | Loss: 0.3074
Epoch: 15/20 | Batch: 321/455 | Loss: 0.0934
Epoch: 15/20 | Batch: 331/455 | Loss: 0.1733
Epoch: 15/20 | Batch: 341/455 | Loss: 0.3765
Epoch: 15/20 | Batch: 351/455 | Loss: 0.0313
Epoch: 15/20 | Batch: 361/455 | Loss: 0.0970
Epoch: 15/20 | Batch: 371/455 | Loss: 0.7446
Epoch: 15/20 | Batch: 381/455 | Loss: 0.4737
Epoch: 15/20 | Batch: 391/455 | Loss: 0.5373
Epoch: 15/20 | Batch: 401/455 | Loss: 0.2552
Epoch: 15/20 | Batch: 411/455 | Loss: 0.2268
Epoch: 15/20 | Batch: 421/455 | Loss: 0.8340
Epoch: 15/20 | Batch: 431/455 | Loss: 0.7978
Epoch: 15/20 | Batch: 441/455 | Loss: 0.3404
Epoch: 15/20 | Batch: 451/455 | Loss: 0.1679
Epoch: 15/20 | Train Loss: 0.4525 | Train Acc: 87.66% | Val Loss: 0.4636 | Val Acc: 88.73%
Current learning rate: 1e-05
Current learning rate: 1e-05
Current learning rate: 1e-05
Current learning rate: 1e-05
Current learning rate: 1e-05
Current learning rate: 1e-05
Current learning rate: 0.0001
Epoch: 16/20 | Batch: 1/455 | Loss: 0.1238
Epoch: 16/20 | Batch: 11/455 | Loss: 0.2412
Epoch: 16/20 | Batch: 21/455 | Loss: 0.2671
Epoch: 16/20 | Batch: 31/455 | Loss: 0.4915
Epoch: 16/20 | Batch: 41/455 | Loss: 0.3730
Epoch: 16/20 | Batch: 51/455 | Loss: 0.4424
Epoch: 16/20 | Batch: 61/455 | Loss: 0.1953
Epoch: 16/20 | Batch: 71/455 | Loss: 0.6753
Epoch: 16/20 | Batch: 81/455 | Loss: 0.4049
Epoch: 16/20 | Batch: 91/455 | Loss: 0.1607
Epoch: 16/20 | Batch: 101/455 | Loss: 0.5920
Epoch: 16/20 | Batch: 111/455 | Loss: 0.5355
Epoch: 16/20 | Batch: 121/455 | Loss: 0.0413
Epoch: 16/20 | Batch: 131/455 | Loss: 0.8820
Epoch: 16/20 | Batch: 141/455 | Loss: 0.2576
Epoch: 16/20 | Batch: 151/455 | Loss: 0.0332
Epoch: 16/20 | Batch: 161/455 | Loss: 0.4215
Epoch: 16/20 | Batch: 171/455 | Loss: 0.0827
Epoch: 16/20 | Batch: 181/455 | Loss: 0.4006
Epoch: 16/20 | Batch: 191/455 | Loss: 0.5849
Epoch: 16/20 | Batch: 201/455 | Loss: 0.3869
Epoch: 16/20 | Batch: 211/455 | Loss: 0.1572
Epoch: 16/20 | Batch: 221/455 | Loss: 0.2262
Epoch: 16/20 | Batch: 231/455 | Loss: 0.0959
Epoch: 16/20 | Batch: 241/455 | Loss: 1.1021
Epoch: 16/20 | Batch: 251/455 | Loss: 0.0689
Epoch: 16/20 | Batch: 261/455 | Loss: 0.0848
Epoch: 16/20 | Batch: 271/455 | Loss: 0.1342
Epoch: 16/20 | Batch: 281/455 | Loss: 0.4066
Epoch: 16/20 | Batch: 291/455 | Loss: 0.3525
Epoch: 16/20 | Batch: 301/455 | Loss: 0.2123
Epoch: 16/20 | Batch: 311/455 | Loss: 0.4503
Epoch: 16/20 | Batch: 321/455 | Loss: 0.0654
Epoch: 16/20 | Batch: 331/455 | Loss: 0.3306
Epoch: 16/20 | Batch: 341/455 | Loss: 1.3125
Epoch: 16/20 | Batch: 351/455 | Loss: 0.3009
Epoch: 16/20 | Batch: 361/455 | Loss: 0.4352
Epoch: 16/20 | Batch: 371/455 | Loss: 0.3093
Epoch: 16/20 | Batch: 381/455 | Loss: 0.6687
Epoch: 16/20 | Batch: 391/455 | Loss: 0.0200
Epoch: 16/20 | Batch: 401/455 | Loss: 0.1137
Epoch: 16/20 | Batch: 411/455 | Loss: 0.7890
Epoch: 16/20 | Batch: 421/455 | Loss: 0.1167
Epoch: 16/20 | Batch: 431/455 | Loss: 0.0741
Epoch: 16/20 | Batch: 441/455 | Loss: 0.5660
Epoch: 16/20 | Batch: 451/455 | Loss: 0.3739
Epoch: 16/20 | Train Loss: 0.3491 | Train Acc: 90.15% | Val Loss: 0.3264 | Val Acc: 90.93%
Current learning rate: 1e-05
Current learning rate: 1e-05
Current learning rate: 1e-05
Current learning rate: 1e-05
Current learning rate: 1e-05
Current learning rate: 1e-05
Current learning rate: 0.0001
Best accuracy: 90.93%
Model saved to checkpoints\resnet18_pretrained_best.pth
Epoch: 17/20 | Batch: 1/455 | Loss: 0.2181
Epoch: 17/20 | Batch: 11/455 | Loss: 0.0752
Epoch: 17/20 | Batch: 21/455 | Loss: 0.5764
Epoch: 17/20 | Batch: 31/455 | Loss: 0.2925
Epoch: 17/20 | Batch: 41/455 | Loss: 0.3352
Epoch: 17/20 | Batch: 51/455 | Loss: 0.3091
Epoch: 17/20 | Batch: 61/455 | Loss: 0.6893
Epoch: 17/20 | Batch: 71/455 | Loss: 0.4132
Epoch: 17/20 | Batch: 81/455 | Loss: 0.2358
Epoch: 17/20 | Batch: 91/455 | Loss: 0.4320
Epoch: 17/20 | Batch: 101/455 | Loss: 0.1886
Epoch: 17/20 | Batch: 111/455 | Loss: 0.3775
Epoch: 17/20 | Batch: 121/455 | Loss: 0.2004
Epoch: 17/20 | Batch: 131/455 | Loss: 0.3548
Epoch: 17/20 | Batch: 141/455 | Loss: 0.6482
Epoch: 17/20 | Batch: 151/455 | Loss: 0.0627
Epoch: 17/20 | Batch: 161/455 | Loss: 0.3796
Epoch: 17/20 | Batch: 171/455 | Loss: 0.5863
Epoch: 17/20 | Batch: 181/455 | Loss: 0.2454
Epoch: 17/20 | Batch: 191/455 | Loss: 0.0716
Epoch: 17/20 | Batch: 201/455 | Loss: 0.2969
Epoch: 17/20 | Batch: 211/455 | Loss: 0.1751
Epoch: 17/20 | Batch: 221/455 | Loss: 0.5054
Epoch: 17/20 | Batch: 231/455 | Loss: 0.0336
Epoch: 17/20 | Batch: 241/455 | Loss: 0.4539
Epoch: 17/20 | Batch: 251/455 | Loss: 0.3883
Epoch: 17/20 | Batch: 261/455 | Loss: 0.0323
Epoch: 17/20 | Batch: 271/455 | Loss: 0.1987
Epoch: 17/20 | Batch: 281/455 | Loss: 0.0630
Epoch: 17/20 | Batch: 291/455 | Loss: 0.0512
Epoch: 17/20 | Batch: 301/455 | Loss: 0.6020
Epoch: 17/20 | Batch: 311/455 | Loss: 0.1532
Epoch: 17/20 | Batch: 321/455 | Loss: 0.1615
Epoch: 17/20 | Batch: 331/455 | Loss: 0.4772
Epoch: 17/20 | Batch: 341/455 | Loss: 0.1117
Epoch: 17/20 | Batch: 351/455 | Loss: 0.0593
Epoch: 17/20 | Batch: 361/455 | Loss: 0.4258
Epoch: 17/20 | Batch: 371/455 | Loss: 0.2268
Epoch: 17/20 | Batch: 381/455 | Loss: 0.1371
Epoch: 17/20 | Batch: 391/455 | Loss: 0.3403
Epoch: 17/20 | Batch: 401/455 | Loss: 0.2967
Epoch: 17/20 | Batch: 411/455 | Loss: 0.4406
Epoch: 17/20 | Batch: 421/455 | Loss: 0.0243
Epoch: 17/20 | Batch: 431/455 | Loss: 0.0075
Epoch: 17/20 | Batch: 441/455 | Loss: 0.2511
Epoch: 17/20 | Batch: 451/455 | Loss: 0.3155
Epoch: 17/20 | Train Loss: 0.2908 | Train Acc: 91.63% | Val Loss: 0.3162 | Val Acc: 90.67%
Current learning rate: 1e-05
Current learning rate: 1e-05
Current learning rate: 1e-05
Current learning rate: 1e-05
Current learning rate: 1e-05
Current learning rate: 1e-05
Current learning rate: 0.0001
Epoch: 18/20 | Batch: 1/455 | Loss: 0.1257
Epoch: 18/20 | Batch: 11/455 | Loss: 0.5746
Epoch: 18/20 | Batch: 21/455 | Loss: 0.0133
Epoch: 18/20 | Batch: 31/455 | Loss: 0.6225
Epoch: 18/20 | Batch: 41/455 | Loss: 0.6294
Epoch: 18/20 | Batch: 51/455 | Loss: 0.0568
Epoch: 18/20 | Batch: 61/455 | Loss: 0.4939
Epoch: 18/20 | Batch: 71/455 | Loss: 0.1535
Epoch: 18/20 | Batch: 81/455 | Loss: 0.3501
Epoch: 18/20 | Batch: 91/455 | Loss: 0.0394
Epoch: 18/20 | Batch: 101/455 | Loss: 0.3398
Epoch: 18/20 | Batch: 111/455 | Loss: 0.0410
Epoch: 18/20 | Batch: 121/455 | Loss: 0.3612
Epoch: 18/20 | Batch: 131/455 | Loss: 0.3865
Epoch: 18/20 | Batch: 141/455 | Loss: 0.1825
Epoch: 18/20 | Batch: 151/455 | Loss: 0.5026
Epoch: 18/20 | Batch: 161/455 | Loss: 0.5356
Epoch: 18/20 | Batch: 171/455 | Loss: 0.2279
Epoch: 18/20 | Batch: 181/455 | Loss: 0.2616
Epoch: 18/20 | Batch: 191/455 | Loss: 0.5360
Epoch: 18/20 | Batch: 201/455 | Loss: 0.0123
Epoch: 18/20 | Batch: 211/455 | Loss: 0.0913
Epoch: 18/20 | Batch: 221/455 | Loss: 0.3949
Epoch: 18/20 | Batch: 231/455 | Loss: 0.1487
Epoch: 18/20 | Batch: 241/455 | Loss: 0.0661
Epoch: 18/20 | Batch: 251/455 | Loss: 0.3122
Epoch: 18/20 | Batch: 261/455 | Loss: 0.1363
Epoch: 18/20 | Batch: 271/455 | Loss: 0.2923
Epoch: 18/20 | Batch: 281/455 | Loss: 0.4129
Epoch: 18/20 | Batch: 291/455 | Loss: 0.1484
Epoch: 18/20 | Batch: 301/455 | Loss: 0.1567
Epoch: 18/20 | Batch: 311/455 | Loss: 0.4196
Epoch: 18/20 | Batch: 321/455 | Loss: 0.8118
Epoch: 18/20 | Batch: 331/455 | Loss: 0.0991
Epoch: 18/20 | Batch: 341/455 | Loss: 0.5077
Epoch: 18/20 | Batch: 351/455 | Loss: 0.0501
Epoch: 18/20 | Batch: 361/455 | Loss: 0.7639
Epoch: 18/20 | Batch: 371/455 | Loss: 0.2927
Epoch: 18/20 | Batch: 381/455 | Loss: 0.2398
Epoch: 18/20 | Batch: 391/455 | Loss: 0.3464
Epoch: 18/20 | Batch: 401/455 | Loss: 0.1206
Epoch: 18/20 | Batch: 411/455 | Loss: 0.1154
Epoch: 18/20 | Batch: 421/455 | Loss: 0.5551
Epoch: 18/20 | Batch: 431/455 | Loss: 0.1640
Epoch: 18/20 | Batch: 441/455 | Loss: 0.1540
Epoch: 18/20 | Batch: 451/455 | Loss: 0.2720
Epoch: 18/20 | Train Loss: 0.2748 | Train Acc: 92.27% | Val Loss: 0.2968 | Val Acc: 91.95%
Current learning rate: 1e-05
Current learning rate: 1e-05
Current learning rate: 1e-05
Current learning rate: 1e-05
Current learning rate: 1e-05
Current learning rate: 1e-05
Current learning rate: 0.0001
Best accuracy: 91.95%
Model saved to checkpoints\resnet18_pretrained_best.pth
Epoch: 19/20 | Batch: 1/455 | Loss: 0.0568
Epoch: 19/20 | Batch: 11/455 | Loss: 0.2408
Epoch: 19/20 | Batch: 21/455 | Loss: 0.3449
Epoch: 19/20 | Batch: 31/455 | Loss: 0.3242
Epoch: 19/20 | Batch: 41/455 | Loss: 0.0048
Epoch: 19/20 | Batch: 51/455 | Loss: 0.0794
Epoch: 19/20 | Batch: 61/455 | Loss: 0.1477
Epoch: 19/20 | Batch: 71/455 | Loss: 0.0469
Epoch: 19/20 | Batch: 81/455 | Loss: 0.4048
Epoch: 19/20 | Batch: 91/455 | Loss: 0.5653
Epoch: 19/20 | Batch: 101/455 | Loss: 0.0818
Epoch: 19/20 | Batch: 111/455 | Loss: 0.1267
Epoch: 19/20 | Batch: 121/455 | Loss: 0.3618
Epoch: 19/20 | Batch: 131/455 | Loss: 0.0406
Epoch: 19/20 | Batch: 141/455 | Loss: 0.6575
Epoch: 19/20 | Batch: 151/455 | Loss: 0.4888
Epoch: 19/20 | Batch: 161/455 | Loss: 0.0400
Epoch: 19/20 | Batch: 171/455 | Loss: 0.0663
Epoch: 19/20 | Batch: 181/455 | Loss: 0.1694
Epoch: 19/20 | Batch: 191/455 | Loss: 0.5208
Epoch: 19/20 | Batch: 201/455 | Loss: 0.1623
Epoch: 19/20 | Batch: 211/455 | Loss: 0.6640
Epoch: 19/20 | Batch: 221/455 | Loss: 0.3408
Epoch: 19/20 | Batch: 231/455 | Loss: 0.6998
Epoch: 19/20 | Batch: 241/455 | Loss: 0.2482
Epoch: 19/20 | Batch: 251/455 | Loss: 0.5155
Epoch: 19/20 | Batch: 261/455 | Loss: 0.2878
Epoch: 19/20 | Batch: 271/455 | Loss: 0.2752
Epoch: 19/20 | Batch: 281/455 | Loss: 0.4004
Epoch: 19/20 | Batch: 291/455 | Loss: 0.0285
Epoch: 19/20 | Batch: 301/455 | Loss: 0.7854
Epoch: 19/20 | Batch: 311/455 | Loss: 0.0151
Epoch: 19/20 | Batch: 321/455 | Loss: 0.1589
Epoch: 19/20 | Batch: 331/455 | Loss: 0.3321
Epoch: 19/20 | Batch: 341/455 | Loss: 0.0721
Epoch: 19/20 | Batch: 351/455 | Loss: 0.4319
Epoch: 19/20 | Batch: 361/455 | Loss: 0.0470
Epoch: 19/20 | Batch: 371/455 | Loss: 0.0275
Epoch: 19/20 | Batch: 381/455 | Loss: 0.6236
Epoch: 19/20 | Batch: 391/455 | Loss: 0.0465
Epoch: 19/20 | Batch: 401/455 | Loss: 0.2933
Epoch: 19/20 | Batch: 411/455 | Loss: 0.0529
Epoch: 19/20 | Batch: 421/455 | Loss: 0.2526
Epoch: 19/20 | Batch: 431/455 | Loss: 0.5317
Epoch: 19/20 | Batch: 441/455 | Loss: 0.2074
Epoch: 19/20 | Batch: 451/455 | Loss: 0.4395
Epoch: 19/20 | Train Loss: 0.2762 | Train Acc: 92.18% | Val Loss: 0.3012 | Val Acc: 91.95%
Current learning rate: 1e-05
Current learning rate: 1e-05
Current learning rate: 1e-05
Current learning rate: 1e-05
Current learning rate: 1e-05
Current learning rate: 1e-05
Current learning rate: 0.0001
Epoch: 20/20 | Batch: 1/455 | Loss: 0.4022
Epoch: 20/20 | Batch: 11/455 | Loss: 0.0609
Epoch: 20/20 | Batch: 21/455 | Loss: 0.1747
Epoch: 20/20 | Batch: 31/455 | Loss: 0.3286
Epoch: 20/20 | Batch: 41/455 | Loss: 0.5453
Epoch: 20/20 | Batch: 51/455 | Loss: 0.0905
Epoch: 20/20 | Batch: 61/455 | Loss: 0.2987
Epoch: 20/20 | Batch: 71/455 | Loss: 0.0628
Epoch: 20/20 | Batch: 81/455 | Loss: 0.1700
Epoch: 20/20 | Batch: 91/455 | Loss: 0.1603
Epoch: 20/20 | Batch: 101/455 | Loss: 0.0776
Epoch: 20/20 | Batch: 111/455 | Loss: 0.1204
Epoch: 20/20 | Batch: 121/455 | Loss: 0.0532
Epoch: 20/20 | Batch: 131/455 | Loss: 0.2834
Epoch: 20/20 | Batch: 141/455 | Loss: 0.4649
Epoch: 20/20 | Batch: 151/455 | Loss: 0.5426
Epoch: 20/20 | Batch: 161/455 | Loss: 0.3003
Epoch: 20/20 | Batch: 171/455 | Loss: 0.7431
Epoch: 20/20 | Batch: 181/455 | Loss: 0.2058
Epoch: 20/20 | Batch: 191/455 | Loss: 0.0294
Epoch: 20/20 | Batch: 201/455 | Loss: 0.3214
Epoch: 20/20 | Batch: 211/455 | Loss: 0.1745
Epoch: 20/20 | Batch: 221/455 | Loss: 0.4770
Epoch: 20/20 | Batch: 231/455 | Loss: 0.3563
Epoch: 20/20 | Batch: 241/455 | Loss: 0.5455
Epoch: 20/20 | Batch: 251/455 | Loss: 0.2282
Epoch: 20/20 | Batch: 261/455 | Loss: 0.0319
Epoch: 20/20 | Batch: 271/455 | Loss: 0.1004
Epoch: 20/20 | Batch: 281/455 | Loss: 0.4128
Epoch: 20/20 | Batch: 291/455 | Loss: 0.0364
Epoch: 20/20 | Batch: 301/455 | Loss: 0.0088
Epoch: 20/20 | Batch: 311/455 | Loss: 0.0667
Epoch: 20/20 | Batch: 321/455 | Loss: 0.1070
Epoch: 20/20 | Batch: 331/455 | Loss: 0.2528
Epoch: 20/20 | Batch: 341/455 | Loss: 0.4670
Epoch: 20/20 | Batch: 351/455 | Loss: 0.2087
Epoch: 20/20 | Batch: 361/455 | Loss: 0.0725
Epoch: 20/20 | Batch: 371/455 | Loss: 0.1357
Epoch: 20/20 | Batch: 381/455 | Loss: 0.2748
Epoch: 20/20 | Batch: 391/455 | Loss: 0.2160
Epoch: 20/20 | Batch: 401/455 | Loss: 0.0283
Epoch: 20/20 | Batch: 411/455 | Loss: 0.0485
Epoch: 20/20 | Batch: 421/455 | Loss: 0.0974
Epoch: 20/20 | Batch: 431/455 | Loss: 0.0866
Epoch: 20/20 | Batch: 441/455 | Loss: 0.0921
Epoch: 20/20 | Batch: 451/455 | Loss: 0.4991
Epoch: 20/20 | Train Loss: 0.2514 | Train Acc: 92.72% | Val Loss: 0.2864 | Val Acc: 92.65%
Current learning rate: 1e-05
Current learning rate: 1e-05
Current learning rate: 1e-05
Current learning rate: 1e-05
Current learning rate: 1e-05
Current learning rate: 1e-05
Current learning rate: 0.0001
Best accuracy: 92.65%
Model saved to checkpoints\resnet18_pretrained_best.pth

(base) C:\Users\26336\Desktop\FDU\神经网络\home_work_2>python -m tensorboard.main --logdir=runs
TensorFlow installation not found - running with reduced feature set.
Serving TensorBoard on localhost; to expose to the network, use a proxy or pass --bind_all
TensorBoard 2.19.0 at http://localhost:6006/ (Press CTRL+C to quit)

(base) C:\Users\26336\Desktop\FDU\神经网络\home_work_2>
(base) C:\Users\26336\Desktop\FDU\神经网络\home_work_2>
(base) C:\Users\26336\Desktop\FDU\神经网络\home_work_2>
(base) C:\Users\26336\Desktop\FDU\神经网络\home_work_2>python main.py
Training with pretrained weights...
Number of classes: 102
Class names: ['BACKGROUND_Google', 'Faces', 'Faces_easy', 'Leopards', 'Motorbikes', 'accordion', 'airplanes', 'anchor', 'ant', 'barrel', 'bass', 'beaver', 'binocular', 'bonsai', 'brain', 'brontosaurus', 'buddha', 'butterfly', 'camera', 'cannon', 'car_side', 'ceiling_fan', 'cellphone', 'chair', 'chandelier', 'cougar_body', 'cougar_face', 'crab', 'crayfish', 'crocodile', 'crocodile_head', 'cup', 'dalmatian', 'dollar_bill', 'dolphin', 'dragonfly', 'electric_guitar', 'elephant', 'emu', 'euphonium', 'ewer', 'ferry', 'flamingo', 'flamingo_head', 'garfield', 'gerenuk', 'gramophone', 'grand_piano', 'hawksbill', 'headphone', 'hedgehog', 'helicopter', 'ibis', 'inline_skate', 'joshua_tree', 'kangaroo', 'ketch', 'lamp', 'laptop', 'llama', 'lobster', 'lotus', 'mandolin', 'mayfly', 'menorah', 'metronome', 'minaret', 'nautilus', 'octopus', 'okapi', 'pagoda', 'panda', 'pigeon', 'pizza', 'platypus', 'pyramid', 'revolver', 'rhino', 'rooster', 'saxophone', 'schooner', 'scissors', 'scorpion', 'sea_horse', 'snoopy', 'soccer_ball', 'stapler', 'starfish', 'stegosaurus', 'stop_sign', 'strawberry', 'sunflower', 'tick', 'trilobite', 'umbrella', 'watch', 'water_lilly', 'wheelchair', 'wild_cat', 'windsor_chair', 'wrench', 'yin_yang']
Training samples: 7280
Validation samples: 1864
Epoch: 1/20 | Batch: 1/228 | Loss: 4.9077
Epoch: 1/20 | Batch: 11/228 | Loss: 3.7120
Epoch: 1/20 | Batch: 21/228 | Loss: 3.0723
Epoch: 1/20 | Batch: 31/228 | Loss: 2.8421
Epoch: 1/20 | Batch: 41/228 | Loss: 2.7726
Epoch: 1/20 | Batch: 51/228 | Loss: 3.0003
Epoch: 1/20 | Batch: 61/228 | Loss: 2.5484
Epoch: 1/20 | Batch: 71/228 | Loss: 2.0861
Epoch: 1/20 | Batch: 81/228 | Loss: 2.4049
Epoch: 1/20 | Batch: 91/228 | Loss: 2.3274
Epoch: 1/20 | Batch: 101/228 | Loss: 2.1075
Epoch: 1/20 | Batch: 111/228 | Loss: 2.4911
Epoch: 1/20 | Batch: 121/228 | Loss: 2.1608
Epoch: 1/20 | Batch: 131/228 | Loss: 2.1388
Epoch: 1/20 | Batch: 141/228 | Loss: 1.8266
Epoch: 1/20 | Batch: 151/228 | Loss: 2.0183
Epoch: 1/20 | Batch: 161/228 | Loss: 1.4610
Epoch: 1/20 | Batch: 171/228 | Loss: 2.0060
Epoch: 1/20 | Batch: 181/228 | Loss: 1.3312
Epoch: 1/20 | Batch: 191/228 | Loss: 1.5691
Epoch: 1/20 | Batch: 201/228 | Loss: 1.3262
Epoch: 1/20 | Batch: 211/228 | Loss: 1.6971
Epoch: 1/20 | Batch: 221/228 | Loss: 1.4054
Epoch: 1/20 | Train Loss: 2.2427 | Train Acc: 52.71% | Val Loss: 0.9209 | Val Acc: 78.86%
Current learning rate: 0.0001
Current learning rate: 0.0001
Current learning rate: 0.0001
Current learning rate: 0.0001
Current learning rate: 0.0001
Current learning rate: 0.0001
Current learning rate: 0.0001
Best accuracy: 78.86%
Model saved to checkpoints\resnet18_pretrained_best.pth
Epoch: 2/20 | Batch: 1/228 | Loss: 1.1394
Epoch: 2/20 | Batch: 11/228 | Loss: 0.8326
Epoch: 2/20 | Batch: 21/228 | Loss: 1.0833
Epoch: 2/20 | Batch: 31/228 | Loss: 1.7638
Epoch: 2/20 | Batch: 41/228 | Loss: 1.2520
Epoch: 2/20 | Batch: 51/228 | Loss: 1.0966
Epoch: 2/20 | Batch: 61/228 | Loss: 1.1880
Epoch: 2/20 | Batch: 71/228 | Loss: 1.1209
Epoch: 2/20 | Batch: 81/228 | Loss: 1.4714
Epoch: 2/20 | Batch: 91/228 | Loss: 1.1633
Epoch: 2/20 | Batch: 101/228 | Loss: 0.9231
Epoch: 2/20 | Batch: 111/228 | Loss: 0.9196
Epoch: 2/20 | Batch: 121/228 | Loss: 1.0305
Epoch: 2/20 | Batch: 131/228 | Loss: 0.7627
Epoch: 2/20 | Batch: 141/228 | Loss: 0.8972
Epoch: 2/20 | Batch: 151/228 | Loss: 0.9703
Epoch: 2/20 | Batch: 161/228 | Loss: 0.6382
Epoch: 2/20 | Batch: 171/228 | Loss: 0.8658
Epoch: 2/20 | Batch: 181/228 | Loss: 0.5806
Epoch: 2/20 | Batch: 191/228 | Loss: 0.8252
Epoch: 2/20 | Batch: 201/228 | Loss: 0.9284
Epoch: 2/20 | Batch: 211/228 | Loss: 1.2724
Epoch: 2/20 | Batch: 221/228 | Loss: 0.8213
Epoch: 2/20 | Train Loss: 1.0687 | Train Acc: 77.24% | Val Loss: 0.5235 | Val Acc: 87.45%
Current learning rate: 0.0001
Current learning rate: 0.0001
Current learning rate: 0.0001
Current learning rate: 0.0001
Current learning rate: 0.0001
Current learning rate: 0.0001
Current learning rate: 0.0001
Best accuracy: 87.45%
Model saved to checkpoints\resnet18_pretrained_best.pth
Epoch: 3/20 | Batch: 1/228 | Loss: 0.7579
Epoch: 3/20 | Batch: 11/228 | Loss: 0.9042
Epoch: 3/20 | Batch: 21/228 | Loss: 0.4968
Epoch: 3/20 | Batch: 31/228 | Loss: 1.1769
Epoch: 3/20 | Batch: 41/228 | Loss: 0.6058
Epoch: 3/20 | Batch: 51/228 | Loss: 0.6928
Epoch: 3/20 | Batch: 61/228 | Loss: 0.9918
Epoch: 3/20 | Batch: 71/228 | Loss: 0.8944
Epoch: 3/20 | Batch: 81/228 | Loss: 0.6987
Epoch: 3/20 | Batch: 91/228 | Loss: 0.8241
Epoch: 3/20 | Batch: 101/228 | Loss: 0.6053
Epoch: 3/20 | Batch: 111/228 | Loss: 0.8262
Epoch: 3/20 | Batch: 121/228 | Loss: 1.0723
Epoch: 3/20 | Batch: 131/228 | Loss: 0.4211
Epoch: 3/20 | Batch: 141/228 | Loss: 0.4288
Epoch: 3/20 | Batch: 151/228 | Loss: 0.6939
Epoch: 3/20 | Batch: 161/228 | Loss: 0.6035
Epoch: 3/20 | Batch: 171/228 | Loss: 0.6999
Epoch: 3/20 | Batch: 181/228 | Loss: 0.6891
Epoch: 3/20 | Batch: 191/228 | Loss: 0.7370
Epoch: 3/20 | Batch: 201/228 | Loss: 0.4813
Epoch: 3/20 | Batch: 211/228 | Loss: 0.8571
Epoch: 3/20 | Batch: 221/228 | Loss: 0.8553
Epoch: 3/20 | Train Loss: 0.7731 | Train Acc: 82.42% | Val Loss: 0.4441 | Val Acc: 88.52%
Current learning rate: 0.0001
Current learning rate: 0.0001
Current learning rate: 0.0001
Current learning rate: 0.0001
Current learning rate: 0.0001
Current learning rate: 0.0001
Current learning rate: 0.0001
Best accuracy: 88.52%
Model saved to checkpoints\resnet18_pretrained_best.pth
Epoch: 4/20 | Batch: 1/228 | Loss: 0.4445
Epoch: 4/20 | Batch: 11/228 | Loss: 0.8562
Epoch: 4/20 | Batch: 21/228 | Loss: 0.5539
Epoch: 4/20 | Batch: 31/228 | Loss: 0.2555
Epoch: 4/20 | Batch: 41/228 | Loss: 0.4674
Epoch: 4/20 | Batch: 51/228 | Loss: 0.3658
Epoch: 4/20 | Batch: 61/228 | Loss: 0.5286
Epoch: 4/20 | Batch: 71/228 | Loss: 0.6771
Epoch: 4/20 | Batch: 81/228 | Loss: 0.6687
Epoch: 4/20 | Batch: 91/228 | Loss: 0.6789
Epoch: 4/20 | Batch: 101/228 | Loss: 0.8127
Epoch: 4/20 | Batch: 111/228 | Loss: 0.5425
Epoch: 4/20 | Batch: 121/228 | Loss: 0.4236
Epoch: 4/20 | Batch: 131/228 | Loss: 0.5914
Epoch: 4/20 | Batch: 141/228 | Loss: 0.5278
Epoch: 4/20 | Batch: 151/228 | Loss: 0.7689
Epoch: 4/20 | Batch: 161/228 | Loss: 0.6651
Epoch: 4/20 | Batch: 171/228 | Loss: 0.7055
Epoch: 4/20 | Batch: 181/228 | Loss: 1.0819
Epoch: 4/20 | Batch: 191/228 | Loss: 0.8059
Epoch: 4/20 | Batch: 201/228 | Loss: 0.7558
Epoch: 4/20 | Batch: 211/228 | Loss: 0.5347
Epoch: 4/20 | Batch: 221/228 | Loss: 0.2633
Epoch: 4/20 | Train Loss: 0.6495 | Train Acc: 84.92% | Val Loss: 0.3560 | Val Acc: 89.97%
Current learning rate: 0.0001
Current learning rate: 0.0001
Current learning rate: 0.0001
Current learning rate: 0.0001
Current learning rate: 0.0001
Current learning rate: 0.0001
Current learning rate: 0.0001
Best accuracy: 89.97%
Model saved to checkpoints\resnet18_pretrained_best.pth
Epoch: 5/20 | Batch: 1/228 | Loss: 0.5369
Epoch: 5/20 | Batch: 11/228 | Loss: 0.5352
Epoch: 5/20 | Batch: 21/228 | Loss: 0.5365
Epoch: 5/20 | Batch: 31/228 | Loss: 0.3903
Epoch: 5/20 | Batch: 41/228 | Loss: 0.2987
Epoch: 5/20 | Batch: 51/228 | Loss: 0.5756
Epoch: 5/20 | Batch: 61/228 | Loss: 0.6956
Epoch: 5/20 | Batch: 71/228 | Loss: 0.6380
Epoch: 5/20 | Batch: 81/228 | Loss: 1.2473
Epoch: 5/20 | Batch: 91/228 | Loss: 0.5372
Epoch: 5/20 | Batch: 101/228 | Loss: 0.4994
Epoch: 5/20 | Batch: 111/228 | Loss: 0.5915
Epoch: 5/20 | Batch: 121/228 | Loss: 0.3684
Epoch: 5/20 | Batch: 131/228 | Loss: 0.3122
Epoch: 5/20 | Batch: 141/228 | Loss: 0.4377
Epoch: 5/20 | Batch: 151/228 | Loss: 0.4105
Epoch: 5/20 | Batch: 161/228 | Loss: 0.4654
Epoch: 5/20 | Batch: 171/228 | Loss: 0.7355
Epoch: 5/20 | Batch: 181/228 | Loss: 0.4874
Epoch: 5/20 | Batch: 191/228 | Loss: 0.4976
Epoch: 5/20 | Batch: 201/228 | Loss: 0.6832
Epoch: 5/20 | Batch: 211/228 | Loss: 0.4595
Epoch: 5/20 | Batch: 221/228 | Loss: 0.7341
Epoch: 5/20 | Train Loss: 0.5646 | Train Acc: 86.52% | Val Loss: 0.3542 | Val Acc: 90.61%
Current learning rate: 0.0001
Current learning rate: 0.0001
Current learning rate: 0.0001
Current learning rate: 0.0001
Current learning rate: 0.0001
Current learning rate: 0.0001
Current learning rate: 0.0001
Best accuracy: 90.61%
Model saved to checkpoints\resnet18_pretrained_best.pth
Epoch: 6/20 | Batch: 1/228 | Loss: 0.7266
Epoch: 6/20 | Batch: 11/228 | Loss: 0.4596
Epoch: 6/20 | Batch: 21/228 | Loss: 0.5630
Epoch: 6/20 | Batch: 31/228 | Loss: 0.2715
Epoch: 6/20 | Batch: 41/228 | Loss: 0.4604
Epoch: 6/20 | Batch: 51/228 | Loss: 0.3903
Epoch: 6/20 | Batch: 61/228 | Loss: 0.4773
Epoch: 6/20 | Batch: 71/228 | Loss: 0.2896
Epoch: 6/20 | Batch: 81/228 | Loss: 0.4423
Epoch: 6/20 | Batch: 91/228 | Loss: 0.6809
Epoch: 6/20 | Batch: 101/228 | Loss: 0.2538
Epoch: 6/20 | Batch: 111/228 | Loss: 0.2941
Epoch: 6/20 | Batch: 121/228 | Loss: 0.2012
Epoch: 6/20 | Batch: 131/228 | Loss: 0.4261
Epoch: 6/20 | Batch: 141/228 | Loss: 0.3644
Epoch: 6/20 | Batch: 151/228 | Loss: 0.5296
Epoch: 6/20 | Batch: 161/228 | Loss: 0.3562
Epoch: 6/20 | Batch: 171/228 | Loss: 0.3905
Epoch: 6/20 | Batch: 181/228 | Loss: 0.4868
Epoch: 6/20 | Batch: 191/228 | Loss: 0.5011
Epoch: 6/20 | Batch: 201/228 | Loss: 0.4600
Epoch: 6/20 | Batch: 211/228 | Loss: 0.2584
Epoch: 6/20 | Batch: 221/228 | Loss: 0.2267
Epoch: 6/20 | Train Loss: 0.4946 | Train Acc: 87.90% | Val Loss: 0.3378 | Val Acc: 90.61%
Current learning rate: 0.0001
Current learning rate: 0.0001
Current learning rate: 0.0001
Current learning rate: 0.0001
Current learning rate: 0.0001
Current learning rate: 0.0001
Current learning rate: 0.0001
Epoch: 7/20 | Batch: 1/228 | Loss: 0.2650
Epoch: 7/20 | Batch: 11/228 | Loss: 0.5427
Epoch: 7/20 | Batch: 21/228 | Loss: 0.5764
Epoch: 7/20 | Batch: 31/228 | Loss: 0.3904
Epoch: 7/20 | Batch: 41/228 | Loss: 0.5225
Epoch: 7/20 | Batch: 51/228 | Loss: 0.4158
Epoch: 7/20 | Batch: 61/228 | Loss: 0.7368
Epoch: 7/20 | Batch: 71/228 | Loss: 0.3582
Epoch: 7/20 | Batch: 81/228 | Loss: 0.3832
Epoch: 7/20 | Batch: 91/228 | Loss: 0.4686
Epoch: 7/20 | Batch: 101/228 | Loss: 0.3403
Epoch: 7/20 | Batch: 111/228 | Loss: 0.5133
Epoch: 7/20 | Batch: 121/228 | Loss: 0.7740
Epoch: 7/20 | Batch: 131/228 | Loss: 0.3449
Epoch: 7/20 | Batch: 141/228 | Loss: 0.4734
Epoch: 7/20 | Batch: 151/228 | Loss: 0.3967
Epoch: 7/20 | Batch: 161/228 | Loss: 0.6312
Epoch: 7/20 | Batch: 171/228 | Loss: 0.4057
Epoch: 7/20 | Batch: 181/228 | Loss: 0.5349
Epoch: 7/20 | Batch: 191/228 | Loss: 0.1818
Epoch: 7/20 | Batch: 201/228 | Loss: 0.3036
Epoch: 7/20 | Batch: 211/228 | Loss: 0.2443
Epoch: 7/20 | Batch: 221/228 | Loss: 0.6008
Epoch: 7/20 | Train Loss: 0.4598 | Train Acc: 89.08% | Val Loss: 0.3329 | Val Acc: 89.54%
Current learning rate: 0.0001
Current learning rate: 0.0001
Current learning rate: 0.0001
Current learning rate: 0.0001
Current learning rate: 0.0001
Current learning rate: 0.0001
Current learning rate: 0.0001
Epoch: 8/20 | Batch: 1/228 | Loss: 0.7029
Epoch: 8/20 | Batch: 11/228 | Loss: 0.3461
Epoch: 8/20 | Batch: 21/228 | Loss: 0.8212
Epoch: 8/20 | Batch: 31/228 | Loss: 0.3859
Epoch: 8/20 | Batch: 41/228 | Loss: 0.3931
Epoch: 8/20 | Batch: 51/228 | Loss: 0.2847
Epoch: 8/20 | Batch: 61/228 | Loss: 0.1423
Epoch: 8/20 | Batch: 71/228 | Loss: 0.3216
Epoch: 8/20 | Batch: 81/228 | Loss: 0.3561
Epoch: 8/20 | Batch: 91/228 | Loss: 0.1627
Epoch: 8/20 | Batch: 101/228 | Loss: 0.4264
Epoch: 8/20 | Batch: 111/228 | Loss: 0.4360
Epoch: 8/20 | Batch: 121/228 | Loss: 0.4534
Epoch: 8/20 | Batch: 131/228 | Loss: 0.5459
Epoch: 8/20 | Batch: 141/228 | Loss: 0.4935
Epoch: 8/20 | Batch: 151/228 | Loss: 0.6763
Epoch: 8/20 | Batch: 161/228 | Loss: 0.3185
Epoch: 8/20 | Batch: 171/228 | Loss: 0.2709
Epoch: 8/20 | Batch: 181/228 | Loss: 0.5911
Epoch: 8/20 | Batch: 191/228 | Loss: 0.4827
Epoch: 8/20 | Batch: 201/228 | Loss: 0.4547
Epoch: 8/20 | Batch: 211/228 | Loss: 0.3644
Epoch: 8/20 | Batch: 221/228 | Loss: 0.2228
Epoch: 8/20 | Train Loss: 0.4266 | Train Acc: 89.37% | Val Loss: 0.2785 | Val Acc: 91.42%
Current learning rate: 0.0001
Current learning rate: 0.0001
Current learning rate: 0.0001
Current learning rate: 0.0001
Current learning rate: 0.0001
Current learning rate: 0.0001
Current learning rate: 0.0001
Best accuracy: 91.42%
Model saved to checkpoints\resnet18_pretrained_best.pth
Epoch: 9/20 | Batch: 1/228 | Loss: 0.2543
Epoch: 9/20 | Batch: 11/228 | Loss: 0.3371
Epoch: 9/20 | Batch: 21/228 | Loss: 0.4367
Epoch: 9/20 | Batch: 31/228 | Loss: 0.5980
Epoch: 9/20 | Batch: 41/228 | Loss: 0.3470
Epoch: 9/20 | Batch: 51/228 | Loss: 0.3712
Epoch: 9/20 | Batch: 61/228 | Loss: 0.5965
Epoch: 9/20 | Batch: 71/228 | Loss: 0.2496
Epoch: 9/20 | Batch: 81/228 | Loss: 0.3641
Epoch: 9/20 | Batch: 91/228 | Loss: 0.6402
Epoch: 9/20 | Batch: 101/228 | Loss: 0.3832
Epoch: 9/20 | Batch: 111/228 | Loss: 0.0607
Epoch: 9/20 | Batch: 121/228 | Loss: 0.3711
Epoch: 9/20 | Batch: 131/228 | Loss: 0.3558
Epoch: 9/20 | Batch: 141/228 | Loss: 0.5443
Epoch: 9/20 | Batch: 151/228 | Loss: 0.3416
Epoch: 9/20 | Batch: 161/228 | Loss: 0.2509
Epoch: 9/20 | Batch: 171/228 | Loss: 0.4995
Epoch: 9/20 | Batch: 181/228 | Loss: 0.3790
Epoch: 9/20 | Batch: 191/228 | Loss: 0.4219
Epoch: 9/20 | Batch: 201/228 | Loss: 0.7002
Epoch: 9/20 | Batch: 211/228 | Loss: 0.1261
Epoch: 9/20 | Batch: 221/228 | Loss: 0.3020
Epoch: 9/20 | Train Loss: 0.4236 | Train Acc: 89.44% | Val Loss: 0.2790 | Val Acc: 92.17%
Current learning rate: 0.0001
Current learning rate: 0.0001
Current learning rate: 0.0001
Current learning rate: 0.0001
Current learning rate: 0.0001
Current learning rate: 0.0001
Current learning rate: 0.0001
Best accuracy: 92.17%
Model saved to checkpoints\resnet18_pretrained_best.pth
Epoch: 10/20 | Batch: 1/228 | Loss: 0.5665
Epoch: 10/20 | Batch: 11/228 | Loss: 0.5691
Epoch: 10/20 | Batch: 21/228 | Loss: 0.6411
Epoch: 10/20 | Batch: 31/228 | Loss: 0.3651
Epoch: 10/20 | Batch: 41/228 | Loss: 0.4351
Epoch: 10/20 | Batch: 51/228 | Loss: 0.2870
Epoch: 10/20 | Batch: 61/228 | Loss: 0.3496
Epoch: 10/20 | Batch: 71/228 | Loss: 0.3007
Epoch: 10/20 | Batch: 81/228 | Loss: 0.1537
Epoch: 10/20 | Batch: 91/228 | Loss: 0.3286
Epoch: 10/20 | Batch: 101/228 | Loss: 0.2009
Epoch: 10/20 | Batch: 111/228 | Loss: 0.2937
Epoch: 10/20 | Batch: 121/228 | Loss: 0.1686
Epoch: 10/20 | Batch: 131/228 | Loss: 0.1633
Epoch: 10/20 | Batch: 141/228 | Loss: 0.3643
Epoch: 10/20 | Batch: 151/228 | Loss: 0.3786
Epoch: 10/20 | Batch: 161/228 | Loss: 0.4007
Epoch: 10/20 | Batch: 171/228 | Loss: 0.2599
Epoch: 10/20 | Batch: 181/228 | Loss: 0.2205
Epoch: 10/20 | Batch: 191/228 | Loss: 0.6651
Epoch: 10/20 | Batch: 201/228 | Loss: 0.2841
Epoch: 10/20 | Batch: 211/228 | Loss: 0.3293
Epoch: 10/20 | Batch: 221/228 | Loss: 0.5473
Epoch: 10/20 | Train Loss: 0.4005 | Train Acc: 89.67% | Val Loss: 0.2749 | Val Acc: 92.22%
Current learning rate: 0.0001
Current learning rate: 0.0001
Current learning rate: 0.0001
Current learning rate: 0.0001
Current learning rate: 0.0001
Current learning rate: 0.0001
Current learning rate: 0.0001
Best accuracy: 92.22%
Model saved to checkpoints\resnet18_pretrained_best.pth
Epoch: 11/20 | Batch: 1/228 | Loss: 0.4248
Epoch: 11/20 | Batch: 11/228 | Loss: 0.1380
Epoch: 11/20 | Batch: 21/228 | Loss: 0.2144
Epoch: 11/20 | Batch: 31/228 | Loss: 0.4288
Epoch: 11/20 | Batch: 41/228 | Loss: 0.3421
Epoch: 11/20 | Batch: 51/228 | Loss: 0.5302
Epoch: 11/20 | Batch: 61/228 | Loss: 0.2606
Epoch: 11/20 | Batch: 71/228 | Loss: 0.1946
Epoch: 11/20 | Batch: 81/228 | Loss: 0.3381
Epoch: 11/20 | Batch: 91/228 | Loss: 0.1895
Epoch: 11/20 | Batch: 101/228 | Loss: 0.1627
Epoch: 11/20 | Batch: 111/228 | Loss: 0.9172
Epoch: 11/20 | Batch: 121/228 | Loss: 0.2682
Epoch: 11/20 | Batch: 131/228 | Loss: 0.2977
Epoch: 11/20 | Batch: 141/228 | Loss: 0.4063
Epoch: 11/20 | Batch: 151/228 | Loss: 0.4112
Epoch: 11/20 | Batch: 161/228 | Loss: 0.6078
Epoch: 11/20 | Batch: 171/228 | Loss: 0.2058
Epoch: 11/20 | Batch: 181/228 | Loss: 0.5331
Epoch: 11/20 | Batch: 191/228 | Loss: 0.4991
Epoch: 11/20 | Batch: 201/228 | Loss: 0.3975
Epoch: 11/20 | Batch: 211/228 | Loss: 0.1636
Epoch: 11/20 | Batch: 221/228 | Loss: 0.4628
Epoch: 11/20 | Train Loss: 0.3744 | Train Acc: 90.56% | Val Loss: 0.2923 | Val Acc: 91.36%
Current learning rate: 0.0001
Current learning rate: 0.0001
Current learning rate: 0.0001
Current learning rate: 0.0001
Current learning rate: 0.0001
Current learning rate: 0.0001
Current learning rate: 0.0001
Epoch: 12/20 | Batch: 1/228 | Loss: 0.3893
Epoch: 12/20 | Batch: 11/228 | Loss: 0.3202
Epoch: 12/20 | Batch: 21/228 | Loss: 0.3912
Epoch: 12/20 | Batch: 31/228 | Loss: 0.2489
Epoch: 12/20 | Batch: 41/228 | Loss: 0.1990
Epoch: 12/20 | Batch: 51/228 | Loss: 0.4457
Epoch: 12/20 | Batch: 61/228 | Loss: 0.4045
Epoch: 12/20 | Batch: 71/228 | Loss: 0.2261
Epoch: 12/20 | Batch: 81/228 | Loss: 0.5445
Epoch: 12/20 | Batch: 91/228 | Loss: 0.5031
Epoch: 12/20 | Batch: 101/228 | Loss: 0.6162
Epoch: 12/20 | Batch: 111/228 | Loss: 0.2156
Epoch: 12/20 | Batch: 121/228 | Loss: 0.4176
Epoch: 12/20 | Batch: 131/228 | Loss: 0.2490
Epoch: 12/20 | Batch: 141/228 | Loss: 0.1582
Epoch: 12/20 | Batch: 151/228 | Loss: 0.2305
Epoch: 12/20 | Batch: 161/228 | Loss: 0.5492
Epoch: 12/20 | Batch: 171/228 | Loss: 0.7306
Epoch: 12/20 | Batch: 181/228 | Loss: 0.4467
Epoch: 12/20 | Batch: 191/228 | Loss: 0.3074
Epoch: 12/20 | Batch: 201/228 | Loss: 0.7338
Epoch: 12/20 | Batch: 211/228 | Loss: 0.3859
Epoch: 12/20 | Batch: 221/228 | Loss: 0.4385
Epoch: 12/20 | Train Loss: 0.3664 | Train Acc: 90.62% | Val Loss: 0.2656 | Val Acc: 92.49%
Current learning rate: 0.0001
Current learning rate: 0.0001
Current learning rate: 0.0001
Current learning rate: 0.0001
Current learning rate: 0.0001
Current learning rate: 0.0001
Current learning rate: 0.0001
Best accuracy: 92.49%
Model saved to checkpoints\resnet18_pretrained_best.pth
Epoch: 13/20 | Batch: 1/228 | Loss: 0.1850
Epoch: 13/20 | Batch: 11/228 | Loss: 0.4849
Epoch: 13/20 | Batch: 21/228 | Loss: 0.1554
Epoch: 13/20 | Batch: 31/228 | Loss: 0.2544
Epoch: 13/20 | Batch: 41/228 | Loss: 0.2281
Epoch: 13/20 | Batch: 51/228 | Loss: 0.5742
Epoch: 13/20 | Batch: 61/228 | Loss: 0.2256
Epoch: 13/20 | Batch: 71/228 | Loss: 0.2762
Epoch: 13/20 | Batch: 81/228 | Loss: 0.3578
Epoch: 13/20 | Batch: 91/228 | Loss: 0.2620
Epoch: 13/20 | Batch: 101/228 | Loss: 0.2977
Epoch: 13/20 | Batch: 111/228 | Loss: 0.4159
Epoch: 13/20 | Batch: 121/228 | Loss: 0.3994
Epoch: 13/20 | Batch: 131/228 | Loss: 0.2213
Epoch: 13/20 | Batch: 141/228 | Loss: 0.5582
Epoch: 13/20 | Batch: 151/228 | Loss: 0.5866
Epoch: 13/20 | Batch: 161/228 | Loss: 0.2631
Epoch: 13/20 | Batch: 171/228 | Loss: 0.3290
Epoch: 13/20 | Batch: 181/228 | Loss: 0.2157
Epoch: 13/20 | Batch: 191/228 | Loss: 0.3917
Epoch: 13/20 | Batch: 201/228 | Loss: 0.2905
Epoch: 13/20 | Batch: 211/228 | Loss: 0.1213
Epoch: 13/20 | Batch: 221/228 | Loss: 0.5141
Epoch: 13/20 | Train Loss: 0.3473 | Train Acc: 90.80% | Val Loss: 0.2905 | Val Acc: 90.61%
Current learning rate: 0.0001
Current learning rate: 0.0001
Current learning rate: 0.0001
Current learning rate: 0.0001
Current learning rate: 0.0001
Current learning rate: 0.0001
Current learning rate: 0.0001
Epoch: 14/20 | Batch: 1/228 | Loss: 0.2531
Epoch: 14/20 | Batch: 11/228 | Loss: 0.3372
Epoch: 14/20 | Batch: 21/228 | Loss: 0.3946
Epoch: 14/20 | Batch: 31/228 | Loss: 0.2584
Epoch: 14/20 | Batch: 41/228 | Loss: 0.4077
Epoch: 14/20 | Batch: 51/228 | Loss: 0.2220
Epoch: 14/20 | Batch: 61/228 | Loss: 0.1131
Epoch: 14/20 | Batch: 71/228 | Loss: 0.1477
Epoch: 14/20 | Batch: 81/228 | Loss: 0.3168
Epoch: 14/20 | Batch: 91/228 | Loss: 0.1958
Epoch: 14/20 | Batch: 101/228 | Loss: 0.3384
Epoch: 14/20 | Batch: 111/228 | Loss: 0.1670
Epoch: 14/20 | Batch: 121/228 | Loss: 0.1724
Epoch: 14/20 | Batch: 131/228 | Loss: 0.3099
Epoch: 14/20 | Batch: 141/228 | Loss: 0.1374
Epoch: 14/20 | Batch: 151/228 | Loss: 0.6878
Epoch: 14/20 | Batch: 161/228 | Loss: 0.4133
Epoch: 14/20 | Batch: 171/228 | Loss: 0.3208
Epoch: 14/20 | Batch: 181/228 | Loss: 0.1139
Epoch: 14/20 | Batch: 191/228 | Loss: 0.2905
Epoch: 14/20 | Batch: 201/228 | Loss: 0.2653
Epoch: 14/20 | Batch: 211/228 | Loss: 0.6881
Epoch: 14/20 | Batch: 221/228 | Loss: 0.2549
Epoch: 14/20 | Train Loss: 0.3374 | Train Acc: 91.13% | Val Loss: 0.3012 | Val Acc: 91.04%
Current learning rate: 0.0001
Current learning rate: 0.0001
Current learning rate: 0.0001
Current learning rate: 0.0001
Current learning rate: 0.0001
Current learning rate: 0.0001
Current learning rate: 0.0001
Epoch: 15/20 | Batch: 1/228 | Loss: 0.3325
Epoch: 15/20 | Batch: 11/228 | Loss: 0.3478
Epoch: 15/20 | Batch: 21/228 | Loss: 0.0304
Epoch: 15/20 | Batch: 31/228 | Loss: 0.2092
Epoch: 15/20 | Batch: 41/228 | Loss: 0.5797
Epoch: 15/20 | Batch: 51/228 | Loss: 0.3323
Epoch: 15/20 | Batch: 61/228 | Loss: 0.1818
Epoch: 15/20 | Batch: 71/228 | Loss: 0.4942
Epoch: 15/20 | Batch: 81/228 | Loss: 0.4171
Epoch: 15/20 | Batch: 91/228 | Loss: 0.1788
Epoch: 15/20 | Batch: 101/228 | Loss: 0.3833
Epoch: 15/20 | Batch: 111/228 | Loss: 0.1439
Epoch: 15/20 | Batch: 121/228 | Loss: 0.3534
Epoch: 15/20 | Batch: 131/228 | Loss: 0.1959
Epoch: 15/20 | Batch: 141/228 | Loss: 0.4231
Epoch: 15/20 | Batch: 151/228 | Loss: 0.2339
Epoch: 15/20 | Batch: 161/228 | Loss: 0.2146
Epoch: 15/20 | Batch: 171/228 | Loss: 0.2954
Epoch: 15/20 | Batch: 181/228 | Loss: 0.2390
Epoch: 15/20 | Batch: 191/228 | Loss: 0.3886
Epoch: 15/20 | Batch: 201/228 | Loss: 0.0976
Epoch: 15/20 | Batch: 211/228 | Loss: 0.6239
Epoch: 15/20 | Batch: 221/228 | Loss: 0.2791
Epoch: 15/20 | Train Loss: 0.3223 | Train Acc: 91.63% | Val Loss: 0.2687 | Val Acc: 91.95%
Current learning rate: 0.0001
Current learning rate: 0.0001
Current learning rate: 0.0001
Current learning rate: 0.0001
Current learning rate: 0.0001
Current learning rate: 0.0001
Current learning rate: 0.0001
Epoch: 16/20 | Batch: 1/228 | Loss: 0.3930
Epoch: 16/20 | Batch: 11/228 | Loss: 0.3118
Epoch: 16/20 | Batch: 21/228 | Loss: 0.1473
Epoch: 16/20 | Batch: 31/228 | Loss: 0.2398
Epoch: 16/20 | Batch: 41/228 | Loss: 0.1393
Epoch: 16/20 | Batch: 51/228 | Loss: 0.1413
Epoch: 16/20 | Batch: 61/228 | Loss: 0.3366
Epoch: 16/20 | Batch: 71/228 | Loss: 0.4242
Epoch: 16/20 | Batch: 81/228 | Loss: 0.2321
Epoch: 16/20 | Batch: 91/228 | Loss: 0.6115
Epoch: 16/20 | Batch: 101/228 | Loss: 0.6693
Epoch: 16/20 | Batch: 111/228 | Loss: 0.2016
Epoch: 16/20 | Batch: 121/228 | Loss: 0.4070
Epoch: 16/20 | Batch: 131/228 | Loss: 0.3891
Epoch: 16/20 | Batch: 141/228 | Loss: 0.3051
Epoch: 16/20 | Batch: 151/228 | Loss: 0.4700
Epoch: 16/20 | Batch: 161/228 | Loss: 0.6153
Epoch: 16/20 | Batch: 171/228 | Loss: 0.2566
Epoch: 16/20 | Batch: 181/228 | Loss: 0.6539
Epoch: 16/20 | Batch: 191/228 | Loss: 0.3316
Epoch: 16/20 | Batch: 201/228 | Loss: 0.4437
Epoch: 16/20 | Batch: 211/228 | Loss: 0.0774
Epoch: 16/20 | Batch: 221/228 | Loss: 0.2227
Epoch: 16/20 | Train Loss: 0.3057 | Train Acc: 92.46% | Val Loss: 0.3066 | Val Acc: 90.56%
Current learning rate: 0.0001
Current learning rate: 0.0001
Current learning rate: 0.0001
Current learning rate: 0.0001
Current learning rate: 0.0001
Current learning rate: 0.0001
Current learning rate: 0.0001
Epoch: 17/20 | Batch: 1/228 | Loss: 0.4855
Epoch: 17/20 | Batch: 11/228 | Loss: 0.1347
Epoch: 17/20 | Batch: 21/228 | Loss: 0.3215
Epoch: 17/20 | Batch: 31/228 | Loss: 0.2100
Epoch: 17/20 | Batch: 41/228 | Loss: 0.3758
Epoch: 17/20 | Batch: 51/228 | Loss: 0.4950
Epoch: 17/20 | Batch: 61/228 | Loss: 0.7067
Epoch: 17/20 | Batch: 71/228 | Loss: 0.1924
Epoch: 17/20 | Batch: 81/228 | Loss: 0.3161
Epoch: 17/20 | Batch: 91/228 | Loss: 0.2182
Epoch: 17/20 | Batch: 101/228 | Loss: 0.1409
Epoch: 17/20 | Batch: 111/228 | Loss: 0.2225
Epoch: 17/20 | Batch: 121/228 | Loss: 0.2868
Epoch: 17/20 | Batch: 131/228 | Loss: 0.1660
Epoch: 17/20 | Batch: 141/228 | Loss: 0.5717
Epoch: 17/20 | Batch: 151/228 | Loss: 0.3103
Epoch: 17/20 | Batch: 161/228 | Loss: 0.2656
Epoch: 17/20 | Batch: 171/228 | Loss: 0.4488
Epoch: 17/20 | Batch: 181/228 | Loss: 0.1060
Epoch: 17/20 | Batch: 191/228 | Loss: 0.1517
Epoch: 17/20 | Batch: 201/228 | Loss: 0.0749
Epoch: 17/20 | Batch: 211/228 | Loss: 0.4900
Epoch: 17/20 | Batch: 221/228 | Loss: 0.4891
Epoch: 17/20 | Train Loss: 0.2991 | Train Acc: 92.20% | Val Loss: 0.2882 | Val Acc: 91.58%
Current learning rate: 0.0001
Current learning rate: 0.0001
Current learning rate: 0.0001
Current learning rate: 0.0001
Current learning rate: 0.0001
Current learning rate: 0.0001
Current learning rate: 0.0001
Epoch: 18/20 | Batch: 1/228 | Loss: 0.3596
Epoch: 18/20 | Batch: 11/228 | Loss: 0.1818
Epoch: 18/20 | Batch: 21/228 | Loss: 0.2659
Epoch: 18/20 | Batch: 31/228 | Loss: 0.2250
Epoch: 18/20 | Batch: 41/228 | Loss: 0.3755
Epoch: 18/20 | Batch: 51/228 | Loss: 0.5496
Epoch: 18/20 | Batch: 61/228 | Loss: 0.0843
Epoch: 18/20 | Batch: 71/228 | Loss: 0.1623
Epoch: 18/20 | Batch: 81/228 | Loss: 0.1724
Epoch: 18/20 | Batch: 91/228 | Loss: 0.2037
Epoch: 18/20 | Batch: 101/228 | Loss: 0.0657
Epoch: 18/20 | Batch: 111/228 | Loss: 0.1717
Epoch: 18/20 | Batch: 121/228 | Loss: 0.2385
Epoch: 18/20 | Batch: 131/228 | Loss: 0.2839
Epoch: 18/20 | Batch: 141/228 | Loss: 0.5184
Epoch: 18/20 | Batch: 151/228 | Loss: 0.2611
Epoch: 18/20 | Batch: 161/228 | Loss: 0.3053
Epoch: 18/20 | Batch: 171/228 | Loss: 0.4076
Epoch: 18/20 | Batch: 181/228 | Loss: 0.1228
Epoch: 18/20 | Batch: 191/228 | Loss: 0.4017
Epoch: 18/20 | Batch: 201/228 | Loss: 0.5988
Epoch: 18/20 | Batch: 211/228 | Loss: 0.1959
Epoch: 18/20 | Batch: 221/228 | Loss: 0.3609
Epoch: 18/20 | Train Loss: 0.3086 | Train Acc: 91.87% | Val Loss: 0.2701 | Val Acc: 92.65%
Current learning rate: 0.0001
Current learning rate: 0.0001
Current learning rate: 0.0001
Current learning rate: 0.0001
Current learning rate: 0.0001
Current learning rate: 0.0001
Current learning rate: 0.0001
Best accuracy: 92.65%
Model saved to checkpoints\resnet18_pretrained_best.pth
Epoch: 19/20 | Batch: 1/228 | Loss: 0.1838
Epoch: 19/20 | Batch: 11/228 | Loss: 0.2720
Epoch: 19/20 | Batch: 21/228 | Loss: 0.4368
Epoch: 19/20 | Batch: 31/228 | Loss: 0.2718
Epoch: 19/20 | Batch: 41/228 | Loss: 0.1324
Epoch: 19/20 | Batch: 51/228 | Loss: 0.0623
Epoch: 19/20 | Batch: 61/228 | Loss: 0.2863
Epoch: 19/20 | Batch: 71/228 | Loss: 0.1555
Epoch: 19/20 | Batch: 81/228 | Loss: 0.2685
Epoch: 19/20 | Batch: 91/228 | Loss: 0.2461
Epoch: 19/20 | Batch: 101/228 | Loss: 0.0759
Epoch: 19/20 | Batch: 111/228 | Loss: 0.4056
Epoch: 19/20 | Batch: 121/228 | Loss: 0.1503
Epoch: 19/20 | Batch: 131/228 | Loss: 0.2724
Epoch: 19/20 | Batch: 141/228 | Loss: 0.6548
Epoch: 19/20 | Batch: 151/228 | Loss: 0.5766
Epoch: 19/20 | Batch: 161/228 | Loss: 0.2200
Epoch: 19/20 | Batch: 171/228 | Loss: 0.0400
Epoch: 19/20 | Batch: 181/228 | Loss: 0.3662
Epoch: 19/20 | Batch: 191/228 | Loss: 0.5828
Epoch: 19/20 | Batch: 201/228 | Loss: 0.3123
Epoch: 19/20 | Batch: 211/228 | Loss: 0.3542
Epoch: 19/20 | Batch: 221/228 | Loss: 0.3422
Epoch: 19/20 | Train Loss: 0.2953 | Train Acc: 91.99% | Val Loss: 0.2755 | Val Acc: 91.58%
Current learning rate: 0.0001
Current learning rate: 0.0001
Current learning rate: 0.0001
Current learning rate: 0.0001
Current learning rate: 0.0001
Current learning rate: 0.0001
Current learning rate: 0.0001
Epoch: 20/20 | Batch: 1/228 | Loss: 0.2847
Epoch: 20/20 | Batch: 11/228 | Loss: 0.4585
Epoch: 20/20 | Batch: 21/228 | Loss: 0.2726
Epoch: 20/20 | Batch: 31/228 | Loss: 0.2251
Epoch: 20/20 | Batch: 41/228 | Loss: 0.2317
Epoch: 20/20 | Batch: 51/228 | Loss: 0.2803
Epoch: 20/20 | Batch: 61/228 | Loss: 0.5483
Epoch: 20/20 | Batch: 71/228 | Loss: 0.1579
Epoch: 20/20 | Batch: 81/228 | Loss: 0.5440
Epoch: 20/20 | Batch: 91/228 | Loss: 0.3071
Epoch: 20/20 | Batch: 101/228 | Loss: 0.2051
Epoch: 20/20 | Batch: 111/228 | Loss: 0.3011
Epoch: 20/20 | Batch: 121/228 | Loss: 0.2821
Epoch: 20/20 | Batch: 131/228 | Loss: 0.2048
Epoch: 20/20 | Batch: 141/228 | Loss: 0.5174
Epoch: 20/20 | Batch: 151/228 | Loss: 0.3795
Epoch: 20/20 | Batch: 161/228 | Loss: 0.0426
Epoch: 20/20 | Batch: 171/228 | Loss: 0.2346
Epoch: 20/20 | Batch: 181/228 | Loss: 0.1852
Epoch: 20/20 | Batch: 191/228 | Loss: 0.2074
Epoch: 20/20 | Batch: 201/228 | Loss: 0.2483
Epoch: 20/20 | Batch: 211/228 | Loss: 0.1670
Epoch: 20/20 | Batch: 221/228 | Loss: 0.1622
Epoch: 20/20 | Train Loss: 0.2882 | Train Acc: 92.34% | Val Loss: 0.3057 | Val Acc: 91.36%
Current learning rate: 0.0001
Current learning rate: 0.0001
Current learning rate: 0.0001
Current learning rate: 0.0001
Current learning rate: 0.0001
Current learning rate: 0.0001
Current learning rate: 0.0001

(base) C:\Users\26336\Desktop\FDU\神经网络\home_work_2>
(base) C:\Users\26336\Desktop\FDU\神经网络\home_work_2>
(base) C:\Users\26336\Desktop\FDU\神经网络\home_work_2>python main.py

(base) C:\Users\26336\Desktop\FDU\神经网络\home_work_2>
(base) C:\Users\26336\Desktop\FDU\神经网络\home_work_2>
(base) C:\Users\26336\Desktop\FDU\神经网络\home_work_2>python main.py
Training with pretrained weights...
Number of classes: 102
Class names: ['BACKGROUND_Google', 'Faces', 'Faces_easy', 'Leopards', 'Motorbikes', 'accordion', 'airplanes', 'anchor', 'ant', 'barrel', 'bass', 'beaver', 'binocular', 'bonsai', 'brain', 'brontosaurus', 'buddha', 'butterfly', 'camera', 'cannon', 'car_side', 'ceiling_fan', 'cellphone', 'chair', 'chandelier', 'cougar_body', 'cougar_face', 'crab', 'crayfish', 'crocodile', 'crocodile_head', 'cup', 'dalmatian', 'dollar_bill', 'dolphin', 'dragonfly', 'electric_guitar', 'elephant', 'emu', 'euphonium', 'ewer', 'ferry', 'flamingo', 'flamingo_head', 'garfield', 'gerenuk', 'gramophone', 'grand_piano', 'hawksbill', 'headphone', 'hedgehog', 'helicopter', 'ibis', 'inline_skate', 'joshua_tree', 'kangaroo', 'ketch', 'lamp', 'laptop', 'llama', 'lobster', 'lotus', 'mandolin', 'mayfly', 'menorah', 'metronome', 'minaret', 'nautilus', 'octopus', 'okapi', 'pagoda', 'panda', 'pigeon', 'pizza', 'platypus', 'pyramid', 'revolver', 'rhino', 'rooster', 'saxophone', 'schooner', 'scissors', 'scorpion', 'sea_horse', 'snoopy', 'soccer_ball', 'stapler', 'starfish', 'stegosaurus', 'stop_sign', 'strawberry', 'sunflower', 'tick', 'trilobite', 'umbrella', 'watch', 'water_lilly', 'wheelchair', 'wild_cat', 'windsor_chair', 'wrench', 'yin_yang']
Training samples: 7280
Validation samples: 1864
Epoch: 1/20 | Batch: 1/228 | Loss: 4.6503
Epoch: 1/20 | Batch: 11/228 | Loss: 4.3572
Epoch: 1/20 | Batch: 21/228 | Loss: 4.6634
Epoch: 1/20 | Batch: 31/228 | Loss: 4.1178
Epoch: 1/20 | Batch: 41/228 | Loss: 4.2648
Epoch: 1/20 | Batch: 51/228 | Loss: 4.0422
Epoch: 1/20 | Batch: 61/228 | Loss: 4.1515
Epoch: 1/20 | Batch: 71/228 | Loss: 4.2900
Epoch: 1/20 | Batch: 81/228 | Loss: 3.3041
Epoch: 1/20 | Batch: 91/228 | Loss: 3.4611
Epoch: 1/20 | Batch: 101/228 | Loss: 3.7042
Epoch: 1/20 | Batch: 111/228 | Loss: 3.6934
Epoch: 1/20 | Batch: 121/228 | Loss: 3.5245
Epoch: 1/20 | Batch: 131/228 | Loss: 3.0123
Epoch: 1/20 | Batch: 141/228 | Loss: 3.7176
Epoch: 1/20 | Batch: 151/228 | Loss: 3.1689
Epoch: 1/20 | Batch: 161/228 | Loss: 3.2910
Epoch: 1/20 | Batch: 171/228 | Loss: 3.8186
Epoch: 1/20 | Batch: 181/228 | Loss: 3.4666
Epoch: 1/20 | Batch: 191/228 | Loss: 3.1973
Epoch: 1/20 | Batch: 201/228 | Loss: 3.2797
Epoch: 1/20 | Batch: 211/228 | Loss: 3.3811
Epoch: 1/20 | Batch: 221/228 | Loss: 3.2976
Epoch: 1/20 | Train Loss: 3.7473 | Train Acc: 21.61% | Val Loss: 3.1591 | Val Acc: 31.12%
Current learning rate: 0.0001
Best accuracy: 31.12%
Model saved to checkpoints\resnet18_scratch_best.pth
Epoch: 2/20 | Batch: 1/228 | Loss: 3.2025
Epoch: 2/20 | Batch: 11/228 | Loss: 3.2692
Epoch: 2/20 | Batch: 21/228 | Loss: 3.8440
Epoch: 2/20 | Batch: 31/228 | Loss: 3.3210
Epoch: 2/20 | Batch: 41/228 | Loss: 3.6879
Epoch: 2/20 | Batch: 51/228 | Loss: 3.5929
Epoch: 2/20 | Batch: 61/228 | Loss: 2.9651
Epoch: 2/20 | Batch: 71/228 | Loss: 3.4931
Epoch: 2/20 | Batch: 81/228 | Loss: 2.9284
Epoch: 2/20 | Batch: 91/228 | Loss: 3.5294
Epoch: 2/20 | Batch: 101/228 | Loss: 3.6137
Epoch: 2/20 | Batch: 111/228 | Loss: 3.3625
Epoch: 2/20 | Batch: 121/228 | Loss: 3.2428
Epoch: 2/20 | Batch: 131/228 | Loss: 2.8521
Epoch: 2/20 | Batch: 141/228 | Loss: 3.4173
Epoch: 2/20 | Batch: 151/228 | Loss: 2.9451
Epoch: 2/20 | Batch: 161/228 | Loss: 3.4130
Epoch: 2/20 | Batch: 171/228 | Loss: 3.4645
Epoch: 2/20 | Batch: 181/228 | Loss: 3.3596
Epoch: 2/20 | Batch: 191/228 | Loss: 3.1552
Epoch: 2/20 | Batch: 201/228 | Loss: 3.0213
Epoch: 2/20 | Batch: 211/228 | Loss: 2.6592
Epoch: 2/20 | Batch: 221/228 | Loss: 3.0034
Epoch: 2/20 | Train Loss: 3.2606 | Train Acc: 27.95% | Val Loss: 2.9096 | Val Acc: 32.46%
Current learning rate: 0.0001
Best accuracy: 32.46%
Model saved to checkpoints\resnet18_scratch_best.pth
Epoch: 3/20 | Batch: 1/228 | Loss: 2.9677
Epoch: 3/20 | Batch: 11/228 | Loss: 2.9899
Epoch: 3/20 | Batch: 21/228 | Loss: 3.1001
Epoch: 3/20 | Batch: 31/228 | Loss: 2.3955
Epoch: 3/20 | Batch: 41/228 | Loss: 2.6657
Epoch: 3/20 | Batch: 51/228 | Loss: 3.1066
Epoch: 3/20 | Batch: 61/228 | Loss: 3.2936
Epoch: 3/20 | Batch: 71/228 | Loss: 2.9334
Epoch: 3/20 | Batch: 81/228 | Loss: 2.8699
Epoch: 3/20 | Batch: 91/228 | Loss: 3.1656
Epoch: 3/20 | Batch: 101/228 | Loss: 2.5877
Epoch: 3/20 | Batch: 111/228 | Loss: 3.0483
Epoch: 3/20 | Batch: 121/228 | Loss: 2.8583
Epoch: 3/20 | Batch: 131/228 | Loss: 3.7625
Epoch: 3/20 | Batch: 141/228 | Loss: 2.9183
Epoch: 3/20 | Batch: 151/228 | Loss: 2.6650
Epoch: 3/20 | Batch: 161/228 | Loss: 2.5511
Epoch: 3/20 | Batch: 171/228 | Loss: 3.9697
Epoch: 3/20 | Batch: 181/228 | Loss: 3.0283
Epoch: 3/20 | Batch: 191/228 | Loss: 3.1286
Epoch: 3/20 | Batch: 201/228 | Loss: 3.5050
Epoch: 3/20 | Batch: 211/228 | Loss: 2.7494
Epoch: 3/20 | Batch: 221/228 | Loss: 3.0934
Epoch: 3/20 | Train Loss: 2.9997 | Train Acc: 31.83% | Val Loss: 2.7800 | Val Acc: 32.67%
Current learning rate: 0.0001
Best accuracy: 32.67%
Model saved to checkpoints\resnet18_scratch_best.pth
Epoch: 4/20 | Batch: 1/228 | Loss: 3.2144
Epoch: 4/20 | Batch: 11/228 | Loss: 2.9252
Epoch: 4/20 | Batch: 21/228 | Loss: 3.3978
Epoch: 4/20 | Batch: 31/228 | Loss: 3.2915
Epoch: 4/20 | Batch: 41/228 | Loss: 3.0219
Epoch: 4/20 | Batch: 51/228 | Loss: 3.5533
Epoch: 4/20 | Batch: 61/228 | Loss: 2.7179
Epoch: 4/20 | Batch: 71/228 | Loss: 2.7244
Epoch: 4/20 | Batch: 81/228 | Loss: 3.0467
Epoch: 4/20 | Batch: 91/228 | Loss: 2.8375
Epoch: 4/20 | Batch: 101/228 | Loss: 2.9462
Epoch: 4/20 | Batch: 111/228 | Loss: 2.6520
Epoch: 4/20 | Batch: 121/228 | Loss: 2.3356
Epoch: 4/20 | Batch: 131/228 | Loss: 2.9402
Epoch: 4/20 | Batch: 141/228 | Loss: 2.5141
Epoch: 4/20 | Batch: 151/228 | Loss: 2.5218
Epoch: 4/20 | Batch: 161/228 | Loss: 2.7490
Epoch: 4/20 | Batch: 171/228 | Loss: 2.2317
Epoch: 4/20 | Batch: 181/228 | Loss: 2.9196
Epoch: 4/20 | Batch: 191/228 | Loss: 3.0654
Epoch: 4/20 | Batch: 201/228 | Loss: 2.9128
Epoch: 4/20 | Batch: 211/228 | Loss: 2.5400
Epoch: 4/20 | Batch: 221/228 | Loss: 3.2275
Epoch: 4/20 | Train Loss: 2.8304 | Train Acc: 34.52% | Val Loss: 2.4363 | Val Acc: 41.15%
Current learning rate: 0.0001
Best accuracy: 41.15%
Model saved to checkpoints\resnet18_scratch_best.pth
Epoch: 5/20 | Batch: 1/228 | Loss: 2.3583
Epoch: 5/20 | Batch: 11/228 | Loss: 2.6379
Epoch: 5/20 | Batch: 21/228 | Loss: 2.8722
Epoch: 5/20 | Batch: 31/228 | Loss: 3.1415
Epoch: 5/20 | Batch: 41/228 | Loss: 2.1101
Epoch: 5/20 | Batch: 51/228 | Loss: 2.4642
Epoch: 5/20 | Batch: 61/228 | Loss: 2.4528
Epoch: 5/20 | Batch: 71/228 | Loss: 2.5747
Epoch: 5/20 | Batch: 81/228 | Loss: 2.8106
Epoch: 5/20 | Batch: 91/228 | Loss: 2.2398
Epoch: 5/20 | Batch: 101/228 | Loss: 2.5541
Epoch: 5/20 | Batch: 111/228 | Loss: 2.9726
Epoch: 5/20 | Batch: 121/228 | Loss: 2.4557
Epoch: 5/20 | Batch: 131/228 | Loss: 2.0323
Epoch: 5/20 | Batch: 141/228 | Loss: 2.7412
Epoch: 5/20 | Batch: 151/228 | Loss: 2.6725
Epoch: 5/20 | Batch: 161/228 | Loss: 2.2533
Epoch: 5/20 | Batch: 171/228 | Loss: 2.8734
Epoch: 5/20 | Batch: 181/228 | Loss: 2.1405
Epoch: 5/20 | Batch: 191/228 | Loss: 3.3324
Epoch: 5/20 | Batch: 201/228 | Loss: 2.6507
Epoch: 5/20 | Batch: 211/228 | Loss: 2.8903
Epoch: 5/20 | Batch: 221/228 | Loss: 2.3252
Epoch: 5/20 | Train Loss: 2.6611 | Train Acc: 37.57% | Val Loss: 2.3481 | Val Acc: 40.08%
Current learning rate: 0.0001
Epoch: 6/20 | Batch: 1/228 | Loss: 1.9956
Epoch: 6/20 | Batch: 11/228 | Loss: 2.7341
Epoch: 6/20 | Batch: 21/228 | Loss: 2.2838
Epoch: 6/20 | Batch: 31/228 | Loss: 3.3554
Epoch: 6/20 | Batch: 41/228 | Loss: 2.9471
Epoch: 6/20 | Batch: 51/228 | Loss: 2.6476
Epoch: 6/20 | Batch: 61/228 | Loss: 2.9683
Epoch: 6/20 | Batch: 71/228 | Loss: 2.3940
Epoch: 6/20 | Batch: 81/228 | Loss: 2.7809
Epoch: 6/20 | Batch: 91/228 | Loss: 2.4638
Epoch: 6/20 | Batch: 101/228 | Loss: 2.5543
Epoch: 6/20 | Batch: 111/228 | Loss: 2.0098
Epoch: 6/20 | Batch: 121/228 | Loss: 2.5632
Epoch: 6/20 | Batch: 131/228 | Loss: 2.4070
Epoch: 6/20 | Batch: 141/228 | Loss: 2.5752
Epoch: 6/20 | Batch: 151/228 | Loss: 2.2123
Epoch: 6/20 | Batch: 161/228 | Loss: 2.5090
Epoch: 6/20 | Batch: 171/228 | Loss: 2.1326
Epoch: 6/20 | Batch: 181/228 | Loss: 2.5029
Epoch: 6/20 | Batch: 191/228 | Loss: 2.2346
Epoch: 6/20 | Batch: 201/228 | Loss: 2.4194
Epoch: 6/20 | Batch: 211/228 | Loss: 2.0017
Epoch: 6/20 | Batch: 221/228 | Loss: 2.4593
Epoch: 6/20 | Train Loss: 2.5149 | Train Acc: 40.58% | Val Loss: 2.2418 | Val Acc: 43.29%
Current learning rate: 0.0001
Best accuracy: 43.29%
Model saved to checkpoints\resnet18_scratch_best.pth
Epoch: 7/20 | Batch: 1/228 | Loss: 2.2103
Epoch: 7/20 | Batch: 11/228 | Loss: 2.4320
Epoch: 7/20 | Batch: 21/228 | Loss: 2.5544
Epoch: 7/20 | Batch: 31/228 | Loss: 1.8702
Epoch: 7/20 | Batch: 41/228 | Loss: 2.3462
Epoch: 7/20 | Batch: 51/228 | Loss: 2.5938
Epoch: 7/20 | Batch: 61/228 | Loss: 2.9040
Epoch: 7/20 | Batch: 71/228 | Loss: 1.8728
Epoch: 7/20 | Batch: 81/228 | Loss: 2.2669
Epoch: 7/20 | Batch: 91/228 | Loss: 2.5521
Epoch: 7/20 | Batch: 101/228 | Loss: 2.2545
Epoch: 7/20 | Batch: 111/228 | Loss: 2.1171
Epoch: 7/20 | Batch: 121/228 | Loss: 2.7652
Epoch: 7/20 | Batch: 131/228 | Loss: 2.2860
Epoch: 7/20 | Batch: 141/228 | Loss: 3.0272
Epoch: 7/20 | Batch: 151/228 | Loss: 1.8163
Epoch: 7/20 | Batch: 161/228 | Loss: 1.9904
Epoch: 7/20 | Batch: 171/228 | Loss: 1.9773
Epoch: 7/20 | Batch: 181/228 | Loss: 2.3680
Epoch: 7/20 | Batch: 191/228 | Loss: 1.8943
Epoch: 7/20 | Batch: 201/228 | Loss: 2.9145
Epoch: 7/20 | Batch: 211/228 | Loss: 2.3109
Epoch: 7/20 | Batch: 221/228 | Loss: 1.7925
Epoch: 7/20 | Train Loss: 2.3795 | Train Acc: 43.21% | Val Loss: 2.0900 | Val Acc: 47.75%
Current learning rate: 0.0001
Best accuracy: 47.75%
Model saved to checkpoints\resnet18_scratch_best.pth
Epoch: 8/20 | Batch: 1/228 | Loss: 1.8300
Epoch: 8/20 | Batch: 11/228 | Loss: 2.7302
Epoch: 8/20 | Batch: 21/228 | Loss: 3.1931
Epoch: 8/20 | Batch: 31/228 | Loss: 2.3019
Epoch: 8/20 | Batch: 41/228 | Loss: 2.3093
Epoch: 8/20 | Batch: 51/228 | Loss: 2.2126
Epoch: 8/20 | Batch: 61/228 | Loss: 2.7514
Epoch: 8/20 | Batch: 71/228 | Loss: 2.2200
Epoch: 8/20 | Batch: 81/228 | Loss: 2.3495
Epoch: 8/20 | Batch: 91/228 | Loss: 2.5190
Epoch: 8/20 | Batch: 101/228 | Loss: 1.9586
Epoch: 8/20 | Batch: 111/228 | Loss: 1.4797
Epoch: 8/20 | Batch: 121/228 | Loss: 2.3333
Epoch: 8/20 | Batch: 131/228 | Loss: 1.9617
Epoch: 8/20 | Batch: 141/228 | Loss: 1.9261
Epoch: 8/20 | Batch: 151/228 | Loss: 2.2460
Epoch: 8/20 | Batch: 161/228 | Loss: 2.0750
Epoch: 8/20 | Batch: 171/228 | Loss: 2.4833
Epoch: 8/20 | Batch: 181/228 | Loss: 2.0197
Epoch: 8/20 | Batch: 191/228 | Loss: 1.9912
Epoch: 8/20 | Batch: 201/228 | Loss: 2.5822
Epoch: 8/20 | Batch: 211/228 | Loss: 2.2134
Epoch: 8/20 | Batch: 221/228 | Loss: 2.4937
Epoch: 8/20 | Train Loss: 2.2915 | Train Acc: 44.64% | Val Loss: 1.9970 | Val Acc: 50.80%
Current learning rate: 0.0001
Best accuracy: 50.80%
Model saved to checkpoints\resnet18_scratch_best.pth
Epoch: 9/20 | Batch: 1/228 | Loss: 1.7799
Epoch: 9/20 | Batch: 11/228 | Loss: 2.0359
Epoch: 9/20 | Batch: 21/228 | Loss: 1.9868
Epoch: 9/20 | Batch: 31/228 | Loss: 1.6861
Epoch: 9/20 | Batch: 41/228 | Loss: 2.5292
Epoch: 9/20 | Batch: 51/228 | Loss: 1.9826
Epoch: 9/20 | Batch: 61/228 | Loss: 1.8956
Epoch: 9/20 | Batch: 71/228 | Loss: 1.7688
Epoch: 9/20 | Batch: 81/228 | Loss: 2.4559
Epoch: 9/20 | Batch: 91/228 | Loss: 1.9501
Epoch: 9/20 | Batch: 101/228 | Loss: 2.2217
Epoch: 9/20 | Batch: 111/228 | Loss: 2.1655
Epoch: 9/20 | Batch: 121/228 | Loss: 1.9691
Epoch: 9/20 | Batch: 131/228 | Loss: 2.3565
Epoch: 9/20 | Batch: 141/228 | Loss: 2.0522
Epoch: 9/20 | Batch: 151/228 | Loss: 3.0155
Epoch: 9/20 | Batch: 161/228 | Loss: 2.6850
Epoch: 9/20 | Batch: 171/228 | Loss: 2.3608
Epoch: 9/20 | Batch: 181/228 | Loss: 2.5166
Epoch: 9/20 | Batch: 191/228 | Loss: 1.9880
Epoch: 9/20 | Batch: 201/228 | Loss: 2.4278
Epoch: 9/20 | Batch: 211/228 | Loss: 1.9370
Epoch: 9/20 | Batch: 221/228 | Loss: 1.9860
Epoch: 9/20 | Train Loss: 2.1683 | Train Acc: 46.92% | Val Loss: 1.8737 | Val Acc: 53.38%
Current learning rate: 0.0001
Best accuracy: 53.38%
Model saved to checkpoints\resnet18_scratch_best.pth
Epoch: 10/20 | Batch: 1/228 | Loss: 1.9658
Epoch: 10/20 | Batch: 11/228 | Loss: 1.7752
Epoch: 10/20 | Batch: 21/228 | Loss: 1.9081
Epoch: 10/20 | Batch: 31/228 | Loss: 2.1868
Epoch: 10/20 | Batch: 41/228 | Loss: 1.8802
Epoch: 10/20 | Batch: 51/228 | Loss: 2.5557
Epoch: 10/20 | Batch: 61/228 | Loss: 2.1115
Epoch: 10/20 | Batch: 71/228 | Loss: 2.3567
Epoch: 10/20 | Batch: 81/228 | Loss: 1.9802
Epoch: 10/20 | Batch: 91/228 | Loss: 1.9955
Epoch: 10/20 | Batch: 101/228 | Loss: 1.8978
Epoch: 10/20 | Batch: 111/228 | Loss: 2.4482
Epoch: 10/20 | Batch: 121/228 | Loss: 2.1742
Epoch: 10/20 | Batch: 131/228 | Loss: 2.4795
Epoch: 10/20 | Batch: 141/228 | Loss: 2.2852
Epoch: 10/20 | Batch: 151/228 | Loss: 2.0967
Epoch: 10/20 | Batch: 161/228 | Loss: 2.1725
Epoch: 10/20 | Batch: 171/228 | Loss: 2.7576
Epoch: 10/20 | Batch: 181/228 | Loss: 2.1305
Epoch: 10/20 | Batch: 191/228 | Loss: 2.0365
Epoch: 10/20 | Batch: 201/228 | Loss: 2.5834
Epoch: 10/20 | Batch: 211/228 | Loss: 2.1938
Epoch: 10/20 | Batch: 221/228 | Loss: 1.9829
Epoch: 10/20 | Train Loss: 2.1072 | Train Acc: 48.68% | Val Loss: 1.8871 | Val Acc: 52.31%
Current learning rate: 0.0001
Epoch: 11/20 | Batch: 1/228 | Loss: 2.1269
Epoch: 11/20 | Batch: 11/228 | Loss: 2.3203
Epoch: 11/20 | Batch: 21/228 | Loss: 1.9981
Epoch: 11/20 | Batch: 31/228 | Loss: 1.7449
Epoch: 11/20 | Batch: 41/228 | Loss: 2.4225
Epoch: 11/20 | Batch: 51/228 | Loss: 2.0503
Epoch: 11/20 | Batch: 61/228 | Loss: 2.3137
Epoch: 11/20 | Batch: 71/228 | Loss: 2.1540
Epoch: 11/20 | Batch: 81/228 | Loss: 1.6746
Epoch: 11/20 | Batch: 91/228 | Loss: 1.9199
Epoch: 11/20 | Batch: 101/228 | Loss: 2.0676
Epoch: 11/20 | Batch: 111/228 | Loss: 2.4844
Epoch: 11/20 | Batch: 121/228 | Loss: 1.8147
Epoch: 11/20 | Batch: 131/228 | Loss: 1.5959
Epoch: 11/20 | Batch: 141/228 | Loss: 2.0632
Epoch: 11/20 | Batch: 151/228 | Loss: 2.2140
Epoch: 11/20 | Batch: 161/228 | Loss: 1.9351
Epoch: 11/20 | Batch: 171/228 | Loss: 2.2809
Epoch: 11/20 | Batch: 181/228 | Loss: 2.2374
Epoch: 11/20 | Batch: 191/228 | Loss: 1.6124
Epoch: 11/20 | Batch: 201/228 | Loss: 2.5182
Epoch: 11/20 | Batch: 211/228 | Loss: 1.7433
Epoch: 11/20 | Batch: 221/228 | Loss: 1.5213
Epoch: 11/20 | Train Loss: 2.0046 | Train Acc: 50.41% | Val Loss: 1.6602 | Val Acc: 57.03%
Current learning rate: 0.0001
Best accuracy: 57.03%
Model saved to checkpoints\resnet18_scratch_best.pth
Epoch: 12/20 | Batch: 1/228 | Loss: 1.7658
Epoch: 12/20 | Batch: 11/228 | Loss: 1.9171
Epoch: 12/20 | Batch: 21/228 | Loss: 2.0304
Epoch: 12/20 | Batch: 31/228 | Loss: 1.7558
Epoch: 12/20 | Batch: 41/228 | Loss: 1.6265
Epoch: 12/20 | Batch: 51/228 | Loss: 1.4938
Epoch: 12/20 | Batch: 61/228 | Loss: 2.0057
Epoch: 12/20 | Batch: 71/228 | Loss: 1.9409
Epoch: 12/20 | Batch: 81/228 | Loss: 2.3983
Epoch: 12/20 | Batch: 91/228 | Loss: 2.3952
Epoch: 12/20 | Batch: 101/228 | Loss: 2.4618
Epoch: 12/20 | Batch: 111/228 | Loss: 1.7688
Epoch: 12/20 | Batch: 121/228 | Loss: 1.8118
Epoch: 12/20 | Batch: 131/228 | Loss: 2.2987
Epoch: 12/20 | Batch: 141/228 | Loss: 2.0239
Epoch: 12/20 | Batch: 151/228 | Loss: 1.7391
Epoch: 12/20 | Batch: 161/228 | Loss: 2.0553
Epoch: 12/20 | Batch: 171/228 | Loss: 1.7115
Epoch: 12/20 | Batch: 181/228 | Loss: 1.5369
Epoch: 12/20 | Batch: 191/228 | Loss: 1.6867
Epoch: 12/20 | Batch: 201/228 | Loss: 2.3888
Epoch: 12/20 | Batch: 211/228 | Loss: 2.0259
Epoch: 12/20 | Batch: 221/228 | Loss: 1.4392
Epoch: 12/20 | Train Loss: 1.9294 | Train Acc: 51.40% | Val Loss: 1.6650 | Val Acc: 57.30%
Current learning rate: 0.0001
Best accuracy: 57.30%
Model saved to checkpoints\resnet18_scratch_best.pth
Epoch: 13/20 | Batch: 1/228 | Loss: 1.9166
Epoch: 13/20 | Batch: 11/228 | Loss: 2.0650
Epoch: 13/20 | Batch: 21/228 | Loss: 1.7203
Epoch: 13/20 | Batch: 31/228 | Loss: 1.5931
Epoch: 13/20 | Batch: 41/228 | Loss: 1.9381
Epoch: 13/20 | Batch: 51/228 | Loss: 2.0504
Epoch: 13/20 | Batch: 61/228 | Loss: 2.2563
Epoch: 13/20 | Batch: 71/228 | Loss: 2.0147
Epoch: 13/20 | Batch: 81/228 | Loss: 1.4260
Epoch: 13/20 | Batch: 91/228 | Loss: 1.9137
Epoch: 13/20 | Batch: 101/228 | Loss: 2.2126
Epoch: 13/20 | Batch: 111/228 | Loss: 2.0141
Epoch: 13/20 | Batch: 121/228 | Loss: 1.6998
Epoch: 13/20 | Batch: 131/228 | Loss: 1.2568
Epoch: 13/20 | Batch: 141/228 | Loss: 1.8374
Epoch: 13/20 | Batch: 151/228 | Loss: 1.5902
Epoch: 13/20 | Batch: 161/228 | Loss: 1.7320
Epoch: 13/20 | Batch: 171/228 | Loss: 1.7484
Epoch: 13/20 | Batch: 181/228 | Loss: 1.7808
Epoch: 13/20 | Batch: 191/228 | Loss: 1.8467
Epoch: 13/20 | Batch: 201/228 | Loss: 1.5589
Epoch: 13/20 | Batch: 211/228 | Loss: 1.3926
Epoch: 13/20 | Batch: 221/228 | Loss: 1.7598
Epoch: 13/20 | Train Loss: 1.8458 | Train Acc: 54.01% | Val Loss: 1.5599 | Val Acc: 61.21%
Current learning rate: 0.0001
Best accuracy: 61.21%
Model saved to checkpoints\resnet18_scratch_best.pth
Epoch: 14/20 | Batch: 1/228 | Loss: 2.0954
Epoch: 14/20 | Batch: 11/228 | Loss: 2.0583
Epoch: 14/20 | Batch: 21/228 | Loss: 2.0520
Epoch: 14/20 | Batch: 31/228 | Loss: 2.2097
Epoch: 14/20 | Batch: 41/228 | Loss: 1.7485
Epoch: 14/20 | Batch: 51/228 | Loss: 1.5291
Epoch: 14/20 | Batch: 61/228 | Loss: 2.0387
Epoch: 14/20 | Batch: 71/228 | Loss: 1.6151
Epoch: 14/20 | Batch: 81/228 | Loss: 1.6576
Epoch: 14/20 | Batch: 91/228 | Loss: 1.8376
Epoch: 14/20 | Batch: 101/228 | Loss: 1.6309
Epoch: 14/20 | Batch: 111/228 | Loss: 1.9929
Epoch: 14/20 | Batch: 121/228 | Loss: 1.5595
Epoch: 14/20 | Batch: 131/228 | Loss: 1.2500
Epoch: 14/20 | Batch: 141/228 | Loss: 1.4990
Epoch: 14/20 | Batch: 151/228 | Loss: 1.1931
Epoch: 14/20 | Batch: 161/228 | Loss: 1.8738
Epoch: 14/20 | Batch: 171/228 | Loss: 2.1922
Epoch: 14/20 | Batch: 181/228 | Loss: 2.0212
Epoch: 14/20 | Batch: 191/228 | Loss: 1.9482
Epoch: 14/20 | Batch: 201/228 | Loss: 2.0977
Epoch: 14/20 | Batch: 211/228 | Loss: 1.7816
Epoch: 14/20 | Batch: 221/228 | Loss: 1.4635
Epoch: 14/20 | Train Loss: 1.8048 | Train Acc: 55.49% | Val Loss: 1.4961 | Val Acc: 60.68%
Current learning rate: 0.0001
Epoch: 15/20 | Batch: 1/228 | Loss: 1.6820
Epoch: 15/20 | Batch: 11/228 | Loss: 1.4501
Epoch: 15/20 | Batch: 21/228 | Loss: 1.8307
Epoch: 15/20 | Batch: 31/228 | Loss: 1.7426
Epoch: 15/20 | Batch: 41/228 | Loss: 1.1310
Epoch: 15/20 | Batch: 51/228 | Loss: 1.4206
Epoch: 15/20 | Batch: 61/228 | Loss: 1.4418
Epoch: 15/20 | Batch: 71/228 | Loss: 1.9307
Epoch: 15/20 | Batch: 81/228 | Loss: 1.7804
Epoch: 15/20 | Batch: 91/228 | Loss: 1.3331
Epoch: 15/20 | Batch: 101/228 | Loss: 1.8180
Epoch: 15/20 | Batch: 111/228 | Loss: 1.5966
Epoch: 15/20 | Batch: 121/228 | Loss: 2.0822
Epoch: 15/20 | Batch: 131/228 | Loss: 1.7822
Epoch: 15/20 | Batch: 141/228 | Loss: 1.5208
Epoch: 15/20 | Batch: 151/228 | Loss: 1.9163
Epoch: 15/20 | Batch: 161/228 | Loss: 1.8516
Epoch: 15/20 | Batch: 171/228 | Loss: 1.8561
Epoch: 15/20 | Batch: 181/228 | Loss: 2.1921
Epoch: 15/20 | Batch: 191/228 | Loss: 1.8413
Epoch: 15/20 | Batch: 201/228 | Loss: 1.8794
Epoch: 15/20 | Batch: 211/228 | Loss: 1.7766
Epoch: 15/20 | Batch: 221/228 | Loss: 1.2653
Epoch: 15/20 | Train Loss: 1.7448 | Train Acc: 55.91% | Val Loss: 1.5988 | Val Acc: 59.01%
Current learning rate: 0.0001
Epoch: 16/20 | Batch: 1/228 | Loss: 1.6499
Epoch: 16/20 | Batch: 11/228 | Loss: 1.9950
Epoch: 16/20 | Batch: 21/228 | Loss: 1.6799
Epoch: 16/20 | Batch: 31/228 | Loss: 1.3545
Epoch: 16/20 | Batch: 41/228 | Loss: 1.6071
Epoch: 16/20 | Batch: 51/228 | Loss: 1.9865
Epoch: 16/20 | Batch: 61/228 | Loss: 1.4839
Epoch: 16/20 | Batch: 71/228 | Loss: 1.9749
Epoch: 16/20 | Batch: 81/228 | Loss: 1.9869
Epoch: 16/20 | Batch: 91/228 | Loss: 1.6176
Epoch: 16/20 | Batch: 101/228 | Loss: 1.6679
Epoch: 16/20 | Batch: 111/228 | Loss: 1.6854
Epoch: 16/20 | Batch: 121/228 | Loss: 1.7496
Epoch: 16/20 | Batch: 131/228 | Loss: 1.3978
Epoch: 16/20 | Batch: 141/228 | Loss: 1.5017
Epoch: 16/20 | Batch: 151/228 | Loss: 1.5422
Epoch: 16/20 | Batch: 161/228 | Loss: 1.8553
Epoch: 16/20 | Batch: 171/228 | Loss: 1.5695
Epoch: 16/20 | Batch: 181/228 | Loss: 1.8254
Epoch: 16/20 | Batch: 191/228 | Loss: 1.4904
Epoch: 16/20 | Batch: 201/228 | Loss: 1.4171
Epoch: 16/20 | Batch: 211/228 | Loss: 2.0330
Epoch: 16/20 | Batch: 221/228 | Loss: 1.7446
Epoch: 16/20 | Train Loss: 1.6787 | Train Acc: 57.39% | Val Loss: 1.4309 | Val Acc: 61.32%
Current learning rate: 0.0001
Best accuracy: 61.32%
Model saved to checkpoints\resnet18_scratch_best.pth
Epoch: 17/20 | Batch: 1/228 | Loss: 1.8967
Epoch: 17/20 | Batch: 11/228 | Loss: 2.0294
Epoch: 17/20 | Batch: 21/228 | Loss: 2.1773
Epoch: 17/20 | Batch: 31/228 | Loss: 1.2385
Epoch: 17/20 | Batch: 41/228 | Loss: 1.7253
Epoch: 17/20 | Batch: 51/228 | Loss: 1.4754
Epoch: 17/20 | Batch: 61/228 | Loss: 1.3819
Epoch: 17/20 | Batch: 71/228 | Loss: 1.4216
Epoch: 17/20 | Batch: 81/228 | Loss: 0.9592
Epoch: 17/20 | Batch: 91/228 | Loss: 1.2616
Epoch: 17/20 | Batch: 101/228 | Loss: 1.7200
Epoch: 17/20 | Batch: 111/228 | Loss: 1.8918
Epoch: 17/20 | Batch: 121/228 | Loss: 1.6590
Epoch: 17/20 | Batch: 131/228 | Loss: 1.4187
Epoch: 17/20 | Batch: 141/228 | Loss: 1.5944
Epoch: 17/20 | Batch: 151/228 | Loss: 1.9212
Epoch: 17/20 | Batch: 161/228 | Loss: 1.6221
Epoch: 17/20 | Batch: 171/228 | Loss: 1.9125
Epoch: 17/20 | Batch: 181/228 | Loss: 1.2417
Epoch: 17/20 | Batch: 191/228 | Loss: 2.2676
Epoch: 17/20 | Batch: 201/228 | Loss: 1.9731
Epoch: 17/20 | Batch: 211/228 | Loss: 1.5979
Epoch: 17/20 | Batch: 221/228 | Loss: 1.3887
Epoch: 17/20 | Train Loss: 1.6643 | Train Acc: 58.15% | Val Loss: 1.4348 | Val Acc: 62.50%
Current learning rate: 0.0001
Best accuracy: 62.50%
Model saved to checkpoints\resnet18_scratch_best.pth
Epoch: 18/20 | Batch: 1/228 | Loss: 1.7588
Epoch: 18/20 | Batch: 11/228 | Loss: 1.4561
Epoch: 18/20 | Batch: 21/228 | Loss: 1.7943
Epoch: 18/20 | Batch: 31/228 | Loss: 1.9889
Epoch: 18/20 | Batch: 41/228 | Loss: 1.9225
Epoch: 18/20 | Batch: 51/228 | Loss: 1.7034
Epoch: 18/20 | Batch: 61/228 | Loss: 1.1647
Epoch: 18/20 | Batch: 71/228 | Loss: 1.5129
Epoch: 18/20 | Batch: 81/228 | Loss: 1.6627
Epoch: 18/20 | Batch: 91/228 | Loss: 2.0736
Epoch: 18/20 | Batch: 101/228 | Loss: 1.8082
Epoch: 18/20 | Batch: 111/228 | Loss: 1.7167
Epoch: 18/20 | Batch: 121/228 | Loss: 1.4304
Epoch: 18/20 | Batch: 131/228 | Loss: 1.9021
Epoch: 18/20 | Batch: 141/228 | Loss: 1.4342
Epoch: 18/20 | Batch: 151/228 | Loss: 1.6279
Epoch: 18/20 | Batch: 161/228 | Loss: 1.1737
Epoch: 18/20 | Batch: 171/228 | Loss: 1.7067
Epoch: 18/20 | Batch: 181/228 | Loss: 1.3497
Epoch: 18/20 | Batch: 191/228 | Loss: 1.1204
Epoch: 18/20 | Batch: 201/228 | Loss: 1.9180
Epoch: 18/20 | Batch: 211/228 | Loss: 1.7190
Epoch: 18/20 | Batch: 221/228 | Loss: 1.3355
Epoch: 18/20 | Train Loss: 1.6142 | Train Acc: 58.74% | Val Loss: 1.4539 | Val Acc: 62.50%
Current learning rate: 0.0001
Epoch: 19/20 | Batch: 1/228 | Loss: 1.7822
Epoch: 19/20 | Batch: 11/228 | Loss: 1.1921
Epoch: 19/20 | Batch: 21/228 | Loss: 1.9567
Epoch: 19/20 | Batch: 31/228 | Loss: 1.5549
Epoch: 19/20 | Batch: 41/228 | Loss: 1.7225
Epoch: 19/20 | Batch: 51/228 | Loss: 1.3157
Epoch: 19/20 | Batch: 61/228 | Loss: 1.4724
Epoch: 19/20 | Batch: 71/228 | Loss: 1.2267
Epoch: 19/20 | Batch: 81/228 | Loss: 1.4455
Epoch: 19/20 | Batch: 91/228 | Loss: 1.6134
Epoch: 19/20 | Batch: 101/228 | Loss: 1.0635
Epoch: 19/20 | Batch: 111/228 | Loss: 1.7910
Epoch: 19/20 | Batch: 121/228 | Loss: 2.2329
Epoch: 19/20 | Batch: 131/228 | Loss: 1.6827
Epoch: 19/20 | Batch: 141/228 | Loss: 1.1843
Epoch: 19/20 | Batch: 151/228 | Loss: 1.5930
Epoch: 19/20 | Batch: 161/228 | Loss: 1.5543
Epoch: 19/20 | Batch: 171/228 | Loss: 1.3970
Epoch: 19/20 | Batch: 181/228 | Loss: 2.1411
Epoch: 19/20 | Batch: 191/228 | Loss: 1.4081
Epoch: 19/20 | Batch: 201/228 | Loss: 1.3449
Epoch: 19/20 | Batch: 211/228 | Loss: 1.1129
Epoch: 19/20 | Batch: 221/228 | Loss: 1.2914
Epoch: 19/20 | Train Loss: 1.5464 | Train Acc: 60.45% | Val Loss: 1.3051 | Val Acc: 65.99%
Current learning rate: 0.0001
Best accuracy: 65.99%
Model saved to checkpoints\resnet18_scratch_best.pth
Epoch: 20/20 | Batch: 1/228 | Loss: 1.4437
Epoch: 20/20 | Batch: 11/228 | Loss: 1.4039
Epoch: 20/20 | Batch: 21/228 | Loss: 1.2127
Epoch: 20/20 | Batch: 31/228 | Loss: 1.7604
Epoch: 20/20 | Batch: 41/228 | Loss: 1.4789
Epoch: 20/20 | Batch: 51/228 | Loss: 1.2881
Epoch: 20/20 | Batch: 61/228 | Loss: 1.5637
Epoch: 20/20 | Batch: 71/228 | Loss: 1.2663
Epoch: 20/20 | Batch: 81/228 | Loss: 1.1548
Epoch: 20/20 | Batch: 91/228 | Loss: 1.6609
Epoch: 20/20 | Batch: 101/228 | Loss: 1.5055
Epoch: 20/20 | Batch: 111/228 | Loss: 1.4486
Epoch: 20/20 | Batch: 121/228 | Loss: 1.1073
Epoch: 20/20 | Batch: 131/228 | Loss: 1.3768
Epoch: 20/20 | Batch: 141/228 | Loss: 1.5722
Epoch: 20/20 | Batch: 151/228 | Loss: 1.1760
Epoch: 20/20 | Batch: 161/228 | Loss: 1.3636
Epoch: 20/20 | Batch: 171/228 | Loss: 1.1293
Epoch: 20/20 | Batch: 181/228 | Loss: 1.5599
Epoch: 20/20 | Batch: 191/228 | Loss: 1.9886
Epoch: 20/20 | Batch: 201/228 | Loss: 1.6208
Epoch: 20/20 | Batch: 211/228 | Loss: 1.4938
Epoch: 20/20 | Batch: 221/228 | Loss: 1.6247
Epoch: 20/20 | Train Loss: 1.5199 | Train Acc: 61.03% | Val Loss: 1.2819 | Val Acc: 66.63%
Current learning rate: 0.0001
Best accuracy: 66.63%
Model saved to checkpoints\resnet18_scratch_best.pth

(base) C:\Users\26336\Desktop\FDU\神经网络\home_work_2>
(base) C:\Users\26336\Desktop\FDU\神经网络\home_work_2>
(base) C:\Users\26336\Desktop\FDU\神经网络\home_work_2>
(base) C:\Users\26336\Desktop\FDU\神经网络\home_work_2>
(base) C:\Users\26336\Desktop\FDU\神经网络\home_work_2>python main.py
Training with pretrained weights...
Number of classes: 102
Class names: ['BACKGROUND_Google', 'Faces', 'Faces_easy', 'Leopards', 'Motorbikes', 'accordion', 'airplanes', 'anchor', 'ant', 'barrel', 'bass', 'beaver', 'binocular', 'bonsai', 'brain', 'brontosaurus', 'buddha', 'butterfly', 'camera', 'cannon', 'car_side', 'ceiling_fan', 'cellphone', 'chair', 'chandelier', 'cougar_body', 'cougar_face', 'crab', 'crayfish', 'crocodile', 'crocodile_head', 'cup', 'dalmatian', 'dollar_bill', 'dolphin', 'dragonfly', 'electric_guitar', 'elephant', 'emu', 'euphonium', 'ewer', 'ferry', 'flamingo', 'flamingo_head', 'garfield', 'gerenuk', 'gramophone', 'grand_piano', 'hawksbill', 'headphone', 'hedgehog', 'helicopter', 'ibis', 'inline_skate', 'joshua_tree', 'kangaroo', 'ketch', 'lamp', 'laptop', 'llama', 'lobster', 'lotus', 'mandolin', 'mayfly', 'menorah', 'metronome', 'minaret', 'nautilus', 'octopus', 'okapi', 'pagoda', 'panda', 'pigeon', 'pizza', 'platypus', 'pyramid', 'revolver', 'rhino', 'rooster', 'saxophone', 'schooner', 'scissors', 'scorpion', 'sea_horse', 'snoopy', 'soccer_ball', 'stapler', 'starfish', 'stegosaurus', 'stop_sign', 'strawberry', 'sunflower', 'tick', 'trilobite', 'umbrella', 'watch', 'water_lilly', 'wheelchair', 'wild_cat', 'windsor_chair', 'wrench', 'yin_yang']
Training samples: 7280
Validation samples: 1864
Epoch: 1/20 | Batch: 1/455 | Loss: 4.9373
Epoch: 1/20 | Batch: 11/455 | Loss: 4.3497
Epoch: 1/20 | Batch: 21/455 | Loss: 3.6869
Epoch: 1/20 | Batch: 31/455 | Loss: 3.6593
Epoch: 1/20 | Batch: 41/455 | Loss: 2.8861
Epoch: 1/20 | Batch: 51/455 | Loss: 2.8377
Epoch: 1/20 | Batch: 61/455 | Loss: 2.5729
Epoch: 1/20 | Batch: 71/455 | Loss: 2.6621
Epoch: 1/20 | Batch: 81/455 | Loss: 3.0618
Epoch: 1/20 | Batch: 91/455 | Loss: 3.1400
Epoch: 1/20 | Batch: 101/455 | Loss: 3.0799
Epoch: 1/20 | Batch: 111/455 | Loss: 2.0790
Epoch: 1/20 | Batch: 121/455 | Loss: 2.2455
Epoch: 1/20 | Batch: 131/455 | Loss: 1.8977
Epoch: 1/20 | Batch: 141/455 | Loss: 2.1935
Epoch: 1/20 | Batch: 151/455 | Loss: 2.2709
Epoch: 1/20 | Batch: 161/455 | Loss: 2.7885
Epoch: 1/20 | Batch: 171/455 | Loss: 1.7549
Epoch: 1/20 | Batch: 181/455 | Loss: 2.1217
Epoch: 1/20 | Batch: 191/455 | Loss: 2.4283
Epoch: 1/20 | Batch: 201/455 | Loss: 2.0045
Epoch: 1/20 | Batch: 211/455 | Loss: 1.3083
Epoch: 1/20 | Batch: 221/455 | Loss: 1.3888
Epoch: 1/20 | Batch: 231/455 | Loss: 1.9975
Epoch: 1/20 | Batch: 241/455 | Loss: 1.9919
Epoch: 1/20 | Batch: 251/455 | Loss: 1.6151
Epoch: 1/20 | Batch: 261/455 | Loss: 2.2010
Epoch: 1/20 | Batch: 271/455 | Loss: 2.1901
Epoch: 1/20 | Batch: 281/455 | Loss: 1.6464
Epoch: 1/20 | Batch: 291/455 | Loss: 1.4639
Epoch: 1/20 | Batch: 301/455 | Loss: 1.5392
Epoch: 1/20 | Batch: 311/455 | Loss: 1.9758
Epoch: 1/20 | Batch: 321/455 | Loss: 1.3430
Epoch: 1/20 | Batch: 331/455 | Loss: 1.5801
Epoch: 1/20 | Batch: 341/455 | Loss: 2.2597
Epoch: 1/20 | Batch: 351/455 | Loss: 1.6555
Epoch: 1/20 | Batch: 361/455 | Loss: 1.7511
Epoch: 1/20 | Batch: 371/455 | Loss: 1.2460
Epoch: 1/20 | Batch: 381/455 | Loss: 1.2001
Epoch: 1/20 | Batch: 391/455 | Loss: 1.2699
Epoch: 1/20 | Batch: 401/455 | Loss: 1.3990
Epoch: 1/20 | Batch: 411/455 | Loss: 1.2802
Epoch: 1/20 | Batch: 421/455 | Loss: 0.7673
Epoch: 1/20 | Batch: 431/455 | Loss: 1.6510
Epoch: 1/20 | Batch: 441/455 | Loss: 1.4170
Epoch: 1/20 | Batch: 451/455 | Loss: 1.8859
Epoch: 1/20 | Train Loss: 2.1420 | Train Acc: 53.98% | Val Loss: 0.7692 | Val Acc: 80.04%
Current learning rate: 0.0001
Current learning rate: 0.0001
Current learning rate: 0.0001
Current learning rate: 0.0001
Current learning rate: 0.0001
Current learning rate: 0.0001
Current learning rate: 0.0001
Best accuracy: 80.04%
Model saved to checkpoints\resnet18_pretrained_best.pth
Epoch: 2/20 | Batch: 1/455 | Loss: 1.1089
Epoch: 2/20 | Batch: 11/455 | Loss: 1.7286
Epoch: 2/20 | Batch: 21/455 | Loss: 1.0493
Epoch: 2/20 | Batch: 31/455 | Loss: 1.0609
Epoch: 2/20 | Batch: 41/455 | Loss: 0.9420
Epoch: 2/20 | Batch: 51/455 | Loss: 1.6564
Epoch: 2/20 | Batch: 61/455 | Loss: 1.1577
Epoch: 2/20 | Batch: 71/455 | Loss: 1.9132
Epoch: 2/20 | Batch: 81/455 | Loss: 1.5048
Epoch: 2/20 | Batch: 91/455 | Loss: 0.7607
Epoch: 2/20 | Batch: 101/455 | Loss: 0.8170
Epoch: 2/20 | Batch: 111/455 | Loss: 1.5809
Epoch: 2/20 | Batch: 121/455 | Loss: 0.8637
Epoch: 2/20 | Batch: 131/455 | Loss: 1.1738
Epoch: 2/20 | Batch: 141/455 | Loss: 1.2431
Epoch: 2/20 | Batch: 151/455 | Loss: 0.9515
Epoch: 2/20 | Batch: 161/455 | Loss: 1.0565
Epoch: 2/20 | Batch: 171/455 | Loss: 1.1461
Epoch: 2/20 | Batch: 181/455 | Loss: 1.3931
Epoch: 2/20 | Batch: 191/455 | Loss: 0.9119
Epoch: 2/20 | Batch: 201/455 | Loss: 1.1262
Epoch: 2/20 | Batch: 211/455 | Loss: 0.8539
Epoch: 2/20 | Batch: 221/455 | Loss: 1.3897
Epoch: 2/20 | Batch: 231/455 | Loss: 1.0456
Epoch: 2/20 | Batch: 241/455 | Loss: 0.9408
Epoch: 2/20 | Batch: 251/455 | Loss: 1.2328
Epoch: 2/20 | Batch: 261/455 | Loss: 0.2858
Epoch: 2/20 | Batch: 271/455 | Loss: 0.9162
Epoch: 2/20 | Batch: 281/455 | Loss: 0.9414
Epoch: 2/20 | Batch: 291/455 | Loss: 0.9877
Epoch: 2/20 | Batch: 301/455 | Loss: 0.9943
Epoch: 2/20 | Batch: 311/455 | Loss: 0.6053
Epoch: 2/20 | Batch: 321/455 | Loss: 0.4691
Epoch: 2/20 | Batch: 331/455 | Loss: 1.0448
Epoch: 2/20 | Batch: 341/455 | Loss: 0.6449
Epoch: 2/20 | Batch: 351/455 | Loss: 1.3415
Epoch: 2/20 | Batch: 361/455 | Loss: 0.8595
Epoch: 2/20 | Batch: 371/455 | Loss: 0.6216
Epoch: 2/20 | Batch: 381/455 | Loss: 0.9557
Epoch: 2/20 | Batch: 391/455 | Loss: 0.9781
Epoch: 2/20 | Batch: 401/455 | Loss: 0.9437
Epoch: 2/20 | Batch: 411/455 | Loss: 1.2012
Epoch: 2/20 | Batch: 421/455 | Loss: 1.5279
Epoch: 2/20 | Batch: 431/455 | Loss: 1.3066
Epoch: 2/20 | Batch: 441/455 | Loss: 1.0501
Epoch: 2/20 | Batch: 451/455 | Loss: 0.9117
Epoch: 2/20 | Train Loss: 1.0935 | Train Acc: 75.04% | Val Loss: 0.4771 | Val Acc: 87.45%
Current learning rate: 0.0001
Current learning rate: 0.0001
Current learning rate: 0.0001
Current learning rate: 0.0001
Current learning rate: 0.0001
Current learning rate: 0.0001
Current learning rate: 0.0001
Best accuracy: 87.45%
Model saved to checkpoints\resnet18_pretrained_best.pth
Epoch: 3/20 | Batch: 1/455 | Loss: 0.8508
Epoch: 3/20 | Batch: 11/455 | Loss: 0.8358
Epoch: 3/20 | Batch: 21/455 | Loss: 0.2476
Epoch: 3/20 | Batch: 31/455 | Loss: 0.7197
Epoch: 3/20 | Batch: 41/455 | Loss: 0.5247
Epoch: 3/20 | Batch: 51/455 | Loss: 0.4114
Epoch: 3/20 | Batch: 61/455 | Loss: 0.4284
Epoch: 3/20 | Batch: 71/455 | Loss: 1.0272
Epoch: 3/20 | Batch: 81/455 | Loss: 1.2098
Epoch: 3/20 | Batch: 91/455 | Loss: 1.0646
Epoch: 3/20 | Batch: 101/455 | Loss: 1.0156
Epoch: 3/20 | Batch: 111/455 | Loss: 1.2810
Epoch: 3/20 | Batch: 121/455 | Loss: 0.5565
Epoch: 3/20 | Batch: 131/455 | Loss: 1.0000
Epoch: 3/20 | Batch: 141/455 | Loss: 0.8562
Epoch: 3/20 | Batch: 151/455 | Loss: 0.5687
Epoch: 3/20 | Batch: 161/455 | Loss: 1.3209
Epoch: 3/20 | Batch: 171/455 | Loss: 0.4083
Epoch: 3/20 | Batch: 181/455 | Loss: 0.8053
Epoch: 3/20 | Batch: 191/455 | Loss: 1.3234
Epoch: 3/20 | Batch: 201/455 | Loss: 1.4846
Epoch: 3/20 | Batch: 211/455 | Loss: 0.6748
Epoch: 3/20 | Batch: 221/455 | Loss: 0.6584
Epoch: 3/20 | Batch: 231/455 | Loss: 0.4507
Epoch: 3/20 | Batch: 241/455 | Loss: 0.8715
Epoch: 3/20 | Batch: 251/455 | Loss: 0.5825
Epoch: 3/20 | Batch: 261/455 | Loss: 0.6272
Epoch: 3/20 | Batch: 271/455 | Loss: 0.6793
Epoch: 3/20 | Batch: 281/455 | Loss: 0.9272
Epoch: 3/20 | Batch: 291/455 | Loss: 0.2615
Epoch: 3/20 | Batch: 301/455 | Loss: 1.2845
Epoch: 3/20 | Batch: 311/455 | Loss: 0.8565
Epoch: 3/20 | Batch: 321/455 | Loss: 0.7149
Epoch: 3/20 | Batch: 331/455 | Loss: 1.4599
Epoch: 3/20 | Batch: 341/455 | Loss: 1.6030
Epoch: 3/20 | Batch: 351/455 | Loss: 0.6820
Epoch: 3/20 | Batch: 361/455 | Loss: 1.2615
Epoch: 3/20 | Batch: 371/455 | Loss: 1.1313
Epoch: 3/20 | Batch: 381/455 | Loss: 0.9643
Epoch: 3/20 | Batch: 391/455 | Loss: 0.4825
Epoch: 3/20 | Batch: 401/455 | Loss: 1.3681
Epoch: 3/20 | Batch: 411/455 | Loss: 1.4181
Epoch: 3/20 | Batch: 421/455 | Loss: 1.1363
Epoch: 3/20 | Batch: 431/455 | Loss: 1.1750
Epoch: 3/20 | Batch: 441/455 | Loss: 0.7834
Epoch: 3/20 | Batch: 451/455 | Loss: 1.0628
Epoch: 3/20 | Train Loss: 0.8195 | Train Acc: 80.62% | Val Loss: 0.3802 | Val Acc: 90.40%
Current learning rate: 0.0001
Current learning rate: 0.0001
Current learning rate: 0.0001
Current learning rate: 0.0001
Current learning rate: 0.0001
Current learning rate: 0.0001
Current learning rate: 0.0001
Best accuracy: 90.40%
Model saved to checkpoints\resnet18_pretrained_best.pth
Epoch: 4/20 | Batch: 1/455 | Loss: 0.4916
Epoch: 4/20 | Batch: 11/455 | Loss: 0.7523
Epoch: 4/20 | Batch: 21/455 | Loss: 0.4893
Epoch: 4/20 | Batch: 31/455 | Loss: 1.4540
Epoch: 4/20 | Batch: 41/455 | Loss: 1.0554
Epoch: 4/20 | Batch: 51/455 | Loss: 0.8404
Epoch: 4/20 | Batch: 61/455 | Loss: 0.3829
Epoch: 4/20 | Batch: 71/455 | Loss: 0.6153
Epoch: 4/20 | Batch: 81/455 | Loss: 0.8213
Epoch: 4/20 | Batch: 91/455 | Loss: 0.4876
Epoch: 4/20 | Batch: 101/455 | Loss: 0.5319
Epoch: 4/20 | Batch: 111/455 | Loss: 0.8583
Epoch: 4/20 | Batch: 121/455 | Loss: 0.3856
Epoch: 4/20 | Batch: 131/455 | Loss: 0.7704
Epoch: 4/20 | Batch: 141/455 | Loss: 0.4832
Epoch: 4/20 | Batch: 151/455 | Loss: 1.1365
Epoch: 4/20 | Batch: 161/455 | Loss: 0.7316
Epoch: 4/20 | Batch: 171/455 | Loss: 0.6746
Epoch: 4/20 | Batch: 181/455 | Loss: 0.6173
Epoch: 4/20 | Batch: 191/455 | Loss: 0.5276
Epoch: 4/20 | Batch: 201/455 | Loss: 0.9014
Epoch: 4/20 | Batch: 211/455 | Loss: 1.1526
Epoch: 4/20 | Batch: 221/455 | Loss: 0.8739
Epoch: 4/20 | Batch: 231/455 | Loss: 0.5598
Epoch: 4/20 | Batch: 241/455 | Loss: 0.3797
Epoch: 4/20 | Batch: 251/455 | Loss: 1.1619
Epoch: 4/20 | Batch: 261/455 | Loss: 0.4413
Epoch: 4/20 | Batch: 271/455 | Loss: 0.3882
Epoch: 4/20 | Batch: 281/455 | Loss: 0.8993
Epoch: 4/20 | Batch: 291/455 | Loss: 0.6424
Epoch: 4/20 | Batch: 301/455 | Loss: 0.4915
Epoch: 4/20 | Batch: 311/455 | Loss: 1.0567
Epoch: 4/20 | Batch: 321/455 | Loss: 1.2388
Epoch: 4/20 | Batch: 331/455 | Loss: 0.7649
Epoch: 4/20 | Batch: 341/455 | Loss: 0.8491
Epoch: 4/20 | Batch: 351/455 | Loss: 0.7095
Epoch: 4/20 | Batch: 361/455 | Loss: 0.6391
Epoch: 4/20 | Batch: 371/455 | Loss: 0.6017
Epoch: 4/20 | Batch: 381/455 | Loss: 0.7025
Epoch: 4/20 | Batch: 391/455 | Loss: 0.9949
Epoch: 4/20 | Batch: 401/455 | Loss: 1.0399
Epoch: 4/20 | Batch: 411/455 | Loss: 0.9427
Epoch: 4/20 | Batch: 421/455 | Loss: 0.6394
Epoch: 4/20 | Batch: 431/455 | Loss: 0.6739
Epoch: 4/20 | Batch: 441/455 | Loss: 0.4988
Epoch: 4/20 | Batch: 451/455 | Loss: 0.6135
Epoch: 4/20 | Train Loss: 0.6928 | Train Acc: 83.43% | Val Loss: 0.3599 | Val Acc: 89.48%
Current learning rate: 0.0001
Current learning rate: 0.0001
Current learning rate: 0.0001
Current learning rate: 0.0001
Current learning rate: 0.0001
Current learning rate: 0.0001
Current learning rate: 0.0001
Epoch: 5/20 | Batch: 1/455 | Loss: 0.7434
Epoch: 5/20 | Batch: 11/455 | Loss: 0.2177
Epoch: 5/20 | Batch: 21/455 | Loss: 0.7242
Epoch: 5/20 | Batch: 31/455 | Loss: 0.8095
Epoch: 5/20 | Batch: 41/455 | Loss: 0.6316
Epoch: 5/20 | Batch: 51/455 | Loss: 0.6347
Epoch: 5/20 | Batch: 61/455 | Loss: 0.5988
Epoch: 5/20 | Batch: 71/455 | Loss: 0.3945
Epoch: 5/20 | Batch: 81/455 | Loss: 0.4260
Epoch: 5/20 | Batch: 91/455 | Loss: 1.1180
Epoch: 5/20 | Batch: 101/455 | Loss: 0.5717
Epoch: 5/20 | Batch: 111/455 | Loss: 0.7857
Epoch: 5/20 | Batch: 121/455 | Loss: 0.3465
Epoch: 5/20 | Batch: 131/455 | Loss: 0.3214
Epoch: 5/20 | Batch: 141/455 | Loss: 0.8393
Epoch: 5/20 | Batch: 151/455 | Loss: 0.5911
Epoch: 5/20 | Batch: 161/455 | Loss: 0.6144
Epoch: 5/20 | Batch: 171/455 | Loss: 1.2395
Epoch: 5/20 | Batch: 181/455 | Loss: 0.5221
Epoch: 5/20 | Batch: 191/455 | Loss: 0.4529
Epoch: 5/20 | Batch: 201/455 | Loss: 0.4110
Epoch: 5/20 | Batch: 211/455 | Loss: 0.3322
Epoch: 5/20 | Batch: 221/455 | Loss: 0.8437
Epoch: 5/20 | Batch: 231/455 | Loss: 0.6387
Epoch: 5/20 | Batch: 241/455 | Loss: 0.4383
Epoch: 5/20 | Batch: 251/455 | Loss: 0.9030
Epoch: 5/20 | Batch: 261/455 | Loss: 1.0872
Epoch: 5/20 | Batch: 271/455 | Loss: 1.0128
Epoch: 5/20 | Batch: 281/455 | Loss: 0.5655
Epoch: 5/20 | Batch: 291/455 | Loss: 0.7238
Epoch: 5/20 | Batch: 301/455 | Loss: 0.3891
Epoch: 5/20 | Batch: 311/455 | Loss: 0.7597
Epoch: 5/20 | Batch: 321/455 | Loss: 0.2646
Epoch: 5/20 | Batch: 331/455 | Loss: 0.3418
Epoch: 5/20 | Batch: 341/455 | Loss: 0.7490
Epoch: 5/20 | Batch: 351/455 | Loss: 1.3369
Epoch: 5/20 | Batch: 361/455 | Loss: 0.4501
Epoch: 5/20 | Batch: 371/455 | Loss: 0.4836
Epoch: 5/20 | Batch: 381/455 | Loss: 0.6885
Epoch: 5/20 | Batch: 391/455 | Loss: 0.5742
Epoch: 5/20 | Batch: 401/455 | Loss: 0.8506
Epoch: 5/20 | Batch: 411/455 | Loss: 0.3170
Epoch: 5/20 | Batch: 421/455 | Loss: 1.0819
Epoch: 5/20 | Batch: 431/455 | Loss: 0.5977
Epoch: 5/20 | Batch: 441/455 | Loss: 0.6690
Epoch: 5/20 | Batch: 451/455 | Loss: 0.9423
Epoch: 5/20 | Train Loss: 0.6309 | Train Acc: 84.09% | Val Loss: 0.3577 | Val Acc: 89.32%
Current learning rate: 0.0001
Current learning rate: 0.0001
Current learning rate: 0.0001
Current learning rate: 0.0001
Current learning rate: 0.0001
Current learning rate: 0.0001
Current learning rate: 0.0001
Epoch: 6/20 | Batch: 1/455 | Loss: 0.7751
Epoch: 6/20 | Batch: 11/455 | Loss: 0.3384
Epoch: 6/20 | Batch: 21/455 | Loss: 0.5643
Epoch: 6/20 | Batch: 31/455 | Loss: 0.3627
Epoch: 6/20 | Batch: 41/455 | Loss: 0.2326
Epoch: 6/20 | Batch: 51/455 | Loss: 0.7600
Epoch: 6/20 | Batch: 61/455 | Loss: 0.6009
Epoch: 6/20 | Batch: 71/455 | Loss: 0.6187
Epoch: 6/20 | Batch: 81/455 | Loss: 0.8290
Epoch: 6/20 | Batch: 91/455 | Loss: 0.6053
Epoch: 6/20 | Batch: 101/455 | Loss: 0.1833
Epoch: 6/20 | Batch: 111/455 | Loss: 0.5421
Epoch: 6/20 | Batch: 121/455 | Loss: 0.4196
Epoch: 6/20 | Batch: 131/455 | Loss: 0.6468
Epoch: 6/20 | Batch: 141/455 | Loss: 0.6330
Epoch: 6/20 | Batch: 151/455 | Loss: 0.8385
Epoch: 6/20 | Batch: 161/455 | Loss: 0.4582
Epoch: 6/20 | Batch: 171/455 | Loss: 0.8079
Epoch: 6/20 | Batch: 181/455 | Loss: 0.7607
Epoch: 6/20 | Batch: 191/455 | Loss: 0.3935
Epoch: 6/20 | Batch: 201/455 | Loss: 0.8986
Epoch: 6/20 | Batch: 211/455 | Loss: 0.4825
Epoch: 6/20 | Batch: 221/455 | Loss: 0.5681
Epoch: 6/20 | Batch: 231/455 | Loss: 0.6916
Epoch: 6/20 | Batch: 241/455 | Loss: 0.5412
Epoch: 6/20 | Batch: 251/455 | Loss: 0.4400
Epoch: 6/20 | Batch: 261/455 | Loss: 0.7617
Epoch: 6/20 | Batch: 271/455 | Loss: 0.7407
Epoch: 6/20 | Batch: 281/455 | Loss: 0.9463
Epoch: 6/20 | Batch: 291/455 | Loss: 0.5109
Epoch: 6/20 | Batch: 301/455 | Loss: 0.3510
Epoch: 6/20 | Batch: 311/455 | Loss: 0.3995
Epoch: 6/20 | Batch: 321/455 | Loss: 0.2429
Epoch: 6/20 | Batch: 331/455 | Loss: 0.3456
Epoch: 6/20 | Batch: 341/455 | Loss: 0.4047
Epoch: 6/20 | Batch: 351/455 | Loss: 0.8217
Epoch: 6/20 | Batch: 361/455 | Loss: 0.4828
Epoch: 6/20 | Batch: 371/455 | Loss: 0.3497
Epoch: 6/20 | Batch: 381/455 | Loss: 0.3144
Epoch: 6/20 | Batch: 391/455 | Loss: 0.8462
Epoch: 6/20 | Batch: 401/455 | Loss: 0.8298
Epoch: 6/20 | Batch: 411/455 | Loss: 0.6316
Epoch: 6/20 | Batch: 421/455 | Loss: 0.8418
Epoch: 6/20 | Batch: 431/455 | Loss: 0.4194
Epoch: 6/20 | Batch: 441/455 | Loss: 0.2742
Epoch: 6/20 | Batch: 451/455 | Loss: 0.5432
Epoch: 6/20 | Train Loss: 0.5782 | Train Acc: 85.52% | Val Loss: 0.3216 | Val Acc: 90.93%
Current learning rate: 0.0001
Current learning rate: 0.0001
Current learning rate: 0.0001
Current learning rate: 0.0001
Current learning rate: 0.0001
Current learning rate: 0.0001
Current learning rate: 0.0001
Best accuracy: 90.93%
Model saved to checkpoints\resnet18_pretrained_best.pth
Epoch: 7/20 | Batch: 1/455 | Loss: 0.3467
Epoch: 7/20 | Batch: 11/455 | Loss: 0.1744
Epoch: 7/20 | Batch: 21/455 | Loss: 0.6617
Epoch: 7/20 | Batch: 31/455 | Loss: 0.4652
Epoch: 7/20 | Batch: 41/455 | Loss: 0.3244
Epoch: 7/20 | Batch: 51/455 | Loss: 1.2004
Epoch: 7/20 | Batch: 61/455 | Loss: 0.6738
Epoch: 7/20 | Batch: 71/455 | Loss: 0.6776
Epoch: 7/20 | Batch: 81/455 | Loss: 0.1956
Epoch: 7/20 | Batch: 91/455 | Loss: 0.5714
Epoch: 7/20 | Batch: 101/455 | Loss: 0.2473
Epoch: 7/20 | Batch: 111/455 | Loss: 0.5182
Epoch: 7/20 | Batch: 121/455 | Loss: 0.2096
Epoch: 7/20 | Batch: 131/455 | Loss: 0.2824
Epoch: 7/20 | Batch: 141/455 | Loss: 0.5704
Epoch: 7/20 | Batch: 151/455 | Loss: 0.9323
Epoch: 7/20 | Batch: 161/455 | Loss: 0.4120
Epoch: 7/20 | Batch: 171/455 | Loss: 0.5292
Epoch: 7/20 | Batch: 181/455 | Loss: 0.2416
Epoch: 7/20 | Batch: 191/455 | Loss: 0.2498
Epoch: 7/20 | Batch: 201/455 | Loss: 0.1632
Epoch: 7/20 | Batch: 211/455 | Loss: 0.4618
Epoch: 7/20 | Batch: 221/455 | Loss: 0.4805
Epoch: 7/20 | Batch: 231/455 | Loss: 0.9678
Epoch: 7/20 | Batch: 241/455 | Loss: 0.6804
Epoch: 7/20 | Batch: 251/455 | Loss: 0.7255
Epoch: 7/20 | Batch: 261/455 | Loss: 0.1809
Epoch: 7/20 | Batch: 271/455 | Loss: 0.5728
Epoch: 7/20 | Batch: 281/455 | Loss: 0.3914
Epoch: 7/20 | Batch: 291/455 | Loss: 0.6931
Epoch: 7/20 | Batch: 301/455 | Loss: 0.2051
Epoch: 7/20 | Batch: 311/455 | Loss: 0.9630
Epoch: 7/20 | Batch: 321/455 | Loss: 0.4793
Epoch: 7/20 | Batch: 331/455 | Loss: 0.7245
Epoch: 7/20 | Batch: 341/455 | Loss: 0.8901
Epoch: 7/20 | Batch: 351/455 | Loss: 0.2309
Epoch: 7/20 | Batch: 361/455 | Loss: 0.3756
Epoch: 7/20 | Batch: 371/455 | Loss: 0.3948
Epoch: 7/20 | Batch: 381/455 | Loss: 1.1465
Epoch: 7/20 | Batch: 391/455 | Loss: 0.2632
Epoch: 7/20 | Batch: 401/455 | Loss: 0.3833
Epoch: 7/20 | Batch: 411/455 | Loss: 0.4466
Epoch: 7/20 | Batch: 421/455 | Loss: 0.5450
Epoch: 7/20 | Batch: 431/455 | Loss: 0.3415
Epoch: 7/20 | Batch: 441/455 | Loss: 1.0096
Epoch: 7/20 | Batch: 451/455 | Loss: 0.5275
Epoch: 7/20 | Train Loss: 0.5387 | Train Acc: 86.17% | Val Loss: 0.3225 | Val Acc: 91.26%
Current learning rate: 0.0001
Current learning rate: 0.0001
Current learning rate: 0.0001
Current learning rate: 0.0001
Current learning rate: 0.0001
Current learning rate: 0.0001
Current learning rate: 0.0001
Best accuracy: 91.26%
Model saved to checkpoints\resnet18_pretrained_best.pth
Epoch: 8/20 | Batch: 1/455 | Loss: 0.5479
Epoch: 8/20 | Batch: 11/455 | Loss: 0.7518
Epoch: 8/20 | Batch: 21/455 | Loss: 0.1849
Epoch: 8/20 | Batch: 31/455 | Loss: 0.3526
Epoch: 8/20 | Batch: 41/455 | Loss: 0.3844
Epoch: 8/20 | Batch: 51/455 | Loss: 0.8702
Epoch: 8/20 | Batch: 61/455 | Loss: 1.1964
Epoch: 8/20 | Batch: 71/455 | Loss: 0.6457
Epoch: 8/20 | Batch: 81/455 | Loss: 0.1180
Epoch: 8/20 | Batch: 91/455 | Loss: 0.6785
Epoch: 8/20 | Batch: 101/455 | Loss: 0.3960
Epoch: 8/20 | Batch: 111/455 | Loss: 0.2302
Epoch: 8/20 | Batch: 121/455 | Loss: 0.1989
Epoch: 8/20 | Batch: 131/455 | Loss: 0.4415
Epoch: 8/20 | Batch: 141/455 | Loss: 0.5177
Epoch: 8/20 | Batch: 151/455 | Loss: 0.1855
Epoch: 8/20 | Batch: 161/455 | Loss: 0.3793
Epoch: 8/20 | Batch: 171/455 | Loss: 0.4343
Epoch: 8/20 | Batch: 181/455 | Loss: 0.4024
Epoch: 8/20 | Batch: 191/455 | Loss: 0.2027
Epoch: 8/20 | Batch: 201/455 | Loss: 0.7666
Epoch: 8/20 | Batch: 211/455 | Loss: 0.1656
Epoch: 8/20 | Batch: 221/455 | Loss: 0.1495
Epoch: 8/20 | Batch: 231/455 | Loss: 1.1776
Epoch: 8/20 | Batch: 241/455 | Loss: 0.3204
Epoch: 8/20 | Batch: 251/455 | Loss: 0.7844
Epoch: 8/20 | Batch: 261/455 | Loss: 1.1108
Epoch: 8/20 | Batch: 271/455 | Loss: 0.4236
Epoch: 8/20 | Batch: 281/455 | Loss: 0.2095
Epoch: 8/20 | Batch: 291/455 | Loss: 0.2488
Epoch: 8/20 | Batch: 301/455 | Loss: 0.3802
Epoch: 8/20 | Batch: 311/455 | Loss: 0.4219
Epoch: 8/20 | Batch: 321/455 | Loss: 0.3599
Epoch: 8/20 | Batch: 331/455 | Loss: 0.2502
Epoch: 8/20 | Batch: 341/455 | Loss: 0.3112
Epoch: 8/20 | Batch: 351/455 | Loss: 0.2213
Epoch: 8/20 | Batch: 361/455 | Loss: 0.1789
Epoch: 8/20 | Batch: 371/455 | Loss: 0.4796
Epoch: 8/20 | Batch: 381/455 | Loss: 0.7585
Epoch: 8/20 | Batch: 391/455 | Loss: 0.4779
Epoch: 8/20 | Batch: 401/455 | Loss: 0.1835
Epoch: 8/20 | Batch: 411/455 | Loss: 0.2936
Epoch: 8/20 | Batch: 421/455 | Loss: 0.5679
Epoch: 8/20 | Batch: 431/455 | Loss: 0.3791
Epoch: 8/20 | Batch: 441/455 | Loss: 0.9353
Epoch: 8/20 | Batch: 451/455 | Loss: 0.6701
Epoch: 8/20 | Train Loss: 0.5075 | Train Acc: 86.70% | Val Loss: 0.3265 | Val Acc: 89.97%
Current learning rate: 0.0001
Current learning rate: 0.0001
Current learning rate: 0.0001
Current learning rate: 0.0001
Current learning rate: 0.0001
Current learning rate: 0.0001
Current learning rate: 0.0001
Epoch: 9/20 | Batch: 1/455 | Loss: 0.6633
Epoch: 9/20 | Batch: 11/455 | Loss: 0.1768
Epoch: 9/20 | Batch: 21/455 | Loss: 0.4190
Epoch: 9/20 | Batch: 31/455 | Loss: 0.3527
Epoch: 9/20 | Batch: 41/455 | Loss: 0.8895
Epoch: 9/20 | Batch: 51/455 | Loss: 0.9059
Epoch: 9/20 | Batch: 61/455 | Loss: 0.2616
Epoch: 9/20 | Batch: 71/455 | Loss: 0.4034
Epoch: 9/20 | Batch: 81/455 | Loss: 0.4786
Epoch: 9/20 | Batch: 91/455 | Loss: 0.0651
Epoch: 9/20 | Batch: 101/455 | Loss: 0.9686
Epoch: 9/20 | Batch: 111/455 | Loss: 0.3790
Epoch: 9/20 | Batch: 121/455 | Loss: 0.8360
Epoch: 9/20 | Batch: 131/455 | Loss: 0.0997
Epoch: 9/20 | Batch: 141/455 | Loss: 0.2744
Epoch: 9/20 | Batch: 151/455 | Loss: 0.2088
Epoch: 9/20 | Batch: 161/455 | Loss: 0.2074
Epoch: 9/20 | Batch: 171/455 | Loss: 0.5409
Epoch: 9/20 | Batch: 181/455 | Loss: 0.9381
Epoch: 9/20 | Batch: 191/455 | Loss: 0.6166
Epoch: 9/20 | Batch: 201/455 | Loss: 0.6869
Epoch: 9/20 | Batch: 211/455 | Loss: 0.8784
Epoch: 9/20 | Batch: 221/455 | Loss: 0.4726
Epoch: 9/20 | Batch: 231/455 | Loss: 0.7771
Epoch: 9/20 | Batch: 241/455 | Loss: 0.2945
Epoch: 9/20 | Batch: 251/455 | Loss: 0.1396
Epoch: 9/20 | Batch: 261/455 | Loss: 0.3244
Epoch: 9/20 | Batch: 271/455 | Loss: 0.4758
Epoch: 9/20 | Batch: 281/455 | Loss: 0.4742
Epoch: 9/20 | Batch: 291/455 | Loss: 0.5585
Epoch: 9/20 | Batch: 301/455 | Loss: 0.4770
Epoch: 9/20 | Batch: 311/455 | Loss: 0.6100
Epoch: 9/20 | Batch: 321/455 | Loss: 0.4050
Epoch: 9/20 | Batch: 331/455 | Loss: 0.3376
Epoch: 9/20 | Batch: 341/455 | Loss: 0.2057
Epoch: 9/20 | Batch: 351/455 | Loss: 0.0861
Epoch: 9/20 | Batch: 361/455 | Loss: 0.3885
Epoch: 9/20 | Batch: 371/455 | Loss: 0.4249
Epoch: 9/20 | Batch: 381/455 | Loss: 0.1770
Epoch: 9/20 | Batch: 391/455 | Loss: 0.3228
Epoch: 9/20 | Batch: 401/455 | Loss: 1.3511
Epoch: 9/20 | Batch: 411/455 | Loss: 0.8424
Epoch: 9/20 | Batch: 421/455 | Loss: 1.3010
Epoch: 9/20 | Batch: 431/455 | Loss: 0.5518
Epoch: 9/20 | Batch: 441/455 | Loss: 0.7399
Epoch: 9/20 | Batch: 451/455 | Loss: 1.3760
Epoch: 9/20 | Train Loss: 0.4797 | Train Acc: 87.80% | Val Loss: 0.3009 | Val Acc: 90.72%
Current learning rate: 0.0001
Current learning rate: 0.0001
Current learning rate: 0.0001
Current learning rate: 0.0001
Current learning rate: 0.0001
Current learning rate: 0.0001
Current learning rate: 0.0001
Epoch: 10/20 | Batch: 1/455 | Loss: 0.3243
Epoch: 10/20 | Batch: 11/455 | Loss: 0.1614
Epoch: 10/20 | Batch: 21/455 | Loss: 0.6105
Epoch: 10/20 | Batch: 31/455 | Loss: 0.5122
Epoch: 10/20 | Batch: 41/455 | Loss: 0.4423
Epoch: 10/20 | Batch: 51/455 | Loss: 0.3517
Epoch: 10/20 | Batch: 61/455 | Loss: 0.2091
Epoch: 10/20 | Batch: 71/455 | Loss: 0.8095
Epoch: 10/20 | Batch: 81/455 | Loss: 0.6158
Epoch: 10/20 | Batch: 91/455 | Loss: 0.8467
Epoch: 10/20 | Batch: 101/455 | Loss: 0.5926
Epoch: 10/20 | Batch: 111/455 | Loss: 0.4033
Epoch: 10/20 | Batch: 121/455 | Loss: 0.4598
Epoch: 10/20 | Batch: 131/455 | Loss: 0.2595
Epoch: 10/20 | Batch: 141/455 | Loss: 0.5341
Epoch: 10/20 | Batch: 151/455 | Loss: 0.2251
Epoch: 10/20 | Batch: 161/455 | Loss: 0.4316
Epoch: 10/20 | Batch: 171/455 | Loss: 0.1897
Epoch: 10/20 | Batch: 181/455 | Loss: 0.3142
Epoch: 10/20 | Batch: 191/455 | Loss: 0.1274
Epoch: 10/20 | Batch: 201/455 | Loss: 0.1100
Epoch: 10/20 | Batch: 211/455 | Loss: 0.4699
Epoch: 10/20 | Batch: 221/455 | Loss: 1.1214
Epoch: 10/20 | Batch: 231/455 | Loss: 0.7622
Epoch: 10/20 | Batch: 241/455 | Loss: 0.3444
Epoch: 10/20 | Batch: 251/455 | Loss: 0.2997
Epoch: 10/20 | Batch: 261/455 | Loss: 0.4730
Epoch: 10/20 | Batch: 271/455 | Loss: 0.7512
Epoch: 10/20 | Batch: 281/455 | Loss: 0.5341
Epoch: 10/20 | Batch: 291/455 | Loss: 0.4766
Epoch: 10/20 | Batch: 301/455 | Loss: 0.1755
Epoch: 10/20 | Batch: 311/455 | Loss: 0.4301
Epoch: 10/20 | Batch: 321/455 | Loss: 0.1258
Epoch: 10/20 | Batch: 331/455 | Loss: 0.7240
Epoch: 10/20 | Batch: 341/455 | Loss: 0.0721
Epoch: 10/20 | Batch: 351/455 | Loss: 0.4106
Epoch: 10/20 | Batch: 361/455 | Loss: 0.1139
Epoch: 10/20 | Batch: 371/455 | Loss: 0.6523
Epoch: 10/20 | Batch: 381/455 | Loss: 0.7727
Epoch: 10/20 | Batch: 391/455 | Loss: 0.5648
Epoch: 10/20 | Batch: 401/455 | Loss: 0.4140
Epoch: 10/20 | Batch: 411/455 | Loss: 0.6053
Epoch: 10/20 | Batch: 421/455 | Loss: 0.5992
Epoch: 10/20 | Batch: 431/455 | Loss: 0.4632
Epoch: 10/20 | Batch: 441/455 | Loss: 0.0884
Epoch: 10/20 | Batch: 451/455 | Loss: 0.6075
Epoch: 10/20 | Train Loss: 0.4592 | Train Acc: 88.35% | Val Loss: 0.3208 | Val Acc: 90.56%
Current learning rate: 0.0001
Current learning rate: 0.0001
Current learning rate: 0.0001
Current learning rate: 0.0001
Current learning rate: 0.0001
Current learning rate: 0.0001
Current learning rate: 0.0001
Epoch: 11/20 | Batch: 1/455 | Loss: 0.3073
Epoch: 11/20 | Batch: 11/455 | Loss: 0.4378
Epoch: 11/20 | Batch: 21/455 | Loss: 0.5607
Epoch: 11/20 | Batch: 31/455 | Loss: 0.7808
Epoch: 11/20 | Batch: 41/455 | Loss: 0.3113
Epoch: 11/20 | Batch: 51/455 | Loss: 0.1902
Epoch: 11/20 | Batch: 61/455 | Loss: 0.1297
Epoch: 11/20 | Batch: 71/455 | Loss: 0.3404
Epoch: 11/20 | Batch: 81/455 | Loss: 0.6933
Epoch: 11/20 | Batch: 91/455 | Loss: 0.1798
Epoch: 11/20 | Batch: 101/455 | Loss: 0.3367
Epoch: 11/20 | Batch: 111/455 | Loss: 0.1081
Epoch: 11/20 | Batch: 121/455 | Loss: 0.4875
Epoch: 11/20 | Batch: 131/455 | Loss: 0.3852
Epoch: 11/20 | Batch: 141/455 | Loss: 0.5133
Epoch: 11/20 | Batch: 151/455 | Loss: 0.5499
Epoch: 11/20 | Batch: 161/455 | Loss: 0.6205
Epoch: 11/20 | Batch: 171/455 | Loss: 0.4713
Epoch: 11/20 | Batch: 181/455 | Loss: 0.1455
Epoch: 11/20 | Batch: 191/455 | Loss: 0.5249
Epoch: 11/20 | Batch: 201/455 | Loss: 0.3665
Epoch: 11/20 | Batch: 211/455 | Loss: 0.6965
Epoch: 11/20 | Batch: 221/455 | Loss: 0.4589
Epoch: 11/20 | Batch: 231/455 | Loss: 0.8023
Epoch: 11/20 | Batch: 241/455 | Loss: 0.7292
Epoch: 11/20 | Batch: 251/455 | Loss: 0.5353
Epoch: 11/20 | Batch: 261/455 | Loss: 0.6010
Epoch: 11/20 | Batch: 271/455 | Loss: 0.5828
Epoch: 11/20 | Batch: 281/455 | Loss: 0.4597
Epoch: 11/20 | Batch: 291/455 | Loss: 0.6714
Epoch: 11/20 | Batch: 301/455 | Loss: 0.3268
Epoch: 11/20 | Batch: 311/455 | Loss: 0.6485
Epoch: 11/20 | Batch: 321/455 | Loss: 0.2123
Epoch: 11/20 | Batch: 331/455 | Loss: 0.1390
Epoch: 11/20 | Batch: 341/455 | Loss: 0.2009
Epoch: 11/20 | Batch: 351/455 | Loss: 0.3386
Epoch: 11/20 | Batch: 361/455 | Loss: 0.5405
Epoch: 11/20 | Batch: 371/455 | Loss: 0.3489
Epoch: 11/20 | Batch: 381/455 | Loss: 0.8935
Epoch: 11/20 | Batch: 391/455 | Loss: 0.6606
Epoch: 11/20 | Batch: 401/455 | Loss: 0.4569
Epoch: 11/20 | Batch: 411/455 | Loss: 0.3096
Epoch: 11/20 | Batch: 421/455 | Loss: 0.8053
Epoch: 11/20 | Batch: 431/455 | Loss: 0.3293
Epoch: 11/20 | Batch: 441/455 | Loss: 0.5693
Epoch: 11/20 | Batch: 451/455 | Loss: 0.2654
Epoch: 11/20 | Train Loss: 0.4491 | Train Acc: 88.17% | Val Loss: 0.3236 | Val Acc: 90.08%
Current learning rate: 0.0001
Current learning rate: 0.0001
Current learning rate: 0.0001
Current learning rate: 0.0001
Current learning rate: 0.0001
Current learning rate: 0.0001
Current learning rate: 0.0001
Epoch: 12/20 | Batch: 1/455 | Loss: 0.0493
Epoch: 12/20 | Batch: 11/455 | Loss: 0.2074
Epoch: 12/20 | Batch: 21/455 | Loss: 0.3974
Epoch: 12/20 | Batch: 31/455 | Loss: 0.2591
Epoch: 12/20 | Batch: 41/455 | Loss: 0.1401
Epoch: 12/20 | Batch: 51/455 | Loss: 0.6926
Epoch: 12/20 | Batch: 61/455 | Loss: 0.8164
Epoch: 12/20 | Batch: 71/455 | Loss: 0.4013
Epoch: 12/20 | Batch: 81/455 | Loss: 0.5716
Epoch: 12/20 | Batch: 91/455 | Loss: 1.0670
Epoch: 12/20 | Batch: 101/455 | Loss: 0.2616
Epoch: 12/20 | Batch: 111/455 | Loss: 0.3039
Epoch: 12/20 | Batch: 121/455 | Loss: 0.4396
Epoch: 12/20 | Batch: 131/455 | Loss: 0.4256
Epoch: 12/20 | Batch: 141/455 | Loss: 0.3029
Epoch: 12/20 | Batch: 151/455 | Loss: 0.2924
Epoch: 12/20 | Batch: 161/455 | Loss: 0.4644
Epoch: 12/20 | Batch: 171/455 | Loss: 0.2045
Epoch: 12/20 | Batch: 181/455 | Loss: 0.1232
Epoch: 12/20 | Batch: 191/455 | Loss: 0.3169
Epoch: 12/20 | Batch: 201/455 | Loss: 0.4822
Epoch: 12/20 | Batch: 211/455 | Loss: 0.2925
Epoch: 12/20 | Batch: 221/455 | Loss: 0.1946
Epoch: 12/20 | Batch: 231/455 | Loss: 0.1900
Epoch: 12/20 | Batch: 241/455 | Loss: 0.4603
Epoch: 12/20 | Batch: 251/455 | Loss: 0.6192
Epoch: 12/20 | Batch: 261/455 | Loss: 0.2868
Epoch: 12/20 | Batch: 271/455 | Loss: 0.6981
Epoch: 12/20 | Batch: 281/455 | Loss: 0.1366
Epoch: 12/20 | Batch: 291/455 | Loss: 0.5831
Epoch: 12/20 | Batch: 301/455 | Loss: 1.1592
Epoch: 12/20 | Batch: 311/455 | Loss: 0.4862
Epoch: 12/20 | Batch: 321/455 | Loss: 0.1116
Epoch: 12/20 | Batch: 331/455 | Loss: 0.3680
Epoch: 12/20 | Batch: 341/455 | Loss: 0.0879
Epoch: 12/20 | Batch: 351/455 | Loss: 0.3982
Epoch: 12/20 | Batch: 361/455 | Loss: 0.2169
Epoch: 12/20 | Batch: 371/455 | Loss: 0.2901
Epoch: 12/20 | Batch: 381/455 | Loss: 0.1567
Epoch: 12/20 | Batch: 391/455 | Loss: 0.9915
Epoch: 12/20 | Batch: 401/455 | Loss: 0.5487
Epoch: 12/20 | Batch: 411/455 | Loss: 0.6812
Epoch: 12/20 | Batch: 421/455 | Loss: 0.6000
Epoch: 12/20 | Batch: 431/455 | Loss: 0.8941
Epoch: 12/20 | Batch: 441/455 | Loss: 0.3810
Epoch: 12/20 | Batch: 451/455 | Loss: 0.4557
Epoch: 12/20 | Train Loss: 0.4479 | Train Acc: 88.50% | Val Loss: 0.3017 | Val Acc: 90.99%
Current learning rate: 0.0001
Current learning rate: 0.0001
Current learning rate: 0.0001
Current learning rate: 0.0001
Current learning rate: 0.0001
Current learning rate: 0.0001
Current learning rate: 0.0001
Epoch: 13/20 | Batch: 1/455 | Loss: 0.1490
Epoch: 13/20 | Batch: 11/455 | Loss: 0.5746
Epoch: 13/20 | Batch: 21/455 | Loss: 0.1384
Epoch: 13/20 | Batch: 31/455 | Loss: 0.2341
Epoch: 13/20 | Batch: 41/455 | Loss: 0.5185
Epoch: 13/20 | Batch: 51/455 | Loss: 0.4526
Epoch: 13/20 | Batch: 61/455 | Loss: 0.3073
Epoch: 13/20 | Batch: 71/455 | Loss: 0.7400
Epoch: 13/20 | Batch: 81/455 | Loss: 0.8425
Epoch: 13/20 | Batch: 91/455 | Loss: 0.4505
Epoch: 13/20 | Batch: 101/455 | Loss: 0.1756
Epoch: 13/20 | Batch: 111/455 | Loss: 0.5264
Epoch: 13/20 | Batch: 121/455 | Loss: 0.3547
Epoch: 13/20 | Batch: 131/455 | Loss: 0.5081
Epoch: 13/20 | Batch: 141/455 | Loss: 0.2338
Epoch: 13/20 | Batch: 151/455 | Loss: 0.4385
Epoch: 13/20 | Batch: 161/455 | Loss: 0.2378
Epoch: 13/20 | Batch: 171/455 | Loss: 0.4549
Epoch: 13/20 | Batch: 181/455 | Loss: 0.3860
Epoch: 13/20 | Batch: 191/455 | Loss: 0.1772
Epoch: 13/20 | Batch: 201/455 | Loss: 0.3276
Epoch: 13/20 | Batch: 211/455 | Loss: 0.3768
Epoch: 13/20 | Batch: 221/455 | Loss: 0.5312
Epoch: 13/20 | Batch: 231/455 | Loss: 0.1961
Epoch: 13/20 | Batch: 241/455 | Loss: 0.2504
Epoch: 13/20 | Batch: 251/455 | Loss: 0.0276
Epoch: 13/20 | Batch: 261/455 | Loss: 0.1464
Epoch: 13/20 | Batch: 271/455 | Loss: 0.7104
Epoch: 13/20 | Batch: 281/455 | Loss: 0.3861
Epoch: 13/20 | Batch: 291/455 | Loss: 0.6527
Epoch: 13/20 | Batch: 301/455 | Loss: 0.5056
Epoch: 13/20 | Batch: 311/455 | Loss: 0.2467
Epoch: 13/20 | Batch: 321/455 | Loss: 0.4954
Epoch: 13/20 | Batch: 331/455 | Loss: 0.4219
Epoch: 13/20 | Batch: 341/455 | Loss: 0.6150
Epoch: 13/20 | Batch: 351/455 | Loss: 0.3305
Epoch: 13/20 | Batch: 361/455 | Loss: 0.4531
Epoch: 13/20 | Batch: 371/455 | Loss: 0.9681
Epoch: 13/20 | Batch: 381/455 | Loss: 0.5483
Epoch: 13/20 | Batch: 391/455 | Loss: 0.2971
Epoch: 13/20 | Batch: 401/455 | Loss: 1.2623
Epoch: 13/20 | Batch: 411/455 | Loss: 0.4850
Epoch: 13/20 | Batch: 421/455 | Loss: 0.7393
Epoch: 13/20 | Batch: 431/455 | Loss: 0.1525
Epoch: 13/20 | Batch: 441/455 | Loss: 0.5634
Epoch: 13/20 | Batch: 451/455 | Loss: 0.4962
Epoch: 13/20 | Train Loss: 0.4355 | Train Acc: 88.39% | Val Loss: 0.3165 | Val Acc: 91.15%
Current learning rate: 1e-05
Current learning rate: 1e-05
Current learning rate: 1e-05
Current learning rate: 1e-05
Current learning rate: 1e-05
Current learning rate: 1e-05
Current learning rate: 1e-05
Epoch: 14/20 | Batch: 1/455 | Loss: 0.2860
Epoch: 14/20 | Batch: 11/455 | Loss: 0.1085
Epoch: 14/20 | Batch: 21/455 | Loss: 0.6147
Epoch: 14/20 | Batch: 31/455 | Loss: 0.1418
Epoch: 14/20 | Batch: 41/455 | Loss: 0.6573
Epoch: 14/20 | Batch: 51/455 | Loss: 0.5094
Epoch: 14/20 | Batch: 61/455 | Loss: 0.1467
Epoch: 14/20 | Batch: 71/455 | Loss: 0.5563
Epoch: 14/20 | Batch: 81/455 | Loss: 0.1229
Epoch: 14/20 | Batch: 91/455 | Loss: 0.5464
Epoch: 14/20 | Batch: 101/455 | Loss: 0.3559
Epoch: 14/20 | Batch: 111/455 | Loss: 0.8395
Epoch: 14/20 | Batch: 121/455 | Loss: 0.2326
Epoch: 14/20 | Batch: 131/455 | Loss: 0.5862
Epoch: 14/20 | Batch: 141/455 | Loss: 0.1583
Epoch: 14/20 | Batch: 151/455 | Loss: 0.4861
Epoch: 14/20 | Batch: 161/455 | Loss: 0.7421
Epoch: 14/20 | Batch: 171/455 | Loss: 0.1569
Epoch: 14/20 | Batch: 181/455 | Loss: 0.0819
Epoch: 14/20 | Batch: 191/455 | Loss: 0.1799
Epoch: 14/20 | Batch: 201/455 | Loss: 0.6581
Epoch: 14/20 | Batch: 211/455 | Loss: 0.1948
Epoch: 14/20 | Batch: 221/455 | Loss: 0.5672
Epoch: 14/20 | Batch: 231/455 | Loss: 0.5967
Epoch: 14/20 | Batch: 241/455 | Loss: 0.1857
Epoch: 14/20 | Batch: 251/455 | Loss: 0.7465
Epoch: 14/20 | Batch: 261/455 | Loss: 0.7794
Epoch: 14/20 | Batch: 271/455 | Loss: 0.6003
Epoch: 14/20 | Batch: 281/455 | Loss: 0.0870
Epoch: 14/20 | Batch: 291/455 | Loss: 0.3080
Epoch: 14/20 | Batch: 301/455 | Loss: 0.4129
Epoch: 14/20 | Batch: 311/455 | Loss: 0.2433
Epoch: 14/20 | Batch: 321/455 | Loss: 0.1428
Epoch: 14/20 | Batch: 331/455 | Loss: 0.3415
Epoch: 14/20 | Batch: 341/455 | Loss: 0.3725
Epoch: 14/20 | Batch: 351/455 | Loss: 0.0806
Epoch: 14/20 | Batch: 361/455 | Loss: 0.2283
Epoch: 14/20 | Batch: 371/455 | Loss: 0.1521
Epoch: 14/20 | Batch: 381/455 | Loss: 0.3176
Epoch: 14/20 | Batch: 391/455 | Loss: 0.1839
Epoch: 14/20 | Batch: 401/455 | Loss: 0.3204
Epoch: 14/20 | Batch: 411/455 | Loss: 0.3768
Epoch: 14/20 | Batch: 421/455 | Loss: 0.4341
Epoch: 14/20 | Batch: 431/455 | Loss: 0.4889
Epoch: 14/20 | Batch: 441/455 | Loss: 0.6866
Epoch: 14/20 | Batch: 451/455 | Loss: 0.0268
Epoch: 14/20 | Train Loss: 0.3472 | Train Acc: 90.99% | Val Loss: 0.2565 | Val Acc: 92.01%
Current learning rate: 1e-05
Current learning rate: 1e-05
Current learning rate: 1e-05
Current learning rate: 1e-05
Current learning rate: 1e-05
Current learning rate: 1e-05
Current learning rate: 1e-05
Best accuracy: 92.01%
Model saved to checkpoints\resnet18_pretrained_best.pth
Epoch: 15/20 | Batch: 1/455 | Loss: 0.0726
Epoch: 15/20 | Batch: 11/455 | Loss: 0.0977
Epoch: 15/20 | Batch: 21/455 | Loss: 0.0497
Epoch: 15/20 | Batch: 31/455 | Loss: 0.2135
Epoch: 15/20 | Batch: 41/455 | Loss: 0.3426
Epoch: 15/20 | Batch: 51/455 | Loss: 0.1079
Epoch: 15/20 | Batch: 61/455 | Loss: 0.2574
Epoch: 15/20 | Batch: 71/455 | Loss: 0.3487
Epoch: 15/20 | Batch: 81/455 | Loss: 0.2586
Epoch: 15/20 | Batch: 91/455 | Loss: 0.2280
Epoch: 15/20 | Batch: 101/455 | Loss: 0.3471
Epoch: 15/20 | Batch: 111/455 | Loss: 0.1554
Epoch: 15/20 | Batch: 121/455 | Loss: 0.1445
Epoch: 15/20 | Batch: 131/455 | Loss: 0.2456
Epoch: 15/20 | Batch: 141/455 | Loss: 0.2694
Epoch: 15/20 | Batch: 151/455 | Loss: 0.8007
Epoch: 15/20 | Batch: 161/455 | Loss: 0.2061
Epoch: 15/20 | Batch: 171/455 | Loss: 0.1607
Epoch: 15/20 | Batch: 181/455 | Loss: 0.3903
Epoch: 15/20 | Batch: 191/455 | Loss: 0.3888
Epoch: 15/20 | Batch: 201/455 | Loss: 0.3275
Epoch: 15/20 | Batch: 211/455 | Loss: 0.2230
Epoch: 15/20 | Batch: 221/455 | Loss: 0.4749
Epoch: 15/20 | Batch: 231/455 | Loss: 0.2325
Epoch: 15/20 | Batch: 241/455 | Loss: 0.3522
Epoch: 15/20 | Batch: 251/455 | Loss: 0.7746
Epoch: 15/20 | Batch: 261/455 | Loss: 0.2733
Epoch: 15/20 | Batch: 271/455 | Loss: 0.2526
Epoch: 15/20 | Batch: 281/455 | Loss: 0.1776
Epoch: 15/20 | Batch: 291/455 | Loss: 0.3834
Epoch: 15/20 | Batch: 301/455 | Loss: 0.2282
Epoch: 15/20 | Batch: 311/455 | Loss: 0.3013
Epoch: 15/20 | Batch: 321/455 | Loss: 0.1546
Epoch: 15/20 | Batch: 331/455 | Loss: 0.1722
Epoch: 15/20 | Batch: 341/455 | Loss: 0.2832
Epoch: 15/20 | Batch: 351/455 | Loss: 0.3671
Epoch: 15/20 | Batch: 361/455 | Loss: 0.4578
Epoch: 15/20 | Batch: 371/455 | Loss: 0.1093
Epoch: 15/20 | Batch: 381/455 | Loss: 0.3704
Epoch: 15/20 | Batch: 391/455 | Loss: 0.2983
Epoch: 15/20 | Batch: 401/455 | Loss: 0.3109
Epoch: 15/20 | Batch: 411/455 | Loss: 0.2500
Epoch: 15/20 | Batch: 421/455 | Loss: 0.3243
Epoch: 15/20 | Batch: 431/455 | Loss: 0.0313
Epoch: 15/20 | Batch: 441/455 | Loss: 0.1510
Epoch: 15/20 | Batch: 451/455 | Loss: 0.3183
Epoch: 15/20 | Train Loss: 0.2953 | Train Acc: 92.31% | Val Loss: 0.2453 | Val Acc: 92.44%
Current learning rate: 1e-05
Current learning rate: 1e-05
Current learning rate: 1e-05
Current learning rate: 1e-05
Current learning rate: 1e-05
Current learning rate: 1e-05
Current learning rate: 1e-05
Best accuracy: 92.44%
Model saved to checkpoints\resnet18_pretrained_best.pth
Epoch: 16/20 | Batch: 1/455 | Loss: 0.3189
Epoch: 16/20 | Batch: 11/455 | Loss: 0.1455
Epoch: 16/20 | Batch: 21/455 | Loss: 0.4681
Epoch: 16/20 | Batch: 31/455 | Loss: 0.4162
Epoch: 16/20 | Batch: 41/455 | Loss: 0.1921
Epoch: 16/20 | Batch: 51/455 | Loss: 0.7755
Epoch: 16/20 | Batch: 61/455 | Loss: 0.1984
Epoch: 16/20 | Batch: 71/455 | Loss: 0.2153
Epoch: 16/20 | Batch: 81/455 | Loss: 0.1548
Epoch: 16/20 | Batch: 91/455 | Loss: 0.8691
Epoch: 16/20 | Batch: 101/455 | Loss: 0.3189
Epoch: 16/20 | Batch: 111/455 | Loss: 0.1272
Epoch: 16/20 | Batch: 121/455 | Loss: 0.4588
Epoch: 16/20 | Batch: 131/455 | Loss: 0.0272
Epoch: 16/20 | Batch: 141/455 | Loss: 0.0445
Epoch: 16/20 | Batch: 151/455 | Loss: 0.5386
Epoch: 16/20 | Batch: 161/455 | Loss: 0.0519
Epoch: 16/20 | Batch: 171/455 | Loss: 0.0479
Epoch: 16/20 | Batch: 181/455 | Loss: 0.4759
Epoch: 16/20 | Batch: 191/455 | Loss: 0.4985
Epoch: 16/20 | Batch: 201/455 | Loss: 0.0839
Epoch: 16/20 | Batch: 211/455 | Loss: 0.0766
Epoch: 16/20 | Batch: 221/455 | Loss: 0.3299
Epoch: 16/20 | Batch: 231/455 | Loss: 0.7650
Epoch: 16/20 | Batch: 241/455 | Loss: 0.4551
Epoch: 16/20 | Batch: 251/455 | Loss: 0.2597
Epoch: 16/20 | Batch: 261/455 | Loss: 0.1788
Epoch: 16/20 | Batch: 271/455 | Loss: 0.0516
Epoch: 16/20 | Batch: 281/455 | Loss: 0.0565
Epoch: 16/20 | Batch: 291/455 | Loss: 0.0809
Epoch: 16/20 | Batch: 301/455 | Loss: 0.3510
Epoch: 16/20 | Batch: 311/455 | Loss: 0.2340
Epoch: 16/20 | Batch: 321/455 | Loss: 0.5339
Epoch: 16/20 | Batch: 331/455 | Loss: 0.0490
Epoch: 16/20 | Batch: 341/455 | Loss: 0.7416
Epoch: 16/20 | Batch: 351/455 | Loss: 0.1494
Epoch: 16/20 | Batch: 361/455 | Loss: 0.3351
Epoch: 16/20 | Batch: 371/455 | Loss: 0.4039
Epoch: 16/20 | Batch: 381/455 | Loss: 0.1975
Epoch: 16/20 | Batch: 391/455 | Loss: 0.4738
Epoch: 16/20 | Batch: 401/455 | Loss: 0.1220
Epoch: 16/20 | Batch: 411/455 | Loss: 0.5165
Epoch: 16/20 | Batch: 421/455 | Loss: 0.3208
Epoch: 16/20 | Batch: 431/455 | Loss: 0.0399
Epoch: 16/20 | Batch: 441/455 | Loss: 0.3586
Epoch: 16/20 | Batch: 451/455 | Loss: 0.2350
Epoch: 16/20 | Train Loss: 0.2938 | Train Acc: 92.47% | Val Loss: 0.2465 | Val Acc: 92.92%
Current learning rate: 1e-05
Current learning rate: 1e-05
Current learning rate: 1e-05
Current learning rate: 1e-05
Current learning rate: 1e-05
Current learning rate: 1e-05
Current learning rate: 1e-05
Best accuracy: 92.92%
Model saved to checkpoints\resnet18_pretrained_best.pth
Epoch: 17/20 | Batch: 1/455 | Loss: 0.0790
Epoch: 17/20 | Batch: 11/455 | Loss: 0.2364
Epoch: 17/20 | Batch: 21/455 | Loss: 0.4014
Epoch: 17/20 | Batch: 31/455 | Loss: 0.0559
Epoch: 17/20 | Batch: 41/455 | Loss: 0.4964
Epoch: 17/20 | Batch: 51/455 | Loss: 0.2139
Epoch: 17/20 | Batch: 61/455 | Loss: 0.5582
Epoch: 17/20 | Batch: 71/455 | Loss: 0.5030
Epoch: 17/20 | Batch: 81/455 | Loss: 0.2678
Epoch: 17/20 | Batch: 91/455 | Loss: 0.2994
Epoch: 17/20 | Batch: 101/455 | Loss: 0.6071
Epoch: 17/20 | Batch: 111/455 | Loss: 0.3870
Epoch: 17/20 | Batch: 121/455 | Loss: 0.1378
Epoch: 17/20 | Batch: 131/455 | Loss: 0.0813
Epoch: 17/20 | Batch: 141/455 | Loss: 0.2519
Epoch: 17/20 | Batch: 151/455 | Loss: 0.3618
Epoch: 17/20 | Batch: 161/455 | Loss: 0.1590
Epoch: 17/20 | Batch: 171/455 | Loss: 0.3932
Epoch: 17/20 | Batch: 181/455 | Loss: 0.1000
Epoch: 17/20 | Batch: 191/455 | Loss: 0.1749
Epoch: 17/20 | Batch: 201/455 | Loss: 0.1140
Epoch: 17/20 | Batch: 211/455 | Loss: 0.2928
Epoch: 17/20 | Batch: 221/455 | Loss: 0.2620
Epoch: 17/20 | Batch: 231/455 | Loss: 0.0335
Epoch: 17/20 | Batch: 241/455 | Loss: 0.4281
Epoch: 17/20 | Batch: 251/455 | Loss: 0.3271
Epoch: 17/20 | Batch: 261/455 | Loss: 0.3806
Epoch: 17/20 | Batch: 271/455 | Loss: 0.3917
Epoch: 17/20 | Batch: 281/455 | Loss: 0.4096
Epoch: 17/20 | Batch: 291/455 | Loss: 0.1232
Epoch: 17/20 | Batch: 301/455 | Loss: 0.1349
Epoch: 17/20 | Batch: 311/455 | Loss: 0.1774
Epoch: 17/20 | Batch: 321/455 | Loss: 0.2579
Epoch: 17/20 | Batch: 331/455 | Loss: 0.1553
Epoch: 17/20 | Batch: 341/455 | Loss: 0.3939
Epoch: 17/20 | Batch: 351/455 | Loss: 0.3372
Epoch: 17/20 | Batch: 361/455 | Loss: 0.1295
Epoch: 17/20 | Batch: 371/455 | Loss: 0.1029
Epoch: 17/20 | Batch: 381/455 | Loss: 0.0842
Epoch: 17/20 | Batch: 391/455 | Loss: 0.7272
Epoch: 17/20 | Batch: 401/455 | Loss: 0.1126
Epoch: 17/20 | Batch: 411/455 | Loss: 0.0394
Epoch: 17/20 | Batch: 421/455 | Loss: 0.3316
Epoch: 17/20 | Batch: 431/455 | Loss: 0.3016
Epoch: 17/20 | Batch: 441/455 | Loss: 0.2136
Epoch: 17/20 | Batch: 451/455 | Loss: 0.2291
Epoch: 17/20 | Train Loss: 0.2706 | Train Acc: 92.98% | Val Loss: 0.2357 | Val Acc: 92.92%
Current learning rate: 1e-05
Current learning rate: 1e-05
Current learning rate: 1e-05
Current learning rate: 1e-05
Current learning rate: 1e-05
Current learning rate: 1e-05
Current learning rate: 1e-05
Epoch: 18/20 | Batch: 1/455 | Loss: 0.1465
Epoch: 18/20 | Batch: 11/455 | Loss: 0.1844
Epoch: 18/20 | Batch: 21/455 | Loss: 0.0531
Epoch: 18/20 | Batch: 31/455 | Loss: 0.3071
Epoch: 18/20 | Batch: 41/455 | Loss: 0.1043
Epoch: 18/20 | Batch: 51/455 | Loss: 0.3462
Epoch: 18/20 | Batch: 61/455 | Loss: 0.0562
Epoch: 18/20 | Batch: 71/455 | Loss: 0.5252
Epoch: 18/20 | Batch: 81/455 | Loss: 1.1996
Epoch: 18/20 | Batch: 91/455 | Loss: 0.2354
Epoch: 18/20 | Batch: 101/455 | Loss: 0.2566
Epoch: 18/20 | Batch: 111/455 | Loss: 0.5615
Epoch: 18/20 | Batch: 121/455 | Loss: 0.3873
Epoch: 18/20 | Batch: 131/455 | Loss: 0.0569
Epoch: 18/20 | Batch: 141/455 | Loss: 0.8272
Epoch: 18/20 | Batch: 151/455 | Loss: 0.3856
Epoch: 18/20 | Batch: 161/455 | Loss: 0.0186
Epoch: 18/20 | Batch: 171/455 | Loss: 0.0575
Epoch: 18/20 | Batch: 181/455 | Loss: 0.5927
Epoch: 18/20 | Batch: 191/455 | Loss: 0.5241
Epoch: 18/20 | Batch: 201/455 | Loss: 0.0919
Epoch: 18/20 | Batch: 211/455 | Loss: 0.0925
Epoch: 18/20 | Batch: 221/455 | Loss: 0.0708
Epoch: 18/20 | Batch: 231/455 | Loss: 0.0151
Epoch: 18/20 | Batch: 241/455 | Loss: 0.0564
Epoch: 18/20 | Batch: 251/455 | Loss: 0.0588
Epoch: 18/20 | Batch: 261/455 | Loss: 0.3589
Epoch: 18/20 | Batch: 271/455 | Loss: 0.3542
Epoch: 18/20 | Batch: 281/455 | Loss: 0.1481
Epoch: 18/20 | Batch: 291/455 | Loss: 0.1286
Epoch: 18/20 | Batch: 301/455 | Loss: 0.8392
Epoch: 18/20 | Batch: 311/455 | Loss: 0.0188
Epoch: 18/20 | Batch: 321/455 | Loss: 0.5221
Epoch: 18/20 | Batch: 331/455 | Loss: 0.1009
Epoch: 18/20 | Batch: 341/455 | Loss: 0.0981
Epoch: 18/20 | Batch: 351/455 | Loss: 0.1599
Epoch: 18/20 | Batch: 361/455 | Loss: 0.7505
Epoch: 18/20 | Batch: 371/455 | Loss: 0.3979
Epoch: 18/20 | Batch: 381/455 | Loss: 0.2008
Epoch: 18/20 | Batch: 391/455 | Loss: 0.2721
Epoch: 18/20 | Batch: 401/455 | Loss: 0.1224
Epoch: 18/20 | Batch: 411/455 | Loss: 0.1206
Epoch: 18/20 | Batch: 421/455 | Loss: 0.0527
Epoch: 18/20 | Batch: 431/455 | Loss: 0.1110
Epoch: 18/20 | Batch: 441/455 | Loss: 0.1230
Epoch: 18/20 | Batch: 451/455 | Loss: 0.2171
Epoch: 18/20 | Train Loss: 0.2748 | Train Acc: 92.93% | Val Loss: 0.2402 | Val Acc: 92.38%
Current learning rate: 1e-05
Current learning rate: 1e-05
Current learning rate: 1e-05
Current learning rate: 1e-05
Current learning rate: 1e-05
Current learning rate: 1e-05
Current learning rate: 1e-05
Epoch: 19/20 | Batch: 1/455 | Loss: 0.4373
Epoch: 19/20 | Batch: 11/455 | Loss: 0.4167
Epoch: 19/20 | Batch: 21/455 | Loss: 0.6065
Epoch: 19/20 | Batch: 31/455 | Loss: 0.1040
Epoch: 19/20 | Batch: 41/455 | Loss: 0.3829
Epoch: 19/20 | Batch: 51/455 | Loss: 0.2078
Epoch: 19/20 | Batch: 61/455 | Loss: 0.1718
Epoch: 19/20 | Batch: 71/455 | Loss: 0.2419
Epoch: 19/20 | Batch: 81/455 | Loss: 0.3606
Epoch: 19/20 | Batch: 91/455 | Loss: 0.5319
Epoch: 19/20 | Batch: 101/455 | Loss: 0.3412
Epoch: 19/20 | Batch: 111/455 | Loss: 0.2718
Epoch: 19/20 | Batch: 121/455 | Loss: 0.3382
Epoch: 19/20 | Batch: 131/455 | Loss: 0.2757
Epoch: 19/20 | Batch: 141/455 | Loss: 0.1600
Epoch: 19/20 | Batch: 151/455 | Loss: 0.3611
Epoch: 19/20 | Batch: 161/455 | Loss: 0.0246
Epoch: 19/20 | Batch: 171/455 | Loss: 0.7361
Epoch: 19/20 | Batch: 181/455 | Loss: 0.4584
Epoch: 19/20 | Batch: 191/455 | Loss: 0.8628
Epoch: 19/20 | Batch: 201/455 | Loss: 0.8701
Epoch: 19/20 | Batch: 211/455 | Loss: 0.5341
Epoch: 19/20 | Batch: 221/455 | Loss: 0.1074
Epoch: 19/20 | Batch: 231/455 | Loss: 0.1374
Epoch: 19/20 | Batch: 241/455 | Loss: 0.2350
Epoch: 19/20 | Batch: 251/455 | Loss: 0.4028
Epoch: 19/20 | Batch: 261/455 | Loss: 0.6780
Epoch: 19/20 | Batch: 271/455 | Loss: 0.5069
Epoch: 19/20 | Batch: 281/455 | Loss: 0.0181
Epoch: 19/20 | Batch: 291/455 | Loss: 0.3611
Epoch: 19/20 | Batch: 301/455 | Loss: 0.0831
Epoch: 19/20 | Batch: 311/455 | Loss: 0.2111
Epoch: 19/20 | Batch: 321/455 | Loss: 0.3546
Epoch: 19/20 | Batch: 331/455 | Loss: 0.6338
Epoch: 19/20 | Batch: 341/455 | Loss: 0.0428
Epoch: 19/20 | Batch: 351/455 | Loss: 0.2532
Epoch: 19/20 | Batch: 361/455 | Loss: 0.2345
Epoch: 19/20 | Batch: 371/455 | Loss: 0.2553
Epoch: 19/20 | Batch: 381/455 | Loss: 0.1021
Epoch: 19/20 | Batch: 391/455 | Loss: 0.1209
Epoch: 19/20 | Batch: 401/455 | Loss: 0.4493
Epoch: 19/20 | Batch: 411/455 | Loss: 0.3106
Epoch: 19/20 | Batch: 421/455 | Loss: 0.3885
Epoch: 19/20 | Batch: 431/455 | Loss: 0.0709
Epoch: 19/20 | Batch: 441/455 | Loss: 0.0860
Epoch: 19/20 | Batch: 451/455 | Loss: 0.7993
Epoch: 19/20 | Train Loss: 0.2722 | Train Acc: 93.06% | Val Loss: 0.2407 | Val Acc: 92.81%
Current learning rate: 1e-05
Current learning rate: 1e-05
Current learning rate: 1e-05
Current learning rate: 1e-05
Current learning rate: 1e-05
Current learning rate: 1e-05
Current learning rate: 1e-05
Epoch: 20/20 | Batch: 1/455 | Loss: 0.0474
Epoch: 20/20 | Batch: 11/455 | Loss: 0.2036
Epoch: 20/20 | Batch: 21/455 | Loss: 0.4188
Epoch: 20/20 | Batch: 31/455 | Loss: 0.0178
Epoch: 20/20 | Batch: 41/455 | Loss: 0.2535
Epoch: 20/20 | Batch: 51/455 | Loss: 0.2239
Epoch: 20/20 | Batch: 61/455 | Loss: 0.0511
Epoch: 20/20 | Batch: 71/455 | Loss: 0.3526
Epoch: 20/20 | Batch: 81/455 | Loss: 0.2278
Epoch: 20/20 | Batch: 91/455 | Loss: 0.3500
Epoch: 20/20 | Batch: 101/455 | Loss: 0.8241
Epoch: 20/20 | Batch: 111/455 | Loss: 0.2042
Epoch: 20/20 | Batch: 121/455 | Loss: 0.1197
Epoch: 20/20 | Batch: 131/455 | Loss: 0.2484
Epoch: 20/20 | Batch: 141/455 | Loss: 0.0501
Epoch: 20/20 | Batch: 151/455 | Loss: 0.0852
Epoch: 20/20 | Batch: 161/455 | Loss: 0.3966
Epoch: 20/20 | Batch: 171/455 | Loss: 0.0452
Epoch: 20/20 | Batch: 181/455 | Loss: 0.3321
Epoch: 20/20 | Batch: 191/455 | Loss: 0.1369
Epoch: 20/20 | Batch: 201/455 | Loss: 0.0651
Epoch: 20/20 | Batch: 211/455 | Loss: 0.2964
Epoch: 20/20 | Batch: 221/455 | Loss: 0.0407
Epoch: 20/20 | Batch: 231/455 | Loss: 0.3870
Epoch: 20/20 | Batch: 241/455 | Loss: 0.0814
Epoch: 20/20 | Batch: 251/455 | Loss: 0.3054
Epoch: 20/20 | Batch: 261/455 | Loss: 0.2075
Epoch: 20/20 | Batch: 271/455 | Loss: 0.2001
Epoch: 20/20 | Batch: 281/455 | Loss: 0.2049
Epoch: 20/20 | Batch: 291/455 | Loss: 0.2033
Epoch: 20/20 | Batch: 301/455 | Loss: 0.1914
Epoch: 20/20 | Batch: 311/455 | Loss: 0.6200
Epoch: 20/20 | Batch: 321/455 | Loss: 0.2367
Epoch: 20/20 | Batch: 331/455 | Loss: 0.2434
Epoch: 20/20 | Batch: 341/455 | Loss: 0.0439
Epoch: 20/20 | Batch: 351/455 | Loss: 0.0924
Epoch: 20/20 | Batch: 361/455 | Loss: 0.0562
Epoch: 20/20 | Batch: 371/455 | Loss: 0.3066
Epoch: 20/20 | Batch: 381/455 | Loss: 0.1203
Epoch: 20/20 | Batch: 391/455 | Loss: 0.0869
Epoch: 20/20 | Batch: 401/455 | Loss: 0.6390
Epoch: 20/20 | Batch: 411/455 | Loss: 0.2915
Epoch: 20/20 | Batch: 421/455 | Loss: 0.2460
Epoch: 20/20 | Batch: 431/455 | Loss: 0.1074
Epoch: 20/20 | Batch: 441/455 | Loss: 0.2537
Epoch: 20/20 | Batch: 451/455 | Loss: 0.1033
Epoch: 20/20 | Train Loss: 0.2655 | Train Acc: 92.93% | Val Loss: 0.2316 | Val Acc: 92.97%
Current learning rate: 1e-05
Current learning rate: 1e-05
Current learning rate: 1e-05
Current learning rate: 1e-05
Current learning rate: 1e-05
Current learning rate: 1e-05
Current learning rate: 1e-05
Best accuracy: 92.97%
Model saved to checkpoints\resnet18_pretrained_best.pth

(base) C:\Users\26336\Desktop\FDU\神经网络\home_work_2>

              11 File(s)    137,627,457 bytes
               9 Dir(s)   9,593,823,232 bytes free

(base) C:\Users\26336\Desktop\FDU\神经网络\home_work_2>python main.py
Training with pretrained weights...
Number of classes: 102
Class names: ['BACKGROUND_Google', 'Faces', 'Faces_easy', 'Leopards', 'Motorbikes', 'accordion', 'airplanes', 'anchor', 'ant', 'barrel', 'bass', 'beaver', 'binocular', 'bonsai', 'brain', 'brontosaurus', 'buddha', 'butterfly', 'camera', 'cannon', 'car_side', 'ceiling_fan', 'cellphone', 'chair', 'chandelier', 'cougar_body', 'cougar_face', 'crab', 'crayfish', 'crocodile', 'crocodile_head', 'cup', 'dalmatian', 'dollar_bill', 'dolphin', 'dragonfly', 'electric_guitar', 'elephant', 'emu', 'euphonium', 'ewer', 'ferry', 'flamingo', 'flamingo_head', 'garfield', 'gerenuk', 'gramophone', 'grand_piano', 'hawksbill', 'headphone', 'hedgehog', 'helicopter', 'ibis', 'inline_skate', 'joshua_tree', 'kangaroo', 'ketch', 'lamp', 'laptop', 'llama', 'lobster', 'lotus', 'mandolin', 'mayfly', 'menorah', 'metronome', 'minaret', 'nautilus', 'octopus', 'okapi', 'pagoda', 'panda', 'pigeon', 'pizza', 'platypus', 'pyramid', 'revolver', 'rhino', 'rooster', 'saxophone', 'schooner', 'scissors', 'scorpion', 'sea_horse', 'snoopy', 'soccer_ball', 'stapler', 'starfish', 'stegosaurus', 'stop_sign', 'strawberry', 'sunflower', 'tick', 'trilobite', 'umbrella', 'watch', 'water_lilly', 'wheelchair', 'wild_cat', 'windsor_chair', 'wrench', 'yin_yang']
Training samples: 7280
Validation samples: 1864
Epoch: 1/20 | Batch: 1/114 | Loss: 4.6658
Epoch: 1/20 | Batch: 11/114 | Loss: 3.0216
Epoch: 1/20 | Batch: 21/114 | Loss: 2.3485
Epoch: 1/20 | Batch: 31/114 | Loss: 2.4224
Epoch: 1/20 | Batch: 41/114 | Loss: 2.2412
Epoch: 1/20 | Batch: 51/114 | Loss: 1.8460
Epoch: 1/20 | Batch: 61/114 | Loss: 1.6058
Epoch: 1/20 | Batch: 71/114 | Loss: 1.2207
Epoch: 1/20 | Batch: 81/114 | Loss: 1.1752
Epoch: 1/20 | Batch: 91/114 | Loss: 1.2544
Epoch: 1/20 | Batch: 101/114 | Loss: 0.8236
Epoch: 1/20 | Batch: 111/114 | Loss: 1.3077
Epoch: 1/20 | Train Loss: 1.9094 | Train Acc: 57.84% | Val Loss: 0.5884 | Val Acc: 82.94%
Current learning rate: 0.0001
Current learning rate: 0.0001
Current learning rate: 0.0001
Current learning rate: 0.0001
Current learning rate: 0.0001
Current learning rate: 0.0001
Current learning rate: 0.001
Best accuracy: 82.94%
Model saved to checkpoints\resnet18_pretrained_best.pth
Epoch: 2/20 | Batch: 1/114 | Loss: 0.9509
Epoch: 2/20 | Batch: 11/114 | Loss: 0.7092
Epoch: 2/20 | Batch: 21/114 | Loss: 0.9748
Epoch: 2/20 | Batch: 31/114 | Loss: 0.6799
Epoch: 2/20 | Batch: 41/114 | Loss: 1.0864
Epoch: 2/20 | Batch: 51/114 | Loss: 0.8440
Epoch: 2/20 | Batch: 61/114 | Loss: 1.0310
Epoch: 2/20 | Batch: 71/114 | Loss: 0.5520
Epoch: 2/20 | Batch: 81/114 | Loss: 0.7686
Epoch: 2/20 | Batch: 91/114 | Loss: 0.8832
Epoch: 2/20 | Batch: 101/114 | Loss: 0.9317
Epoch: 2/20 | Batch: 111/114 | Loss: 0.7021
Epoch: 2/20 | Train Loss: 0.7640 | Train Acc: 80.00% | Val Loss: 0.4050 | Val Acc: 88.09%
Current learning rate: 0.0001
Current learning rate: 0.0001
Current learning rate: 0.0001
Current learning rate: 0.0001
Current learning rate: 0.0001
Current learning rate: 0.0001
Current learning rate: 0.001
Best accuracy: 88.09%
Model saved to checkpoints\resnet18_pretrained_best.pth
Epoch: 3/20 | Batch: 1/114 | Loss: 0.5220
Epoch: 3/20 | Batch: 11/114 | Loss: 0.7397
Epoch: 3/20 | Batch: 21/114 | Loss: 0.4320
Epoch: 3/20 | Batch: 31/114 | Loss: 0.7630
Epoch: 3/20 | Batch: 41/114 | Loss: 0.3803
Epoch: 3/20 | Batch: 51/114 | Loss: 0.6437
Epoch: 3/20 | Batch: 61/114 | Loss: 0.5285
Epoch: 3/20 | Batch: 71/114 | Loss: 0.5433
Epoch: 3/20 | Batch: 81/114 | Loss: 0.5524
Epoch: 3/20 | Batch: 91/114 | Loss: 0.5875
Epoch: 3/20 | Batch: 101/114 | Loss: 0.7603
Epoch: 3/20 | Batch: 111/114 | Loss: 0.8338
Epoch: 3/20 | Train Loss: 0.5832 | Train Acc: 84.45% | Val Loss: 0.3352 | Val Acc: 90.93%
Current learning rate: 0.0001
Current learning rate: 0.0001
Current learning rate: 0.0001
Current learning rate: 0.0001
Current learning rate: 0.0001
Current learning rate: 0.0001
Current learning rate: 0.001
Best accuracy: 90.93%
Model saved to checkpoints\resnet18_pretrained_best.pth
Epoch: 4/20 | Batch: 1/114 | Loss: 0.5316
Epoch: 4/20 | Batch: 11/114 | Loss: 0.5396
Epoch: 4/20 | Batch: 21/114 | Loss: 0.5491
Epoch: 4/20 | Batch: 31/114 | Loss: 0.5015
Epoch: 4/20 | Batch: 41/114 | Loss: 0.5718
Epoch: 4/20 | Batch: 51/114 | Loss: 0.4046
Epoch: 4/20 | Batch: 61/114 | Loss: 0.6560
Epoch: 4/20 | Batch: 71/114 | Loss: 0.4395
Epoch: 4/20 | Batch: 81/114 | Loss: 0.5607
Epoch: 4/20 | Batch: 91/114 | Loss: 0.7372
Epoch: 4/20 | Batch: 101/114 | Loss: 0.3505
Epoch: 4/20 | Batch: 111/114 | Loss: 0.7812
Epoch: 4/20 | Train Loss: 0.4836 | Train Acc: 86.59% | Val Loss: 0.3308 | Val Acc: 89.65%
Current learning rate: 0.0001
Current learning rate: 0.0001
Current learning rate: 0.0001
Current learning rate: 0.0001
Current learning rate: 0.0001
Current learning rate: 0.0001
Current learning rate: 0.001
Epoch: 5/20 | Batch: 1/114 | Loss: 0.4566
Epoch: 5/20 | Batch: 11/114 | Loss: 0.3683
Epoch: 5/20 | Batch: 21/114 | Loss: 0.2726
Epoch: 5/20 | Batch: 31/114 | Loss: 0.2811
Epoch: 5/20 | Batch: 41/114 | Loss: 0.5203
Epoch: 5/20 | Batch: 51/114 | Loss: 0.4677
Epoch: 5/20 | Batch: 61/114 | Loss: 0.3008
Epoch: 5/20 | Batch: 71/114 | Loss: 0.3617
Epoch: 5/20 | Batch: 81/114 | Loss: 0.6047
Epoch: 5/20 | Batch: 91/114 | Loss: 0.5600
Epoch: 5/20 | Batch: 101/114 | Loss: 0.3313
Epoch: 5/20 | Batch: 111/114 | Loss: 0.4529
Epoch: 5/20 | Train Loss: 0.4316 | Train Acc: 88.15% | Val Loss: 0.2949 | Val Acc: 91.26%
Current learning rate: 0.0001
Current learning rate: 0.0001
Current learning rate: 0.0001
Current learning rate: 0.0001
Current learning rate: 0.0001
Current learning rate: 0.0001
Current learning rate: 0.001
Best accuracy: 91.26%
Model saved to checkpoints\resnet18_pretrained_best.pth
Epoch: 6/20 | Batch: 1/114 | Loss: 0.4449
Epoch: 6/20 | Batch: 11/114 | Loss: 0.2087
Epoch: 6/20 | Batch: 21/114 | Loss: 0.3565
Epoch: 6/20 | Batch: 31/114 | Loss: 0.2809
Epoch: 6/20 | Batch: 41/114 | Loss: 0.4478
Epoch: 6/20 | Batch: 51/114 | Loss: 0.4413
Epoch: 6/20 | Batch: 61/114 | Loss: 0.2825
Epoch: 6/20 | Batch: 71/114 | Loss: 0.3810
Epoch: 6/20 | Batch: 81/114 | Loss: 0.3994
Epoch: 6/20 | Batch: 91/114 | Loss: 0.5227
Epoch: 6/20 | Batch: 101/114 | Loss: 0.4667
Epoch: 6/20 | Batch: 111/114 | Loss: 0.5778
Epoch: 6/20 | Train Loss: 0.3978 | Train Acc: 89.09% | Val Loss: 0.2904 | Val Acc: 91.15%
Current learning rate: 0.0001
Current learning rate: 0.0001
Current learning rate: 0.0001
Current learning rate: 0.0001
Current learning rate: 0.0001
Current learning rate: 0.0001
Current learning rate: 0.001
Epoch: 7/20 | Batch: 1/114 | Loss: 0.1270
Epoch: 7/20 | Batch: 11/114 | Loss: 0.3870
Epoch: 7/20 | Batch: 21/114 | Loss: 0.3699
Epoch: 7/20 | Batch: 31/114 | Loss: 0.3640
Epoch: 7/20 | Batch: 41/114 | Loss: 0.5056
Epoch: 7/20 | Batch: 51/114 | Loss: 0.2056
Epoch: 7/20 | Batch: 61/114 | Loss: 0.3917
Epoch: 7/20 | Batch: 71/114 | Loss: 0.5137
Epoch: 7/20 | Batch: 81/114 | Loss: 0.8003
Epoch: 7/20 | Batch: 91/114 | Loss: 0.3465
Epoch: 7/20 | Batch: 101/114 | Loss: 0.3547
Epoch: 7/20 | Batch: 111/114 | Loss: 0.4511
Epoch: 7/20 | Train Loss: 0.3771 | Train Acc: 89.57% | Val Loss: 0.2983 | Val Acc: 91.74%
Current learning rate: 0.0001
Current learning rate: 0.0001
Current learning rate: 0.0001
Current learning rate: 0.0001
Current learning rate: 0.0001
Current learning rate: 0.0001
Current learning rate: 0.001
Best accuracy: 91.74%
Model saved to checkpoints\resnet18_pretrained_best.pth
Epoch: 8/20 | Batch: 1/114 | Loss: 0.2286
Epoch: 8/20 | Batch: 11/114 | Loss: 0.1899
Epoch: 8/20 | Batch: 21/114 | Loss: 0.1733
Epoch: 8/20 | Batch: 31/114 | Loss: 0.2326
Epoch: 8/20 | Batch: 41/114 | Loss: 0.3081
Epoch: 8/20 | Batch: 51/114 | Loss: 0.3295
Epoch: 8/20 | Batch: 61/114 | Loss: 0.4752
Epoch: 8/20 | Batch: 71/114 | Loss: 0.4616
Epoch: 8/20 | Batch: 81/114 | Loss: 0.2622
Epoch: 8/20 | Batch: 91/114 | Loss: 0.2916
Epoch: 8/20 | Batch: 101/114 | Loss: 0.1441
Epoch: 8/20 | Batch: 111/114 | Loss: 0.4437
Epoch: 8/20 | Train Loss: 0.3485 | Train Acc: 90.44% | Val Loss: 0.2729 | Val Acc: 91.90%
Current learning rate: 0.0001
Current learning rate: 0.0001
Current learning rate: 0.0001
Current learning rate: 0.0001
Current learning rate: 0.0001
Current learning rate: 0.0001
Current learning rate: 0.001
Best accuracy: 91.90%
Model saved to checkpoints\resnet18_pretrained_best.pth
Epoch: 9/20 | Batch: 1/114 | Loss: 0.4033
Epoch: 9/20 | Batch: 11/114 | Loss: 0.3372
Epoch: 9/20 | Batch: 21/114 | Loss: 0.2067
Epoch: 9/20 | Batch: 31/114 | Loss: 0.4575
Epoch: 9/20 | Batch: 41/114 | Loss: 0.3724
Epoch: 9/20 | Batch: 51/114 | Loss: 0.5068
Epoch: 9/20 | Batch: 61/114 | Loss: 0.2859
Epoch: 9/20 | Batch: 71/114 | Loss: 0.3746
Epoch: 9/20 | Batch: 81/114 | Loss: 0.1666
Epoch: 9/20 | Batch: 91/114 | Loss: 0.1859
Epoch: 9/20 | Batch: 101/114 | Loss: 0.3761
Epoch: 9/20 | Batch: 111/114 | Loss: 0.4031
Epoch: 9/20 | Train Loss: 0.3358 | Train Acc: 90.71% | Val Loss: 0.3003 | Val Acc: 90.50%
Current learning rate: 0.0001
Current learning rate: 0.0001
Current learning rate: 0.0001
Current learning rate: 0.0001
Current learning rate: 0.0001
Current learning rate: 0.0001
Current learning rate: 0.001
Epoch: 10/20 | Batch: 1/114 | Loss: 0.3165
Epoch: 10/20 | Batch: 11/114 | Loss: 0.3852
Epoch: 10/20 | Batch: 21/114 | Loss: 0.3117
Epoch: 10/20 | Batch: 31/114 | Loss: 0.1237
Epoch: 10/20 | Batch: 41/114 | Loss: 0.0930
Epoch: 10/20 | Batch: 51/114 | Loss: 0.2566
Epoch: 10/20 | Batch: 61/114 | Loss: 0.7901
Epoch: 10/20 | Batch: 71/114 | Loss: 0.3656
Epoch: 10/20 | Batch: 81/114 | Loss: 0.3242
Epoch: 10/20 | Batch: 91/114 | Loss: 0.4672
Epoch: 10/20 | Batch: 101/114 | Loss: 0.1974
Epoch: 10/20 | Batch: 111/114 | Loss: 0.1921
Epoch: 10/20 | Train Loss: 0.3151 | Train Acc: 91.20% | Val Loss: 0.2718 | Val Acc: 92.01%
Current learning rate: 0.0001
Current learning rate: 0.0001
Current learning rate: 0.0001
Current learning rate: 0.0001
Current learning rate: 0.0001
Current learning rate: 0.0001
Current learning rate: 0.001
Best accuracy: 92.01%
Model saved to checkpoints\resnet18_pretrained_best.pth
Epoch: 11/20 | Batch: 1/114 | Loss: 0.2290
Epoch: 11/20 | Batch: 11/114 | Loss: 0.2347
Epoch: 11/20 | Batch: 21/114 | Loss: 0.4641
Epoch: 11/20 | Batch: 31/114 | Loss: 0.1581
Epoch: 11/20 | Batch: 41/114 | Loss: 0.1920
Epoch: 11/20 | Batch: 51/114 | Loss: 0.3065
Epoch: 11/20 | Batch: 61/114 | Loss: 0.2538
Epoch: 11/20 | Batch: 71/114 | Loss: 0.2962
Epoch: 11/20 | Batch: 81/114 | Loss: 0.2763
Epoch: 11/20 | Batch: 91/114 | Loss: 0.3237
Epoch: 11/20 | Batch: 101/114 | Loss: 0.2910
Epoch: 11/20 | Batch: 111/114 | Loss: 0.2730
Epoch: 11/20 | Train Loss: 0.2992 | Train Acc: 91.50% | Val Loss: 0.2956 | Val Acc: 91.15%
Current learning rate: 0.0001
Current learning rate: 0.0001
Current learning rate: 0.0001
Current learning rate: 0.0001
Current learning rate: 0.0001
Current learning rate: 0.0001
Current learning rate: 0.001
Epoch: 12/20 | Batch: 1/114 | Loss: 0.3562
Epoch: 12/20 | Batch: 11/114 | Loss: 0.2711
Epoch: 12/20 | Batch: 21/114 | Loss: 0.1855
Epoch: 12/20 | Batch: 31/114 | Loss: 0.2992
Epoch: 12/20 | Batch: 41/114 | Loss: 0.3333
Epoch: 12/20 | Batch: 51/114 | Loss: 0.5570
Epoch: 12/20 | Batch: 61/114 | Loss: 0.2656
Epoch: 12/20 | Batch: 71/114 | Loss: 0.3313
Epoch: 12/20 | Batch: 81/114 | Loss: 0.3455
Epoch: 12/20 | Batch: 91/114 | Loss: 0.1459
Epoch: 12/20 | Batch: 101/114 | Loss: 0.3656
Epoch: 12/20 | Batch: 111/114 | Loss: 0.2185
Epoch: 12/20 | Train Loss: 0.3000 | Train Acc: 91.46% | Val Loss: 0.2892 | Val Acc: 92.01%
Current learning rate: 0.0001
Current learning rate: 0.0001
Current learning rate: 0.0001
Current learning rate: 0.0001
Current learning rate: 0.0001
Current learning rate: 0.0001
Current learning rate: 0.001
Epoch: 13/20 | Batch: 1/114 | Loss: 0.1497
Epoch: 13/20 | Batch: 11/114 | Loss: 0.1172
Epoch: 13/20 | Batch: 21/114 | Loss: 0.3562
Epoch: 13/20 | Batch: 31/114 | Loss: 0.0752
Epoch: 13/20 | Batch: 41/114 | Loss: 0.2903
Epoch: 13/20 | Batch: 51/114 | Loss: 0.4366
Epoch: 13/20 | Batch: 61/114 | Loss: 0.2031
Epoch: 13/20 | Batch: 71/114 | Loss: 0.3286
Epoch: 13/20 | Batch: 81/114 | Loss: 0.3229
Epoch: 13/20 | Batch: 91/114 | Loss: 0.3183
Epoch: 13/20 | Batch: 101/114 | Loss: 0.6668
Epoch: 13/20 | Batch: 111/114 | Loss: 0.2967
Epoch: 13/20 | Train Loss: 0.2919 | Train Acc: 91.74% | Val Loss: 0.3194 | Val Acc: 90.67%
Current learning rate: 0.0001
Current learning rate: 0.0001
Current learning rate: 0.0001
Current learning rate: 0.0001
Current learning rate: 0.0001
Current learning rate: 0.0001
Current learning rate: 0.001
Epoch: 14/20 | Batch: 1/114 | Loss: 0.1323
Epoch: 14/20 | Batch: 11/114 | Loss: 0.3230
Epoch: 14/20 | Batch: 21/114 | Loss: 0.3691
Epoch: 14/20 | Batch: 31/114 | Loss: 0.2606
Epoch: 14/20 | Batch: 41/114 | Loss: 0.2508
Epoch: 14/20 | Batch: 51/114 | Loss: 0.3676
Epoch: 14/20 | Batch: 61/114 | Loss: 0.4275
Epoch: 14/20 | Batch: 71/114 | Loss: 0.2554
Epoch: 14/20 | Batch: 81/114 | Loss: 0.2005
Epoch: 14/20 | Batch: 91/114 | Loss: 0.3005
Epoch: 14/20 | Batch: 101/114 | Loss: 0.1567
Epoch: 14/20 | Batch: 111/114 | Loss: 0.0788
Epoch: 14/20 | Train Loss: 0.2896 | Train Acc: 92.23% | Val Loss: 0.3047 | Val Acc: 90.72%
Current learning rate: 0.0001
Current learning rate: 0.0001
Current learning rate: 0.0001
Current learning rate: 0.0001
Current learning rate: 0.0001
Current learning rate: 0.0001
Current learning rate: 0.001
Epoch: 15/20 | Batch: 1/114 | Loss: 0.3935
Epoch: 15/20 | Batch: 11/114 | Loss: 0.2405
Epoch: 15/20 | Batch: 21/114 | Loss: 0.3113
Epoch: 15/20 | Batch: 31/114 | Loss: 0.3042
Epoch: 15/20 | Batch: 41/114 | Loss: 0.2113
Epoch: 15/20 | Batch: 51/114 | Loss: 0.3790
Epoch: 15/20 | Batch: 61/114 | Loss: 0.1834
Epoch: 15/20 | Batch: 71/114 | Loss: 0.3703
Epoch: 15/20 | Batch: 81/114 | Loss: 0.4934
Epoch: 15/20 | Batch: 91/114 | Loss: 0.2065
Epoch: 15/20 | Batch: 101/114 | Loss: 0.2701
Epoch: 15/20 | Batch: 111/114 | Loss: 0.1325
Epoch: 15/20 | Train Loss: 0.2721 | Train Acc: 92.32% | Val Loss: 0.3092 | Val Acc: 90.83%
Current learning rate: 0.0001
Current learning rate: 0.0001
Current learning rate: 0.0001
Current learning rate: 0.0001
Current learning rate: 0.0001
Current learning rate: 0.0001
Current learning rate: 0.001
Epoch: 16/20 | Batch: 1/114 | Loss: 0.1638
Epoch: 16/20 | Batch: 11/114 | Loss: 0.2824
Epoch: 16/20 | Batch: 21/114 | Loss: 0.4750
Epoch: 16/20 | Batch: 31/114 | Loss: 0.4693
Epoch: 16/20 | Batch: 41/114 | Loss: 0.2931
Epoch: 16/20 | Batch: 51/114 | Loss: 0.3290
Epoch: 16/20 | Batch: 61/114 | Loss: 0.0929
Epoch: 16/20 | Batch: 71/114 | Loss: 0.1881
Epoch: 16/20 | Batch: 81/114 | Loss: 0.5147
Epoch: 16/20 | Batch: 91/114 | Loss: 0.3118
Epoch: 16/20 | Batch: 101/114 | Loss: 0.6640
Epoch: 16/20 | Batch: 111/114 | Loss: 0.4315
Epoch: 16/20 | Train Loss: 0.2809 | Train Acc: 91.98% | Val Loss: 0.3175 | Val Acc: 91.31%
Current learning rate: 1e-05
Current learning rate: 1e-05
Current learning rate: 1e-05
Current learning rate: 1e-05
Current learning rate: 1e-05
Current learning rate: 1e-05
Current learning rate: 0.0001
Epoch: 17/20 | Batch: 1/114 | Loss: 0.2341
Epoch: 17/20 | Batch: 11/114 | Loss: 0.2032
Epoch: 17/20 | Batch: 21/114 | Loss: 0.3386
Epoch: 17/20 | Batch: 31/114 | Loss: 0.2540
Epoch: 17/20 | Batch: 41/114 | Loss: 0.1207
Epoch: 17/20 | Batch: 51/114 | Loss: 0.1898
Epoch: 17/20 | Batch: 61/114 | Loss: 0.1908
Epoch: 17/20 | Batch: 71/114 | Loss: 0.1399
Epoch: 17/20 | Batch: 81/114 | Loss: 0.0905
Epoch: 17/20 | Batch: 91/114 | Loss: 0.1592
Epoch: 17/20 | Batch: 101/114 | Loss: 0.0873
Epoch: 17/20 | Batch: 111/114 | Loss: 0.1897
Epoch: 17/20 | Train Loss: 0.2401 | Train Acc: 93.23% | Val Loss: 0.2771 | Val Acc: 91.20%
Current learning rate: 1e-05
Current learning rate: 1e-05
Current learning rate: 1e-05
Current learning rate: 1e-05
Current learning rate: 1e-05
Current learning rate: 1e-05
Current learning rate: 0.0001
Epoch: 18/20 | Batch: 1/114 | Loss: 0.2425
Epoch: 18/20 | Batch: 11/114 | Loss: 0.1915
Epoch: 18/20 | Batch: 21/114 | Loss: 0.3776
Epoch: 18/20 | Batch: 31/114 | Loss: 0.1376
Epoch: 18/20 | Batch: 41/114 | Loss: 0.1510
Epoch: 18/20 | Batch: 51/114 | Loss: 0.1096
Epoch: 18/20 | Batch: 61/114 | Loss: 0.2157
Epoch: 18/20 | Batch: 71/114 | Loss: 0.1416
Epoch: 18/20 | Batch: 81/114 | Loss: 0.4613
Epoch: 18/20 | Batch: 91/114 | Loss: 0.3149
Epoch: 18/20 | Batch: 101/114 | Loss: 0.1984
Epoch: 18/20 | Batch: 111/114 | Loss: 0.2495
Epoch: 18/20 | Train Loss: 0.2153 | Train Acc: 94.24% | Val Loss: 0.2596 | Val Acc: 92.17%
Current learning rate: 1e-05
Current learning rate: 1e-05
Current learning rate: 1e-05
Current learning rate: 1e-05
Current learning rate: 1e-05
Current learning rate: 1e-05
Current learning rate: 0.0001
Best accuracy: 92.17%
Model saved to checkpoints\resnet18_pretrained_best.pth
Epoch: 19/20 | Batch: 1/114 | Loss: 0.2245
Epoch: 19/20 | Batch: 11/114 | Loss: 0.2060
Epoch: 19/20 | Batch: 21/114 | Loss: 0.1463
Epoch: 19/20 | Batch: 31/114 | Loss: 0.1040
Epoch: 19/20 | Batch: 41/114 | Loss: 0.1328
Epoch: 19/20 | Batch: 51/114 | Loss: 0.1737
Epoch: 19/20 | Batch: 61/114 | Loss: 0.1114
Epoch: 19/20 | Batch: 71/114 | Loss: 0.0763
Epoch: 19/20 | Batch: 81/114 | Loss: 0.1670
Epoch: 19/20 | Batch: 91/114 | Loss: 0.0790
Epoch: 19/20 | Batch: 101/114 | Loss: 0.1927
Epoch: 19/20 | Batch: 111/114 | Loss: 0.1618
Epoch: 19/20 | Train Loss: 0.1837 | Train Acc: 94.97% | Val Loss: 0.2601 | Val Acc: 92.22%
Current learning rate: 1e-05
Current learning rate: 1e-05
Current learning rate: 1e-05
Current learning rate: 1e-05
Current learning rate: 1e-05
Current learning rate: 1e-05
Current learning rate: 0.0001
Best accuracy: 92.22%
Model saved to checkpoints\resnet18_pretrained_best.pth
Epoch: 20/20 | Batch: 1/114 | Loss: 0.1330
Epoch: 20/20 | Batch: 11/114 | Loss: 0.3042
Epoch: 20/20 | Batch: 21/114 | Loss: 0.0357
Epoch: 20/20 | Batch: 31/114 | Loss: 0.2634
Epoch: 20/20 | Batch: 41/114 | Loss: 0.1599
Epoch: 20/20 | Batch: 51/114 | Loss: 0.1828
Epoch: 20/20 | Batch: 61/114 | Loss: 0.2298
Epoch: 20/20 | Batch: 71/114 | Loss: 0.1512
Epoch: 20/20 | Batch: 81/114 | Loss: 0.1616
Epoch: 20/20 | Batch: 91/114 | Loss: 0.1041
Epoch: 20/20 | Batch: 101/114 | Loss: 0.2331
Epoch: 20/20 | Batch: 111/114 | Loss: 0.1611
Epoch: 20/20 | Train Loss: 0.2048 | Train Acc: 94.22% | Val Loss: 0.2532 | Val Acc: 92.11%
Current learning rate: 1e-05
Current learning rate: 1e-05
Current learning rate: 1e-05
Current learning rate: 1e-05
Current learning rate: 1e-05
Current learning rate: 1e-05
Current learning rate: 0.0001

(base) C:\Users\26336\Desktop\FDU\神经网络\home_work_2>
(base) C:\Users\26336\Desktop\FDU\神经网络\home_work_2>
(base) C:\Users\26336\Desktop\FDU\神经网络\home_work_2>python main.py
Training with pretrained weights...
Number of classes: 102
Class names: ['BACKGROUND_Google', 'Faces', 'Faces_easy', 'Leopards', 'Motorbikes', 'accordion', 'airplanes', 'anchor', 'ant', 'barrel', 'bass', 'beaver', 'binocular', 'bonsai', 'brain', 'brontosaurus', 'buddha', 'butterfly', 'camera', 'cannon', 'car_side', 'ceiling_fan', 'cellphone', 'chair', 'chandelier', 'cougar_body', 'cougar_face', 'crab', 'crayfish', 'crocodile', 'crocodile_head', 'cup', 'dalmatian', 'dollar_bill', 'dolphin', 'dragonfly', 'electric_guitar', 'elephant', 'emu', 'euphonium', 'ewer', 'ferry', 'flamingo', 'flamingo_head', 'garfield', 'gerenuk', 'gramophone', 'grand_piano', 'hawksbill', 'headphone', 'hedgehog', 'helicopter', 'ibis', 'inline_skate', 'joshua_tree', 'kangaroo', 'ketch', 'lamp', 'laptop', 'llama', 'lobster', 'lotus', 'mandolin', 'mayfly', 'menorah', 'metronome', 'minaret', 'nautilus', 'octopus', 'okapi', 'pagoda', 'panda', 'pigeon', 'pizza', 'platypus', 'pyramid', 'revolver', 'rhino', 'rooster', 'saxophone', 'schooner', 'scissors', 'scorpion', 'sea_horse', 'snoopy', 'soccer_ball', 'stapler', 'starfish', 'stegosaurus', 'stop_sign', 'strawberry', 'sunflower', 'tick', 'trilobite', 'umbrella', 'watch', 'water_lilly', 'wheelchair', 'wild_cat', 'windsor_chair', 'wrench', 'yin_yang']
Training samples: 7280
Validation samples: 1864
Epoch: 1/20 | Batch: 1/228 | Loss: 4.6762
Epoch: 1/20 | Batch: 11/228 | Loss: 6.2364
Epoch: 1/20 | Batch: 21/228 | Loss: 3.5463
Epoch: 1/20 | Batch: 31/228 | Loss: 3.1937
Epoch: 1/20 | Batch: 41/228 | Loss: 1.9034
Epoch: 1/20 | Batch: 51/228 | Loss: 1.4956
Epoch: 1/20 | Batch: 61/228 | Loss: 2.0562
Epoch: 1/20 | Batch: 71/228 | Loss: 1.7106
Epoch: 1/20 | Batch: 81/228 | Loss: 2.5551
Epoch: 1/20 | Batch: 91/228 | Loss: 1.4034
Epoch: 1/20 | Batch: 101/228 | Loss: 1.6205
Epoch: 1/20 | Batch: 111/228 | Loss: 1.4172
Epoch: 1/20 | Batch: 121/228 | Loss: 0.9403
Epoch: 1/20 | Batch: 131/228 | Loss: 1.6108
Epoch: 1/20 | Batch: 141/228 | Loss: 1.0958
Epoch: 1/20 | Batch: 151/228 | Loss: 1.1113
Epoch: 1/20 | Batch: 161/228 | Loss: 1.8269
Epoch: 1/20 | Batch: 171/228 | Loss: 1.1083
Epoch: 1/20 | Batch: 181/228 | Loss: 1.2394
Epoch: 1/20 | Batch: 191/228 | Loss: 1.2451
Epoch: 1/20 | Batch: 201/228 | Loss: 0.9747
Epoch: 1/20 | Batch: 211/228 | Loss: 1.8671
Epoch: 1/20 | Batch: 221/228 | Loss: 0.9043
Epoch: 1/20 | Train Loss: 2.1191 | Train Acc: 57.99% | Val Loss: 1.3963 | Val Acc: 78.43%
Current learning rate: 0.0001
Current learning rate: 0.0001
Current learning rate: 0.0001
Current learning rate: 0.0001
Current learning rate: 0.0001
Current learning rate: 0.0001
Current learning rate: 0.01
Best accuracy: 78.43%
Model saved to checkpoints\resnet18_pretrained_best.pth
Epoch: 2/20 | Batch: 1/228 | Loss: 1.8856
Epoch: 2/20 | Batch: 11/228 | Loss: 0.7618
Epoch: 2/20 | Batch: 21/228 | Loss: 0.7669
Epoch: 2/20 | Batch: 31/228 | Loss: 1.3523
Epoch: 2/20 | Batch: 41/228 | Loss: 0.8657
Epoch: 2/20 | Batch: 51/228 | Loss: 0.8099
Epoch: 2/20 | Batch: 61/228 | Loss: 0.7661
Epoch: 2/20 | Batch: 71/228 | Loss: 1.0210
Epoch: 2/20 | Batch: 81/228 | Loss: 0.8412
Epoch: 2/20 | Batch: 91/228 | Loss: 0.5773
Epoch: 2/20 | Batch: 101/228 | Loss: 0.6826
Epoch: 2/20 | Batch: 111/228 | Loss: 1.3746
Epoch: 2/20 | Batch: 121/228 | Loss: 1.3338
Epoch: 2/20 | Batch: 131/228 | Loss: 0.9044
Epoch: 2/20 | Batch: 141/228 | Loss: 1.5530
Epoch: 2/20 | Batch: 151/228 | Loss: 0.6782
Epoch: 2/20 | Batch: 161/228 | Loss: 1.3364
Epoch: 2/20 | Batch: 171/228 | Loss: 0.7429
Epoch: 2/20 | Batch: 181/228 | Loss: 1.4436
Epoch: 2/20 | Batch: 191/228 | Loss: 0.8596
Epoch: 2/20 | Batch: 201/228 | Loss: 0.6259
Epoch: 2/20 | Batch: 211/228 | Loss: 0.7827
Epoch: 2/20 | Batch: 221/228 | Loss: 0.5517
Epoch: 2/20 | Train Loss: 1.0664 | Train Acc: 74.05% | Val Loss: 0.6216 | Val Acc: 84.60%
Current learning rate: 0.0001
Current learning rate: 0.0001
Current learning rate: 0.0001
Current learning rate: 0.0001
Current learning rate: 0.0001
Current learning rate: 0.0001
Current learning rate: 0.01
Best accuracy: 84.60%
Model saved to checkpoints\resnet18_pretrained_best.pth
Epoch: 3/20 | Batch: 1/228 | Loss: 1.0169
Epoch: 3/20 | Batch: 11/228 | Loss: 1.6703
Epoch: 3/20 | Batch: 21/228 | Loss: 1.3512
Epoch: 3/20 | Batch: 31/228 | Loss: 2.3040
Epoch: 3/20 | Batch: 41/228 | Loss: 0.5556
Epoch: 3/20 | Batch: 51/228 | Loss: 1.6549
Epoch: 3/20 | Batch: 61/228 | Loss: 3.4893
Epoch: 3/20 | Batch: 71/228 | Loss: 3.3879
Epoch: 3/20 | Batch: 81/228 | Loss: 2.3075
Epoch: 3/20 | Batch: 91/228 | Loss: 0.7979
Epoch: 3/20 | Batch: 101/228 | Loss: 1.2251
Epoch: 3/20 | Batch: 111/228 | Loss: 0.8517
Epoch: 3/20 | Batch: 121/228 | Loss: 1.0089
Epoch: 3/20 | Batch: 131/228 | Loss: 1.8841
Epoch: 3/20 | Batch: 141/228 | Loss: 0.9332
Epoch: 3/20 | Batch: 151/228 | Loss: 0.6977
Epoch: 3/20 | Batch: 161/228 | Loss: 0.5460
Epoch: 3/20 | Batch: 171/228 | Loss: 0.4007
Epoch: 3/20 | Batch: 181/228 | Loss: 0.4052
Epoch: 3/20 | Batch: 191/228 | Loss: 1.1506
Epoch: 3/20 | Batch: 201/228 | Loss: 1.0797
Epoch: 3/20 | Batch: 211/228 | Loss: 1.3293
Epoch: 3/20 | Batch: 221/228 | Loss: 0.7016
Epoch: 3/20 | Train Loss: 1.0764 | Train Acc: 75.52% | Val Loss: 0.4353 | Val Acc: 88.79%
Current learning rate: 0.0001
Current learning rate: 0.0001
Current learning rate: 0.0001
Current learning rate: 0.0001
Current learning rate: 0.0001
Current learning rate: 0.0001
Current learning rate: 0.01
Best accuracy: 88.79%
Model saved to checkpoints\resnet18_pretrained_best.pth
Epoch: 4/20 | Batch: 1/228 | Loss: 0.4089
Epoch: 4/20 | Batch: 11/228 | Loss: 0.6570
Epoch: 4/20 | Batch: 21/228 | Loss: 0.4609
Epoch: 4/20 | Batch: 31/228 | Loss: 0.6021
Epoch: 4/20 | Batch: 41/228 | Loss: 0.6287
Epoch: 4/20 | Batch: 51/228 | Loss: 0.5468
Epoch: 4/20 | Batch: 61/228 | Loss: 0.8855
Epoch: 4/20 | Batch: 71/228 | Loss: 0.7844
Epoch: 4/20 | Batch: 81/228 | Loss: 0.3858
Epoch: 4/20 | Batch: 91/228 | Loss: 0.7412
Epoch: 4/20 | Batch: 101/228 | Loss: 0.4113
Epoch: 4/20 | Batch: 111/228 | Loss: 0.2909
Epoch: 4/20 | Batch: 121/228 | Loss: 0.4173
Epoch: 4/20 | Batch: 131/228 | Loss: 0.5408
Epoch: 4/20 | Batch: 141/228 | Loss: 0.5779
Epoch: 4/20 | Batch: 151/228 | Loss: 0.6453
Epoch: 4/20 | Batch: 161/228 | Loss: 0.9338
Epoch: 4/20 | Batch: 171/228 | Loss: 1.3240
Epoch: 4/20 | Batch: 181/228 | Loss: 0.6933
Epoch: 4/20 | Batch: 191/228 | Loss: 1.0693
Epoch: 4/20 | Batch: 201/228 | Loss: 2.0217
Epoch: 4/20 | Batch: 211/228 | Loss: 0.3863
Epoch: 4/20 | Batch: 221/228 | Loss: 1.2333
Epoch: 4/20 | Train Loss: 0.7964 | Train Acc: 80.41% | Val Loss: 0.4319 | Val Acc: 88.68%
Current learning rate: 0.0001
Current learning rate: 0.0001
Current learning rate: 0.0001
Current learning rate: 0.0001
Current learning rate: 0.0001
Current learning rate: 0.0001
Current learning rate: 0.01
Epoch: 5/20 | Batch: 1/228 | Loss: 1.2756
Epoch: 5/20 | Batch: 11/228 | Loss: 0.7457
Epoch: 5/20 | Batch: 21/228 | Loss: 0.5878
Epoch: 5/20 | Batch: 31/228 | Loss: 1.6078
Epoch: 5/20 | Batch: 41/228 | Loss: 1.0597
Epoch: 5/20 | Batch: 51/228 | Loss: 0.9519
Epoch: 5/20 | Batch: 61/228 | Loss: 0.4675
Epoch: 5/20 | Batch: 71/228 | Loss: 0.9505
Epoch: 5/20 | Batch: 81/228 | Loss: 0.6842
Epoch: 5/20 | Batch: 91/228 | Loss: 1.0676
Epoch: 5/20 | Batch: 101/228 | Loss: 0.5364
Epoch: 5/20 | Batch: 111/228 | Loss: 0.2872
Epoch: 5/20 | Batch: 121/228 | Loss: 0.7220
Epoch: 5/20 | Batch: 131/228 | Loss: 0.7064
Epoch: 5/20 | Batch: 141/228 | Loss: 0.8605
Epoch: 5/20 | Batch: 151/228 | Loss: 0.4810
Epoch: 5/20 | Batch: 161/228 | Loss: 0.8405
Epoch: 5/20 | Batch: 171/228 | Loss: 0.9389
Epoch: 5/20 | Batch: 181/228 | Loss: 0.8740
Epoch: 5/20 | Batch: 191/228 | Loss: 1.4411
Epoch: 5/20 | Batch: 201/228 | Loss: 0.8146
Epoch: 5/20 | Batch: 211/228 | Loss: 0.6016
Epoch: 5/20 | Batch: 221/228 | Loss: 1.0958
Epoch: 5/20 | Train Loss: 0.7316 | Train Acc: 81.03% | Val Loss: 0.4072 | Val Acc: 88.95%
Current learning rate: 0.0001
Current learning rate: 0.0001
Current learning rate: 0.0001
Current learning rate: 0.0001
Current learning rate: 0.0001
Current learning rate: 0.0001
Current learning rate: 0.01
Best accuracy: 88.95%
Model saved to checkpoints\resnet18_pretrained_best.pth
Epoch: 6/20 | Batch: 1/228 | Loss: 0.6663
Epoch: 6/20 | Batch: 11/228 | Loss: 0.4660
Epoch: 6/20 | Batch: 21/228 | Loss: 0.6625
Epoch: 6/20 | Batch: 31/228 | Loss: 0.6626
Epoch: 6/20 | Batch: 41/228 | Loss: 0.7637
Epoch: 6/20 | Batch: 51/228 | Loss: 1.1798
Epoch: 6/20 | Batch: 61/228 | Loss: 0.6523
Epoch: 6/20 | Batch: 71/228 | Loss: 0.4796
Epoch: 6/20 | Batch: 81/228 | Loss: 0.2847
Epoch: 6/20 | Batch: 91/228 | Loss: 0.6876
Epoch: 6/20 | Batch: 101/228 | Loss: 0.4880
Epoch: 6/20 | Batch: 111/228 | Loss: 0.3230
Epoch: 6/20 | Batch: 121/228 | Loss: 1.0349
Epoch: 6/20 | Batch: 131/228 | Loss: 1.0447
Epoch: 6/20 | Batch: 141/228 | Loss: 0.3375
Epoch: 6/20 | Batch: 151/228 | Loss: 0.7243
Epoch: 6/20 | Batch: 161/228 | Loss: 0.2517
Epoch: 6/20 | Batch: 171/228 | Loss: 0.6324
Epoch: 6/20 | Batch: 181/228 | Loss: 0.1195
Epoch: 6/20 | Batch: 191/228 | Loss: 0.5277
Epoch: 6/20 | Batch: 201/228 | Loss: 0.5308
Epoch: 6/20 | Batch: 211/228 | Loss: 0.4704
Epoch: 6/20 | Batch: 221/228 | Loss: 0.2647
Epoch: 6/20 | Train Loss: 0.6830 | Train Acc: 83.61% | Val Loss: 0.3604 | Val Acc: 90.02%
Current learning rate: 0.0001
Current learning rate: 0.0001
Current learning rate: 0.0001
Current learning rate: 0.0001
Current learning rate: 0.0001
Current learning rate: 0.0001
Current learning rate: 0.01
Best accuracy: 90.02%
Model saved to checkpoints\resnet18_pretrained_best.pth
Epoch: 7/20 | Batch: 1/228 | Loss: 0.8584
Epoch: 7/20 | Batch: 11/228 | Loss: 0.9093
Epoch: 7/20 | Batch: 21/228 | Loss: 0.9135
Epoch: 7/20 | Batch: 31/228 | Loss: 0.7677
Epoch: 7/20 | Batch: 41/228 | Loss: 0.8035
Epoch: 7/20 | Batch: 51/228 | Loss: 0.4071
Epoch: 7/20 | Batch: 61/228 | Loss: 0.3789
Epoch: 7/20 | Batch: 71/228 | Loss: 0.2537
Epoch: 7/20 | Batch: 81/228 | Loss: 0.8816
Epoch: 7/20 | Batch: 91/228 | Loss: 0.4488
Epoch: 7/20 | Batch: 101/228 | Loss: 0.4736
Epoch: 7/20 | Batch: 111/228 | Loss: 0.3903
Epoch: 7/20 | Batch: 121/228 | Loss: 0.2752
Epoch: 7/20 | Batch: 131/228 | Loss: 4.0978
Epoch: 7/20 | Batch: 141/228 | Loss: 0.5884
Epoch: 7/20 | Batch: 151/228 | Loss: 1.1066
Epoch: 7/20 | Batch: 161/228 | Loss: 1.0222
Epoch: 7/20 | Batch: 171/228 | Loss: 1.0054
Epoch: 7/20 | Batch: 181/228 | Loss: 0.7392
Epoch: 7/20 | Batch: 191/228 | Loss: 0.5967
Epoch: 7/20 | Batch: 201/228 | Loss: 0.9732
Epoch: 7/20 | Batch: 211/228 | Loss: 0.7979
Epoch: 7/20 | Batch: 221/228 | Loss: 0.9962
Epoch: 7/20 | Train Loss: 0.6739 | Train Acc: 83.59% | Val Loss: 0.3781 | Val Acc: 91.31%
Current learning rate: 0.0001
Current learning rate: 0.0001
Current learning rate: 0.0001
Current learning rate: 0.0001
Current learning rate: 0.0001
Current learning rate: 0.0001
Current learning rate: 0.01
Best accuracy: 91.31%
Model saved to checkpoints\resnet18_pretrained_best.pth
Epoch: 8/20 | Batch: 1/228 | Loss: 0.6699
Epoch: 8/20 | Batch: 11/228 | Loss: 0.4651
Epoch: 8/20 | Batch: 21/228 | Loss: 1.6851
Epoch: 8/20 | Batch: 31/228 | Loss: 0.4364
Epoch: 8/20 | Batch: 41/228 | Loss: 0.5192
Epoch: 8/20 | Batch: 51/228 | Loss: 0.3428
Epoch: 8/20 | Batch: 61/228 | Loss: 0.5484
Epoch: 8/20 | Batch: 71/228 | Loss: 1.2370
Epoch: 8/20 | Batch: 81/228 | Loss: 0.6484
Epoch: 8/20 | Batch: 91/228 | Loss: 0.3373
Epoch: 8/20 | Batch: 101/228 | Loss: 0.5504
Epoch: 8/20 | Batch: 111/228 | Loss: 0.4924
Epoch: 8/20 | Batch: 121/228 | Loss: 0.4658
Epoch: 8/20 | Batch: 131/228 | Loss: 1.0542
Epoch: 8/20 | Batch: 141/228 | Loss: 0.3794
Epoch: 8/20 | Batch: 151/228 | Loss: 0.6951
Epoch: 8/20 | Batch: 161/228 | Loss: 1.0528
Epoch: 8/20 | Batch: 171/228 | Loss: 0.7727
Epoch: 8/20 | Batch: 181/228 | Loss: 0.7669
Epoch: 8/20 | Batch: 191/228 | Loss: 0.3290
Epoch: 8/20 | Batch: 201/228 | Loss: 0.2337
Epoch: 8/20 | Batch: 211/228 | Loss: 0.4942
Epoch: 8/20 | Batch: 221/228 | Loss: 0.4102
Epoch: 8/20 | Train Loss: 0.6275 | Train Acc: 83.53% | Val Loss: 0.4011 | Val Acc: 89.16%
Current learning rate: 0.0001
Current learning rate: 0.0001
Current learning rate: 0.0001
Current learning rate: 0.0001
Current learning rate: 0.0001
Current learning rate: 0.0001
Current learning rate: 0.01
Epoch: 9/20 | Batch: 1/228 | Loss: 2.0682
Epoch: 9/20 | Batch: 11/228 | Loss: 0.5006
Epoch: 9/20 | Batch: 21/228 | Loss: 0.3387
Epoch: 9/20 | Batch: 31/228 | Loss: 0.3991
Epoch: 9/20 | Batch: 41/228 | Loss: 0.2051
Epoch: 9/20 | Batch: 51/228 | Loss: 0.6136
Epoch: 9/20 | Batch: 61/228 | Loss: 0.3769
Epoch: 9/20 | Batch: 71/228 | Loss: 0.6916
Epoch: 9/20 | Batch: 81/228 | Loss: 0.6865
Epoch: 9/20 | Batch: 91/228 | Loss: 0.7116
Epoch: 9/20 | Batch: 101/228 | Loss: 0.1818
Epoch: 9/20 | Batch: 111/228 | Loss: 0.1851
Epoch: 9/20 | Batch: 121/228 | Loss: 0.3476
Epoch: 9/20 | Batch: 131/228 | Loss: 0.3972
Epoch: 9/20 | Batch: 141/228 | Loss: 0.9181
Epoch: 9/20 | Batch: 151/228 | Loss: 0.3724
Epoch: 9/20 | Batch: 161/228 | Loss: 0.9499
Epoch: 9/20 | Batch: 171/228 | Loss: 1.0545
Epoch: 9/20 | Batch: 181/228 | Loss: 0.5802
Epoch: 9/20 | Batch: 191/228 | Loss: 0.7262
Epoch: 9/20 | Batch: 201/228 | Loss: 1.4850
Epoch: 9/20 | Batch: 211/228 | Loss: 0.6797
Epoch: 9/20 | Batch: 221/228 | Loss: 0.6932
Epoch: 9/20 | Train Loss: 0.6399 | Train Acc: 84.64% | Val Loss: 0.8518 | Val Acc: 85.94%
Current learning rate: 0.0001
Current learning rate: 0.0001
Current learning rate: 0.0001
Current learning rate: 0.0001
Current learning rate: 0.0001
Current learning rate: 0.0001
Current learning rate: 0.01
Epoch: 10/20 | Batch: 1/228 | Loss: 0.4517
Epoch: 10/20 | Batch: 11/228 | Loss: 0.7781
Epoch: 10/20 | Batch: 21/228 | Loss: 0.9602
Epoch: 10/20 | Batch: 31/228 | Loss: 0.2837
Epoch: 10/20 | Batch: 41/228 | Loss: 0.9686
Epoch: 10/20 | Batch: 51/228 | Loss: 0.1630
Epoch: 10/20 | Batch: 61/228 | Loss: 0.4147
Epoch: 10/20 | Batch: 71/228 | Loss: 0.1222
Epoch: 10/20 | Batch: 81/228 | Loss: 0.1986
Epoch: 10/20 | Batch: 91/228 | Loss: 0.7137
Epoch: 10/20 | Batch: 101/228 | Loss: 0.6909
Epoch: 10/20 | Batch: 111/228 | Loss: 0.4781
Epoch: 10/20 | Batch: 121/228 | Loss: 0.5076
Epoch: 10/20 | Batch: 131/228 | Loss: 0.6591
Epoch: 10/20 | Batch: 141/228 | Loss: 1.4853
Epoch: 10/20 | Batch: 151/228 | Loss: 0.4934
Epoch: 10/20 | Batch: 161/228 | Loss: 0.6682
Epoch: 10/20 | Batch: 171/228 | Loss: 0.5050
Epoch: 10/20 | Batch: 181/228 | Loss: 1.0147
Epoch: 10/20 | Batch: 191/228 | Loss: 0.5980
Epoch: 10/20 | Batch: 201/228 | Loss: 0.4158
Epoch: 10/20 | Batch: 211/228 | Loss: 0.3819
Epoch: 10/20 | Batch: 221/228 | Loss: 0.2048
Epoch: 10/20 | Train Loss: 0.7068 | Train Acc: 83.49% | Val Loss: 0.5060 | Val Acc: 87.61%
Current learning rate: 0.0001
Current learning rate: 0.0001
Current learning rate: 0.0001
Current learning rate: 0.0001
Current learning rate: 0.0001
Current learning rate: 0.0001
Current learning rate: 0.01
Epoch: 11/20 | Batch: 1/228 | Loss: 1.3441
Epoch: 11/20 | Batch: 11/228 | Loss: 0.4231
Epoch: 11/20 | Batch: 21/228 | Loss: 0.6268
Epoch: 11/20 | Batch: 31/228 | Loss: 0.5660
Epoch: 11/20 | Batch: 41/228 | Loss: 0.4898
Epoch: 11/20 | Batch: 51/228 | Loss: 0.5166
Epoch: 11/20 | Batch: 61/228 | Loss: 0.6372
Epoch: 11/20 | Batch: 71/228 | Loss: 0.5746
Epoch: 11/20 | Batch: 81/228 | Loss: 0.6886
Epoch: 11/20 | Batch: 91/228 | Loss: 0.5356
Epoch: 11/20 | Batch: 101/228 | Loss: 0.7899
Epoch: 11/20 | Batch: 111/228 | Loss: 0.6439
Epoch: 11/20 | Batch: 121/228 | Loss: 0.3608
Epoch: 11/20 | Batch: 131/228 | Loss: 0.2337
Epoch: 11/20 | Batch: 141/228 | Loss: 0.4195
Epoch: 11/20 | Batch: 151/228 | Loss: 0.3115
Epoch: 11/20 | Batch: 161/228 | Loss: 0.4569
Epoch: 11/20 | Batch: 171/228 | Loss: 0.3056
Epoch: 11/20 | Batch: 181/228 | Loss: 0.8807
Epoch: 11/20 | Batch: 191/228 | Loss: 0.1567
Epoch: 11/20 | Batch: 201/228 | Loss: 0.4372
Epoch: 11/20 | Batch: 211/228 | Loss: 0.8698
Epoch: 11/20 | Batch: 221/228 | Loss: 0.6430
Epoch: 11/20 | Train Loss: 0.6934 | Train Acc: 84.11% | Val Loss: 0.6437 | Val Acc: 85.68%
Current learning rate: 0.0001
Current learning rate: 0.0001
Current learning rate: 0.0001
Current learning rate: 0.0001
Current learning rate: 0.0001
Current learning rate: 0.0001
Current learning rate: 0.01
Epoch: 12/20 | Batch: 1/228 | Loss: 0.3519
Epoch: 12/20 | Batch: 11/228 | Loss: 1.0129
Epoch: 12/20 | Batch: 21/228 | Loss: 0.6722
Epoch: 12/20 | Batch: 31/228 | Loss: 0.6682
Epoch: 12/20 | Batch: 41/228 | Loss: 1.1437
Epoch: 12/20 | Batch: 51/228 | Loss: 0.8917
Epoch: 12/20 | Batch: 61/228 | Loss: 0.9718
Epoch: 12/20 | Batch: 71/228 | Loss: 0.4643
Epoch: 12/20 | Batch: 81/228 | Loss: 0.6331
Epoch: 12/20 | Batch: 91/228 | Loss: 0.6959
Epoch: 12/20 | Batch: 101/228 | Loss: 0.9695
Epoch: 12/20 | Batch: 111/228 | Loss: 0.3430
Epoch: 12/20 | Batch: 121/228 | Loss: 0.5881
Epoch: 12/20 | Batch: 131/228 | Loss: 0.5864
Epoch: 12/20 | Batch: 141/228 | Loss: 0.3457
Epoch: 12/20 | Batch: 151/228 | Loss: 0.2177
Epoch: 12/20 | Batch: 161/228 | Loss: 0.4310
Epoch: 12/20 | Batch: 171/228 | Loss: 0.8178
Epoch: 12/20 | Batch: 181/228 | Loss: 0.3616
Epoch: 12/20 | Batch: 191/228 | Loss: 0.2428
Epoch: 12/20 | Batch: 201/228 | Loss: 0.7207
Epoch: 12/20 | Batch: 211/228 | Loss: 0.5536
Epoch: 12/20 | Batch: 221/228 | Loss: 0.5815
Epoch: 12/20 | Train Loss: 0.6634 | Train Acc: 84.15% | Val Loss: 0.5240 | Val Acc: 88.95%
Current learning rate: 0.0001
Current learning rate: 0.0001
Current learning rate: 0.0001
Current learning rate: 0.0001
Current learning rate: 0.0001
Current learning rate: 0.0001
Current learning rate: 0.01
Epoch: 13/20 | Batch: 1/228 | Loss: 0.1712
Epoch: 13/20 | Batch: 11/228 | Loss: 0.3971
Epoch: 13/20 | Batch: 21/228 | Loss: 0.8822
Epoch: 13/20 | Batch: 31/228 | Loss: 0.1050
Epoch: 13/20 | Batch: 41/228 | Loss: 0.6635
Epoch: 13/20 | Batch: 51/228 | Loss: 0.4120
Epoch: 13/20 | Batch: 61/228 | Loss: 0.3492
Epoch: 13/20 | Batch: 71/228 | Loss: 0.5290
Epoch: 13/20 | Batch: 81/228 | Loss: 0.4064
Epoch: 13/20 | Batch: 91/228 | Loss: 0.6206
Epoch: 13/20 | Batch: 101/228 | Loss: 0.3929
Epoch: 13/20 | Batch: 111/228 | Loss: 0.3896
Epoch: 13/20 | Batch: 121/228 | Loss: 2.1294
Epoch: 13/20 | Batch: 131/228 | Loss: 0.8371
Epoch: 13/20 | Batch: 141/228 | Loss: 0.3138
Epoch: 13/20 | Batch: 151/228 | Loss: 0.4063
Epoch: 13/20 | Batch: 161/228 | Loss: 0.9109
Epoch: 13/20 | Batch: 171/228 | Loss: 0.0531
Epoch: 13/20 | Batch: 181/228 | Loss: 0.2216
Epoch: 13/20 | Batch: 191/228 | Loss: 0.9771
Epoch: 13/20 | Batch: 201/228 | Loss: 0.2512
Epoch: 13/20 | Batch: 211/228 | Loss: 0.3764
Epoch: 13/20 | Batch: 221/228 | Loss: 0.2119
Epoch: 13/20 | Train Loss: 0.5253 | Train Acc: 86.48% | Val Loss: 0.4481 | Val Acc: 88.73%
Current learning rate: 1e-05
Current learning rate: 1e-05
Current learning rate: 1e-05
Current learning rate: 1e-05
Current learning rate: 1e-05
Current learning rate: 1e-05
Current learning rate: 0.001
Epoch: 14/20 | Batch: 1/228 | Loss: 0.0284
Epoch: 14/20 | Batch: 11/228 | Loss: 0.9375
Epoch: 14/20 | Batch: 21/228 | Loss: 0.4760
Epoch: 14/20 | Batch: 31/228 | Loss: 0.1238
Epoch: 14/20 | Batch: 41/228 | Loss: 0.3646
Epoch: 14/20 | Batch: 51/228 | Loss: 0.5132
Epoch: 14/20 | Batch: 61/228 | Loss: 0.3563
Epoch: 14/20 | Batch: 71/228 | Loss: 0.1808
Epoch: 14/20 | Batch: 81/228 | Loss: 0.5282
Epoch: 14/20 | Batch: 91/228 | Loss: 0.6695
Epoch: 14/20 | Batch: 101/228 | Loss: 0.7305
Epoch: 14/20 | Batch: 111/228 | Loss: 0.4029
Epoch: 14/20 | Batch: 121/228 | Loss: 0.5082
Epoch: 14/20 | Batch: 131/228 | Loss: 0.1882
Epoch: 14/20 | Batch: 141/228 | Loss: 0.3612
Epoch: 14/20 | Batch: 151/228 | Loss: 0.4371
Epoch: 14/20 | Batch: 161/228 | Loss: 0.2247
Epoch: 14/20 | Batch: 171/228 | Loss: 0.1626
Epoch: 14/20 | Batch: 181/228 | Loss: 0.1496
Epoch: 14/20 | Batch: 191/228 | Loss: 0.7253
Epoch: 14/20 | Batch: 201/228 | Loss: 0.6412
Epoch: 14/20 | Batch: 211/228 | Loss: 0.3258
Epoch: 14/20 | Batch: 221/228 | Loss: 0.3031
Epoch: 14/20 | Train Loss: 0.3940 | Train Acc: 89.01% | Val Loss: 0.3193 | Val Acc: 92.27%
Current learning rate: 1e-05
Current learning rate: 1e-05
Current learning rate: 1e-05
Current learning rate: 1e-05
Current learning rate: 1e-05
Current learning rate: 1e-05
Current learning rate: 0.001
Best accuracy: 92.27%
Model saved to checkpoints\resnet18_pretrained_best.pth
Epoch: 15/20 | Batch: 1/228 | Loss: 0.6154
Epoch: 15/20 | Batch: 11/228 | Loss: 0.1089
Epoch: 15/20 | Batch: 21/228 | Loss: 0.5674
Epoch: 15/20 | Batch: 31/228 | Loss: 0.2214
Epoch: 15/20 | Batch: 41/228 | Loss: 0.3519
Epoch: 15/20 | Batch: 51/228 | Loss: 0.2637
Epoch: 15/20 | Batch: 61/228 | Loss: 0.0821
Epoch: 15/20 | Batch: 71/228 | Loss: 0.2344
Epoch: 15/20 | Batch: 81/228 | Loss: 0.5401
Epoch: 15/20 | Batch: 91/228 | Loss: 0.2373
Epoch: 15/20 | Batch: 101/228 | Loss: 0.2119
Epoch: 15/20 | Batch: 111/228 | Loss: 0.3277
Epoch: 15/20 | Batch: 121/228 | Loss: 0.3725
Epoch: 15/20 | Batch: 131/228 | Loss: 0.3136
Epoch: 15/20 | Batch: 141/228 | Loss: 0.2746
Epoch: 15/20 | Batch: 151/228 | Loss: 0.4009
Epoch: 15/20 | Batch: 161/228 | Loss: 0.1613
Epoch: 15/20 | Batch: 171/228 | Loss: 0.7733
Epoch: 15/20 | Batch: 181/228 | Loss: 0.1806
Epoch: 15/20 | Batch: 191/228 | Loss: 0.5277
Epoch: 15/20 | Batch: 201/228 | Loss: 0.0765
Epoch: 15/20 | Batch: 211/228 | Loss: 0.5326
Epoch: 15/20 | Batch: 221/228 | Loss: 0.1853
Epoch: 15/20 | Train Loss: 0.3271 | Train Acc: 91.14% | Val Loss: 0.3066 | Val Acc: 92.22%
Current learning rate: 1e-05
Current learning rate: 1e-05
Current learning rate: 1e-05
Current learning rate: 1e-05
Current learning rate: 1e-05
Current learning rate: 1e-05
Current learning rate: 0.001
Epoch: 16/20 | Batch: 1/228 | Loss: 0.4646
Epoch: 16/20 | Batch: 11/228 | Loss: 1.1297
Epoch: 16/20 | Batch: 21/228 | Loss: 0.0589
Epoch: 16/20 | Batch: 31/228 | Loss: 0.2904
Epoch: 16/20 | Batch: 41/228 | Loss: 0.0886
Epoch: 16/20 | Batch: 51/228 | Loss: 0.1842
Epoch: 16/20 | Batch: 61/228 | Loss: 0.2216
Epoch: 16/20 | Batch: 71/228 | Loss: 0.6201
Epoch: 16/20 | Batch: 81/228 | Loss: 0.2766
Epoch: 16/20 | Batch: 91/228 | Loss: 0.3911
Epoch: 16/20 | Batch: 101/228 | Loss: 0.7304
Epoch: 16/20 | Batch: 111/228 | Loss: 0.2312
Epoch: 16/20 | Batch: 121/228 | Loss: 0.2849
Epoch: 16/20 | Batch: 131/228 | Loss: 0.0863
Epoch: 16/20 | Batch: 141/228 | Loss: 0.4188
Epoch: 16/20 | Batch: 151/228 | Loss: 0.2337
Epoch: 16/20 | Batch: 161/228 | Loss: 0.0685
Epoch: 16/20 | Batch: 171/228 | Loss: 0.6204
Epoch: 16/20 | Batch: 181/228 | Loss: 0.2067
Epoch: 16/20 | Batch: 191/228 | Loss: 0.2217
Epoch: 16/20 | Batch: 201/228 | Loss: 0.3065
Epoch: 16/20 | Batch: 211/228 | Loss: 0.4352
Epoch: 16/20 | Batch: 221/228 | Loss: 0.0701
Epoch: 16/20 | Train Loss: 0.3174 | Train Acc: 91.46% | Val Loss: 0.3426 | Val Acc: 91.79%
Current learning rate: 1e-05
Current learning rate: 1e-05
Current learning rate: 1e-05
Current learning rate: 1e-05
Current learning rate: 1e-05
Current learning rate: 1e-05
Current learning rate: 0.001
Epoch: 17/20 | Batch: 1/228 | Loss: 0.2030
Epoch: 17/20 | Batch: 11/228 | Loss: 0.3239
Epoch: 17/20 | Batch: 21/228 | Loss: 0.1381
Epoch: 17/20 | Batch: 31/228 | Loss: 0.8777
Epoch: 17/20 | Batch: 41/228 | Loss: 0.0503
Epoch: 17/20 | Batch: 51/228 | Loss: 0.4408
Epoch: 17/20 | Batch: 61/228 | Loss: 0.1846
Epoch: 17/20 | Batch: 71/228 | Loss: 0.2042
Epoch: 17/20 | Batch: 81/228 | Loss: 0.6058
Epoch: 17/20 | Batch: 91/228 | Loss: 0.1911
Epoch: 17/20 | Batch: 101/228 | Loss: 0.4902
Epoch: 17/20 | Batch: 111/228 | Loss: 0.2410
Epoch: 17/20 | Batch: 121/228 | Loss: 0.1289
Epoch: 17/20 | Batch: 131/228 | Loss: 0.2479
Epoch: 17/20 | Batch: 141/228 | Loss: 0.1724
Epoch: 17/20 | Batch: 151/228 | Loss: 0.2424
Epoch: 17/20 | Batch: 161/228 | Loss: 0.2105
Epoch: 17/20 | Batch: 171/228 | Loss: 0.1483
Epoch: 17/20 | Batch: 181/228 | Loss: 0.2286
Epoch: 17/20 | Batch: 191/228 | Loss: 0.4559
Epoch: 17/20 | Batch: 201/228 | Loss: 0.1924
Epoch: 17/20 | Batch: 211/228 | Loss: 0.1894
Epoch: 17/20 | Batch: 221/228 | Loss: 0.3172
Epoch: 17/20 | Train Loss: 0.2991 | Train Acc: 91.70% | Val Loss: 0.3242 | Val Acc: 91.90%
Current learning rate: 1e-05
Current learning rate: 1e-05
Current learning rate: 1e-05
Current learning rate: 1e-05
Current learning rate: 1e-05
Current learning rate: 1e-05
Current learning rate: 0.001
Epoch: 18/20 | Batch: 1/228 | Loss: 0.2609
Epoch: 18/20 | Batch: 11/228 | Loss: 0.2155
Epoch: 18/20 | Batch: 21/228 | Loss: 0.1721
Epoch: 18/20 | Batch: 31/228 | Loss: 0.2518
Epoch: 18/20 | Batch: 41/228 | Loss: 0.8010
Epoch: 18/20 | Batch: 51/228 | Loss: 0.2841
Epoch: 18/20 | Batch: 61/228 | Loss: 0.5794
Epoch: 18/20 | Batch: 71/228 | Loss: 0.1308
Epoch: 18/20 | Batch: 81/228 | Loss: 0.4260
Epoch: 18/20 | Batch: 91/228 | Loss: 0.2917
Epoch: 18/20 | Batch: 101/228 | Loss: 0.3138
Epoch: 18/20 | Batch: 111/228 | Loss: 0.2176
Epoch: 18/20 | Batch: 121/228 | Loss: 0.6902
Epoch: 18/20 | Batch: 131/228 | Loss: 0.6028
Epoch: 18/20 | Batch: 141/228 | Loss: 0.1242
Epoch: 18/20 | Batch: 151/228 | Loss: 0.1612
Epoch: 18/20 | Batch: 161/228 | Loss: 0.0433
Epoch: 18/20 | Batch: 171/228 | Loss: 0.3724
Epoch: 18/20 | Batch: 181/228 | Loss: 0.5542
Epoch: 18/20 | Batch: 191/228 | Loss: 0.1035
Epoch: 18/20 | Batch: 201/228 | Loss: 0.0138
Epoch: 18/20 | Batch: 211/228 | Loss: 0.4086
Epoch: 18/20 | Batch: 221/228 | Loss: 0.4661
Epoch: 18/20 | Train Loss: 0.3133 | Train Acc: 91.94% | Val Loss: 0.3240 | Val Acc: 91.58%
Current learning rate: 1e-05
Current learning rate: 1e-05
Current learning rate: 1e-05
Current learning rate: 1e-05
Current learning rate: 1e-05
Current learning rate: 1e-05
Current learning rate: 0.001
Epoch: 19/20 | Batch: 1/228 | Loss: 0.3461
Epoch: 19/20 | Batch: 11/228 | Loss: 0.2504
Epoch: 19/20 | Batch: 21/228 | Loss: 0.1001
Epoch: 19/20 | Batch: 31/228 | Loss: 0.7796
Epoch: 19/20 | Batch: 41/228 | Loss: 0.1236
Epoch: 19/20 | Batch: 51/228 | Loss: 0.3318
Epoch: 19/20 | Batch: 61/228 | Loss: 0.2448
Epoch: 19/20 | Batch: 71/228 | Loss: 0.2632
Epoch: 19/20 | Batch: 81/228 | Loss: 0.2693
Epoch: 19/20 | Batch: 91/228 | Loss: 0.2041
Epoch: 19/20 | Batch: 101/228 | Loss: 0.1442
Epoch: 19/20 | Batch: 111/228 | Loss: 0.6649
Epoch: 19/20 | Batch: 121/228 | Loss: 0.3930
Epoch: 19/20 | Batch: 131/228 | Loss: 0.3931
Epoch: 19/20 | Batch: 141/228 | Loss: 0.0837
Epoch: 19/20 | Batch: 151/228 | Loss: 0.2679
Epoch: 19/20 | Batch: 161/228 | Loss: 0.5371
Epoch: 19/20 | Batch: 171/228 | Loss: 0.6337
Epoch: 19/20 | Batch: 181/228 | Loss: 0.0608
Epoch: 19/20 | Batch: 191/228 | Loss: 0.1396
Epoch: 19/20 | Batch: 201/228 | Loss: 0.2173
Epoch: 19/20 | Batch: 211/228 | Loss: 0.4200
Epoch: 19/20 | Batch: 221/228 | Loss: 0.3606
Epoch: 19/20 | Train Loss: 0.2881 | Train Acc: 92.28% | Val Loss: 0.3176 | Val Acc: 92.49%
Current learning rate: 1e-05
Current learning rate: 1e-05
Current learning rate: 1e-05
Current learning rate: 1e-05
Current learning rate: 1e-05
Current learning rate: 1e-05
Current learning rate: 0.001
Best accuracy: 92.49%
Model saved to checkpoints\resnet18_pretrained_best.pth
Epoch: 20/20 | Batch: 1/228 | Loss: 0.0574
Epoch: 20/20 | Batch: 11/228 | Loss: 0.1424
Epoch: 20/20 | Batch: 21/228 | Loss: 0.0628
Epoch: 20/20 | Batch: 31/228 | Loss: 0.3694
Epoch: 20/20 | Batch: 41/228 | Loss: 0.1277
Epoch: 20/20 | Batch: 51/228 | Loss: 0.3868
Epoch: 20/20 | Batch: 61/228 | Loss: 0.5943
Epoch: 20/20 | Batch: 71/228 | Loss: 0.1818
Epoch: 20/20 | Batch: 81/228 | Loss: 0.2813
Epoch: 20/20 | Batch: 91/228 | Loss: 0.0720
Epoch: 20/20 | Batch: 101/228 | Loss: 0.1512
Epoch: 20/20 | Batch: 111/228 | Loss: 0.3542
Epoch: 20/20 | Batch: 121/228 | Loss: 0.3047
Epoch: 20/20 | Batch: 131/228 | Loss: 0.3453
Epoch: 20/20 | Batch: 141/228 | Loss: 0.7154
Epoch: 20/20 | Batch: 151/228 | Loss: 0.2868
Epoch: 20/20 | Batch: 161/228 | Loss: 0.1724
Epoch: 20/20 | Batch: 171/228 | Loss: 0.3373
Epoch: 20/20 | Batch: 181/228 | Loss: 0.2932
Epoch: 20/20 | Batch: 191/228 | Loss: 0.1897
Epoch: 20/20 | Batch: 201/228 | Loss: 0.0461
Epoch: 20/20 | Batch: 211/228 | Loss: 0.5359
Epoch: 20/20 | Batch: 221/228 | Loss: 0.3129
Epoch: 20/20 | Train Loss: 0.2825 | Train Acc: 92.88% | Val Loss: 0.3118 | Val Acc: 92.44%
Current learning rate: 1e-05
Current learning rate: 1e-05
Current learning rate: 1e-05
Current learning rate: 1e-05
Current learning rate: 1e-05
Current learning rate: 1e-05
Current learning rate: 0.001
